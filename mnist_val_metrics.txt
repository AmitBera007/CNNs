
 Training with LR: 0.001, Batch Size: 32, Optimizer: SGD, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.27375498699815304,94.6,0.9456887005513075,0.9455386336268308
2,0.16949955326373176,96.02857142857142,0.9601121555893807,0.959893003774653
3,0.12818107150120822,96.68571428571428,0.9667018866802687,0.9665666825195615
4,0.11043863097996745,97.44285714285714,0.9741291418921222,0.9741728606762837
5,0.09877679610973623,97.35714285714285,0.9734870552402967,0.9732929257131244
6,0.08989327858929357,97.67142857142858,0.9765720942030814,0.9765203276348124
7,0.08343942635628866,97.71428571428571,0.9770893745815906,0.9768441978932323
8,0.0814157036987886,97.95714285714286,0.9796284506886306,0.9791398236804951
9,0.07471669787864231,98.07142857142857,0.9806006100129968,0.9805348957841036
10,0.07099544395560815,98.04285714285714,0.9803638820192276,0.9801599701786243
11,0.06804214162139656,98.02857142857142,0.9800861568487482,0.9801429182383213
12,0.06780817119200548,98.04285714285714,0.9803721324825148,0.9802055389220289
13,0.06372010467050929,98.24285714285715,0.9821878286849314,0.9822943594863582
14,0.06348304510367482,98.21428571428571,0.9822164305516704,0.9818571895414723
15,0.060780722358727564,98.22857142857143,0.9821782415995305,0.9820905322608585
16,0.05924430351223814,98.28571428571429,0.9827396213016621,0.9826743090023113
17,0.05975585847935686,98.25714285714285,0.9827204597896617,0.9822404257886739
18,0.05877797004817794,98.38571428571429,0.9838435387609259,0.9836152340816214
19,0.05607508453242821,98.38571428571429,0.9838141266305709,0.9836155540358164
20,0.055120364352996935,98.34285714285714,0.9833943762331068,0.9831845979443795
21,0.05637785067492628,98.35714285714286,0.9834892841446836,0.9833872889738281
22,0.05624469890329374,98.31428571428572,0.9832343816726308,0.9828256192476557
23,0.054130390484192194,98.45714285714286,0.9845025459026026,0.9843594839367565
24,0.05452644457130536,98.44285714285715,0.9844650172222471,0.9841544407761743
25,0.054607633986620906,98.31428571428572,0.9831180488427853,0.9828953448486853
26,0.054989909793071653,98.41428571428571,0.9840156273645382,0.9839927573032969
27,0.053546095080354746,98.5,0.984921630919559,0.9847662810371836
28,0.05319225866524035,98.38571428571429,0.9837553256732171,0.9835930486065922
29,0.0526498778001299,98.44285714285715,0.9842904132629254,0.984193753418723
30,0.05218321138878085,98.57142857142858,0.9855527104630166,0.9855655864415652
31,0.05121973949616358,98.54285714285714,0.985370369780051,0.9852104807148129
32,0.052714339959526596,98.5,0.9849889398268067,0.9847670625836678
33,0.05276551093750944,98.4857142857143,0.9847025870420026,0.9847139598120214
34,0.052790698632555394,98.4857142857143,0.9848288300198,0.9846256944391722
35,0.05352127576697635,98.3,0.9829930490851517,0.982765562259393
36,0.05056331083486835,98.42857142857143,0.9841648806929706,0.9841207995068473
37,0.0518889226493549,98.5,0.9849061326377738,0.9848012515359565
38,0.05227024550709159,98.4,0.9838964161378035,0.9838185050088442
39,0.0510536854362145,98.45714285714286,0.984487626007871,0.9843601699480846
40,0.05107298980362832,98.54285714285714,0.9853168692313072,0.9852397938618342
41,0.051073099070039395,98.42857142857143,0.9842369808592014,0.9840744218605437

 Training with LR: 0.001, Batch Size: 32, Optimizer: SGD, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.2796801643012321,94.24285714285713,0.9426190601096053,0.9417523303669253
2,0.1715894118461707,96.02857142857142,0.9601856942826756,0.9596944796999989
3,0.13180891315550564,96.8,0.9678438760392574,0.9676801432906128
4,0.11317078327785617,97.22857142857143,0.9724500350334895,0.971879780444611
5,0.09750006455060554,97.67142857142858,0.976711593652877,0.9764560407449621
6,0.08961226359077784,97.74285714285715,0.9775057398720245,0.9770776379561663
7,0.0804354313880069,97.98571428571428,0.9798034572418937,0.979568368090613
8,0.07749669469008434,97.89999999999999,0.9789606433429577,0.9787817675149739
9,0.07406861828129789,98.0142857142857,0.9801706185833468,0.9799308074214498
10,0.07132466048529568,98.08571428571429,0.9807115812119109,0.9807578708771016
11,0.06998461812998266,98.2,0.9820953342810688,0.9817038405099499
12,0.0662338527782765,98.18571428571428,0.9820030631340071,0.9815278603958401
13,0.06840346429973296,98.28571428571429,0.9828366548187976,0.9827765247813905
14,0.06204950286194546,98.34285714285714,0.9833456773920186,0.9833172595277642
15,0.059453828073187505,98.47142857142858,0.984792597588596,0.9844960107374667
16,0.057672173273855966,98.5,0.9850175482830847,0.984749923844619
17,0.05685561527413014,98.52857142857144,0.9852085998216202,0.9851445341444777
18,0.055984896296193,98.5142857142857,0.9851450201673402,0.9848754125017785
19,0.05315939728255686,98.64285714285714,0.9863323958534933,0.9862510402460766
20,0.05519677664591297,98.4857142857143,0.9847685403829483,0.9846673267852417
21,0.05460678124810956,98.57142857142858,0.9855893949195215,0.9855585028405587
22,0.05547581524184169,98.35714285714286,0.9835003853423963,0.9833167619357305
23,0.055738864183217524,98.44285714285715,0.9843049650217466,0.9842507312546047
24,0.05083539866795551,98.55714285714285,0.9854704105944808,0.9854070986687666
25,0.05383855345675968,98.42857142857143,0.9842939462370692,0.9840337642236132
26,0.0502147792687546,98.5142857142857,0.9851251761300135,0.984916323135753
27,0.049735432039929306,98.64285714285714,0.9862305663853798,0.9863473723582823
28,0.048353450955423316,98.6,0.9858261583434338,0.9858446036561803
29,0.04850543999606446,98.62857142857143,0.9861174343287045,0.9861663779438729
30,0.04882687720423352,98.65714285714286,0.9864903939504451,0.9864570294090914
31,0.04810244352322871,98.64285714285714,0.9862589492162988,0.9863159749282101
32,0.048051583378407765,98.52857142857144,0.9852360647460368,0.984989569691669
33,0.047046750885983035,98.61428571428571,0.9860715905289237,0.985910913274096
34,0.0483258135683758,98.61428571428571,0.9860319699106682,0.9859921837065903
35,0.046428906031220844,98.7,0.9868075546788443,0.9869327015322729
36,0.047178027421537976,98.65714285714286,0.9864523585872182,0.9864201209442898
37,0.047732428343781615,98.65714285714286,0.9863964897528945,0.9864514914608951
38,0.046699967540983434,98.74285714285715,0.9873070571542979,0.9873255203646105
39,0.04625854882455248,98.62857142857143,0.9860593882929869,0.9861803815729671
40,0.045639236141889264,98.67142857142858,0.9866152047187253,0.9865341867715829
41,0.04752642712204985,98.61428571428571,0.9860758638684921,0.9860032426387836
42,0.046685924408287574,98.58571428571429,0.9858043691385928,0.9856672709848763
43,0.04730714451373857,98.62857142857143,0.9861192386213343,0.9861359025549499
44,0.046085591385987286,98.74285714285715,0.9873053788504732,0.9872688641639913
45,0.04464358004840244,98.68571428571428,0.986768098849091,0.9867130659447143
46,0.0454285064093943,98.61428571428571,0.9861080256554702,0.985912400198354
47,0.047647182385279846,98.62857142857143,0.9861671903387773,0.9861145693112091
48,0.04588661955661017,98.71428571428571,0.9870123157483436,0.9870278649663671
49,0.04499933452581451,98.68571428571428,0.986826620467164,0.9866372623673196
50,0.045923693098800816,98.67142857142858,0.9866010911786963,0.9865731892121412

 Training with LR: 0.001, Batch Size: 32, Optimizer: SGD, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.23006706541939959,94.64285714285714,0.9464472310618284,0.9456724076878947
2,0.15303083138378787,96.22857142857143,0.9621143165257269,0.961959578658911
3,0.11772476931923329,96.98571428571428,0.9696536076683934,0.9695775126907338
4,0.10017259375587718,97.31428571428572,0.9731216000932849,0.9727890679200341
5,0.09087487369282468,97.58571428571429,0.9757153592816818,0.9758107781719818
6,0.08491052198542716,97.6,0.9762500603556716,0.9756908767178455
7,0.07692658428536499,97.98571428571428,0.9797409518621075,0.9796946066272703
8,0.07073012909949779,98.11428571428571,0.981003727678986,0.9809708975759165
9,0.06922264914474871,98.17142857142858,0.9816590656913957,0.9814371440875533
10,0.06609222154052222,98.21428571428571,0.9820830576311975,0.9819554073459917
11,0.06663027959003977,98.2,0.9818972970674688,0.9817419181431017
12,0.06131161997715632,98.28571428571429,0.9826769216395395,0.9827403932744847
13,0.06257378160485734,98.22857142857143,0.9821311129203508,0.9821309792156405
14,0.058081134355342075,98.22857142857143,0.9821743544753565,0.9820696945685297
15,0.05707848224933493,98.25714285714285,0.9823072246660788,0.9824743279365092
16,0.058224928827922295,98.3,0.9829458394324609,0.982698419326755
17,0.05761456912379184,98.32857142857144,0.9832003268736669,0.983180224743719
18,0.0558280558537981,98.37142857142858,0.983669712806315,0.983423600648252
19,0.05519693379702906,98.34285714285714,0.9832867886061729,0.9832465185356309
20,0.05340021567049194,98.38571428571429,0.9838782655154988,0.9835779229007855
21,0.0515412965323776,98.47142857142858,0.9845546735141426,0.9846191693428563
22,0.05192706325372094,98.37142857142858,0.9835811140232111,0.9835769783626909
23,0.051272469291518775,98.38571428571429,0.9837619639406693,0.9837338363523397
24,0.05114571753991385,98.41428571428571,0.9839370730275266,0.984049098385125
25,0.05167337133842584,98.32857142857144,0.9831507684347633,0.9831081350665958
26,0.05000229534739841,98.42857142857143,0.9842125564813449,0.984203497226812
27,0.048392411552105934,98.4857142857143,0.9847727307897666,0.9846824699774253
28,0.0491744320739707,98.52857142857144,0.985262758903206,0.9851284885356234
29,0.050560364396562245,98.45714285714286,0.9844253362590999,0.9844849163375505
30,0.048109519599456356,98.5142857142857,0.9850702111253808,0.9849169403716175
31,0.04984375507013711,98.4857142857143,0.9847294057807778,0.9847093374845063
32,0.04814810695532777,98.45714285714286,0.9845089347239829,0.984396116205682
33,0.04742269383155481,98.41428571428571,0.9840532565891029,0.9839465284944845
34,0.04675075265785709,98.4857142857143,0.9847018788759204,0.9847876262824407
35,0.04830667415270199,98.4857142857143,0.9847560457567738,0.9847919026756913
36,0.04817342707891545,98.4857142857143,0.9847260794477138,0.9847334985759119
37,0.04687883781022541,98.52857142857144,0.9853070042721764,0.9850293578102388
38,0.04823001440599578,98.42857142857143,0.9842019565583751,0.9841608883442461
39,0.04642693502573322,98.5142857142857,0.9850384629865481,0.9850220018670448
40,0.04692263628162665,98.4857142857143,0.9847497471400357,0.984675551180439
41,0.047711754408048375,98.38571428571429,0.9836748587573719,0.9837806135552846
42,0.045664785804331184,98.54285714285714,0.9853605605751212,0.9852147302586867
43,0.04700911012063543,98.4857142857143,0.9847239894298795,0.9847196892426803
44,0.04578392744063268,98.6,0.9859033467768255,0.9858204703517753
45,0.047621293444336354,98.5,0.9847825414585618,0.9849534249222396
46,0.04717381042906734,98.55714285714285,0.9854253231296106,0.9854778717932465
47,0.046316070418079815,98.47142857142858,0.9846151841852704,0.9845842681361443

 Training with LR: 0.001, Batch Size: 32, Optimizer: Adam, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.09216689571449066,97.44285714285714,0.974785633816324,0.9740752787315182
2,0.06588138078794428,98.15714285714286,0.9819019031795264,0.9814261530413347
3,0.052890864671335545,98.35714285714286,0.9834979406275742,0.9834666693733244
4,0.050239455677807056,98.4,0.9837675183563956,0.9840759871938791
5,0.04665965301550278,98.5,0.984912037111922,0.9848733595729703
6,0.05080953022501257,98.55714285714285,0.985612808101337,0.985423275879796
7,0.04416402240047767,98.64285714285714,0.986425777241978,0.9862339409695663
8,0.04691660700027818,98.58571428571429,0.9858774487517105,0.9856650182247026
9,0.044813403214798965,98.61428571428571,0.9861350265792034,0.9860069671473177
10,0.0484201422813173,98.5142857142857,0.9851200663203631,0.9850459528787479
11,0.051562123206076234,98.5,0.9848625541475657,0.9848565051201238
12,0.050905625802663064,98.55714285714285,0.9855086564758693,0.985497354962661

 Training with LR: 0.001, Batch Size: 32, Optimizer: Adam, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.08705209739523255,97.7,0.977174591367929,0.9766290964091638
2,0.06401384192557164,98.2,0.9818134888118356,0.982003523619006
3,0.05554947327582174,98.27142857142857,0.9832691709218085,0.9823236286726337
4,0.04761999047767439,98.62857142857143,0.9863503001611482,0.9861243380412409
5,0.05035924239320145,98.55714285714285,0.9855240884832522,0.9854298998039954
6,0.04740809832277525,98.57142857142858,0.9858978175461394,0.9854940291083277
7,0.04328134950539034,98.7,0.9871725982220525,0.9867567551307346
8,0.0473627670421281,98.6,0.9857808696683307,0.9860798016495529
9,0.047180986215948385,98.52857142857144,0.9852787394886138,0.9851718951022918
10,0.04715792167520222,98.5,0.9850426773030353,0.9848685463026932
11,0.0472738663397504,98.5142857142857,0.9851530287218371,0.9850001462711562
12,0.04633758350468951,98.67142857142858,0.9867348690267684,0.9865785457213352

 Training with LR: 0.001, Batch Size: 32, Optimizer: Adam, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.09020655030240071,97.64285714285714,0.9763020714458737,0.9762938520834435
2,0.06682427912805927,98.05714285714285,0.9806436522041138,0.9804690457351087
3,0.0518424875883292,98.4,0.9839763779124656,0.9838924503119812
4,0.04901523686271399,98.5142857142857,0.9853129600029138,0.9849244357956113
5,0.055555360207810454,98.28571428571429,0.9829305282116862,0.9826724494654269
6,0.044603660460572146,98.7,0.987044890015769,0.9867840670035155
7,0.048875496829870545,98.57142857142858,0.9857849338550817,0.9855419775341845
8,0.046387492795341934,98.62857142857143,0.9861838102825786,0.9861764876457164
9,0.04474918111841424,98.74285714285715,0.9872737158073862,0.9873405460232018
10,0.049064329513173216,98.57142857142858,0.9856951344323406,0.9854631457030709
11,0.04980425281586967,98.45714285714286,0.9847229266100156,0.9843678344000161

 Training with LR: 0.001, Batch Size: 64, Optimizer: SGD, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.4571345350959084,92.44285714285714,0.9244124037681137,0.9231701438870834
2,0.24600602049719203,95.31428571428572,0.9530576210123453,0.9525096368539374
3,0.1794200091876767,96.14285714285714,0.9613622983097642,0.9609487884554635
4,0.149323120103641,96.7,0.9669461161869013,0.9666508083123169
5,0.12906312776560133,97.07142857142857,0.9705720924926181,0.9703997054487804
6,0.11483325809240341,97.2,0.9718262063851265,0.9717795655751397
7,0.10702864780006084,97.42857142857143,0.97434469141998,0.974037732859299
8,0.09924768663265489,97.57142857142857,0.9757759981361961,0.9753104783437696
9,0.09554437498816035,97.72857142857143,0.9773663153029739,0.9770098824310793
10,0.08665179522200064,98.02857142857142,0.9801862150136611,0.9800789425273588
11,0.08253526465797967,97.98571428571428,0.979835801821344,0.97958461969389
12,0.07890885810960423,97.98571428571428,0.9797269011396688,0.9796874055461767
13,0.07594393764368512,98.18571428571428,0.9818307952923787,0.981719783037628
14,0.07412888250229034,98.14285714285714,0.9813540695859067,0.9812127476659633
15,0.07296255567873067,98.1,0.9810115406494194,0.980808598958031
16,0.07035879574038766,98.17142857142858,0.9816425800517434,0.9815527905878045
17,0.06781167454001578,98.18571428571428,0.9817641692399869,0.9817058081404211
18,0.06678675691681829,98.34285714285714,0.9833727329906325,0.983274970558585
19,0.06310246085578745,98.42857142857143,0.984163575838274,0.9840770628779609
20,0.06505493194034154,98.3,0.9830326934943304,0.982796081883131
21,0.06116000489247116,98.37142857142858,0.9836783936242707,0.9834796497084776
22,0.059482155892659316,98.42857142857143,0.9842310853641516,0.9841025087724278
23,0.060525322409177365,98.47142857142858,0.9846753101650048,0.9845861253732633
24,0.059787191670726644,98.4,0.9839556393398434,0.9838525487310047
25,0.05762268684973771,98.42857142857143,0.9842106897843242,0.9841693812767455
26,0.0573611465875398,98.52857142857144,0.9851595244675145,0.9852021307573933
27,0.056235951760953126,98.4857142857143,0.9847754688672399,0.9846937258821796
28,0.05553101243197241,98.5142857142857,0.9849986211009734,0.9850402357165713
29,0.053995342645794156,98.6,0.9858898221079639,0.9859097332534127
30,0.05393971794030883,98.57142857142858,0.9856283061567405,0.9855850405799993
31,0.053202830534428355,98.55714285714285,0.9854863056461802,0.9854394038563911
32,0.052018183275041256,98.55714285714285,0.9854703500607475,0.9854296737125063
33,0.051931767965751614,98.62857142857143,0.9861379466909916,0.9861983176010245
34,0.0548061710528352,98.47142857142858,0.9845967949845283,0.9846629603110598
35,0.05205136809752069,98.5,0.9849668841175937,0.984843932759891
36,0.0506981882605363,98.5142857142857,0.9850836852889209,0.9850022164703673
37,0.050289322727952494,98.57142857142858,0.9856200538491292,0.9855643431081929
38,0.04885244655253535,98.64285714285714,0.9862952510685101,0.9863447318695637
39,0.05054919559677894,98.55714285714285,0.9855103568645258,0.9854803584172297
40,0.05095575284424492,98.6,0.9859286929849645,0.9858387759880411
41,0.05117518814619292,98.54285714285714,0.98525976874693,0.9854029267932238
42,0.049503586492077874,98.58571428571429,0.9856837638086917,0.9857802506579482
43,0.048356544042260134,98.62857142857143,0.9861584349813398,0.9861656754878616
44,0.04951978520998223,98.44285714285715,0.9843833323365605,0.9842813956705246
45,0.0484549994749779,98.6,0.9858441933042679,0.9858794157542994
46,0.047662670779126615,98.65714285714286,0.9864643323854555,0.9864530142933814
47,0.04765181548533622,98.57142857142858,0.9855856274979835,0.9855888204823791
48,0.047197505861351435,98.62857142857143,0.9861568826077114,0.9862017887802542
49,0.04919862401333045,98.67142857142858,0.9865940416812509,0.9865925268286778
50,0.047346985069188205,98.52857142857144,0.9852066123227109,0.9851687866073631

 Training with LR: 0.001, Batch Size: 64, Optimizer: SGD, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.4623590824278918,91.62857142857142,0.9165669972486861,0.9148162711461032
2,0.2514557928524234,94.78571428571428,0.9476511896084979,0.9473664630090195
3,0.1886704879050905,95.7,0.9566336283738858,0.956566894630631
4,0.1519631480628794,96.51428571428572,0.9649419350882352,0.9647830409719497
5,0.13263730660758236,96.85714285714285,0.9683752662720956,0.9682794370049732
6,0.11875105418942192,97.07142857142857,0.9704215167324977,0.9705105499875586
7,0.10811638655987653,97.42857142857143,0.9741131426170936,0.9739769571185036
8,0.09873234634710984,97.54285714285714,0.9752771148644717,0.9751954968637266
9,0.09793683666397225,97.65714285714286,0.9765735640279123,0.9761919447550929
10,0.09105014426803047,97.62857142857143,0.9762168512705929,0.9760763251342336
11,0.08743183441798795,97.75714285714285,0.9773658822398789,0.9774216970879227
12,0.08205379103733734,97.85714285714285,0.9784390535151024,0.9783988463294696
13,0.0804074596782977,98.0,0.9797934769519963,0.9799643200131328
14,0.07619575638832017,98.0142857142857,0.9801238329522668,0.9798018421184604
15,0.0749053347686475,98.08571428571429,0.9806417554162555,0.9806283044232054
16,0.07462578441270373,97.94285714285714,0.9794267129597503,0.9790197084045985
17,0.07118498226627708,98.14285714285714,0.9812568565725291,0.9813513609828861
18,0.06741503328931603,98.25714285714285,0.9824544744449921,0.982352628031441
19,0.06602600801905448,98.2,0.9818689146873245,0.9817984749389058
20,0.06545464060353962,98.28571428571429,0.9827629186725865,0.9827226374640563
21,0.0652708761648021,98.28571428571429,0.9826484020260084,0.9827872789921853
22,0.06449082230471752,98.24285714285715,0.9823622101038101,0.98215883530969
23,0.06306511362675916,98.28571428571429,0.9826902721856406,0.9828029276696333
24,0.06052196747200055,98.38571428571429,0.9836414457462652,0.983784600724847
25,0.06084183562038974,98.38571428571429,0.983670985116496,0.9837915969752368
26,0.059888542113317685,98.31428571428572,0.9829703325516219,0.9830396308509366
27,0.05827554612505165,98.41428571428571,0.9839371417870921,0.9840786857105837
28,0.05989282490177588,98.35714285714286,0.9834730074105043,0.983305964091414
29,0.05998427674851634,98.32857142857144,0.9831656822280819,0.9832419936448534
30,0.05635279968211597,98.42857142857143,0.9841236398011304,0.9841839198989681
31,0.059238324288956146,98.25714285714285,0.9825777540371581,0.982277056231623
32,0.056640938034450465,98.52857142857144,0.9851720949347055,0.9851211069248098
33,0.057378477196801794,98.38571428571429,0.9837295341912029,0.9837645407679171
34,0.056253509426658806,98.42857142857143,0.9841753301596935,0.9841839543874347
35,0.054807590506970885,98.32857142857144,0.9831461051388457,0.983162618087164
36,0.05598970828577876,98.5,0.9848588213547969,0.9848892135198023
37,0.05595736072652719,98.34285714285714,0.9832812644846399,0.9834679831506374
38,0.05526316173543984,98.38571428571429,0.9837721876987693,0.983863677884074
39,0.052495116177438336,98.42857142857143,0.984152459510199,0.9841573472296357
40,0.05434882276776162,98.4857142857143,0.984727980301453,0.9848217189211971
41,0.05444410134276206,98.41428571428571,0.9839866267041305,0.9840921478092117
42,0.05412693358534439,98.44285714285715,0.9843317439239904,0.9843994258015574
43,0.05330441908233545,98.54285714285714,0.9852189499171452,0.9853970464407213
44,0.05265262179838663,98.35714285714286,0.9834116743055787,0.9835083174210334

 Training with LR: 0.001, Batch Size: 64, Optimizer: SGD, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.3991641388698058,92.72857142857143,0.927806621726924,0.9263797950878387
2,0.23327314365993845,95.1,0.9508973897269197,0.9503880649415685
3,0.1772776611149311,95.87142857142858,0.9586698686250512,0.9582686639495204
4,0.14891688759354027,96.38571428571429,0.9639239125563781,0.9634384048335528
5,0.13109090920876373,96.75714285714285,0.9677152201195758,0.9672139430896827
6,0.11738256432793358,97.01428571428572,0.9701826382052288,0.9699689499127656
7,0.10909089703451504,97.21428571428572,0.9722682088185925,0.9718355467240818
8,0.09900235062973066,97.45714285714286,0.9746438531593983,0.9742490908886591
9,0.09562721352346919,97.5142857142857,0.9750989298871661,0.9749835895481775
10,0.0886715931309895,97.67142857142858,0.9768663850922327,0.9763823331427319
11,0.08580651779405095,97.71428571428571,0.9772679753774179,0.9768941789112138
12,0.08337184473533522,97.88571428571429,0.9788849656856611,0.9786064072992046
13,0.07905229181051254,97.77142857142857,0.9776859383310447,0.9775424106819365
14,0.07679068847474727,97.82857142857144,0.9784550010269738,0.977964998765849
15,0.07361984765157104,97.94285714285714,0.9795108534295369,0.9792129169201809
16,0.07493888013572855,97.84285714285714,0.9784768123408423,0.9782802216054947
17,0.07150823556902734,98.04285714285714,0.9804613249411303,0.980207941226009
18,0.06854974949224428,98.14285714285714,0.981412300221107,0.9812092497736987
19,0.06700073036957871,98.15714285714286,0.9815512679240197,0.981381193514587
20,0.0662034738893536,98.15714285714286,0.9815503353982148,0.9814039687314281
21,0.06520067260346629,98.04285714285714,0.980438710001758,0.9802571741546158
22,0.06160390923985026,98.22857142857143,0.9822135901677926,0.98217761546973
23,0.06475480860945854,98.07142857142857,0.9808075769152401,0.9805453253321892
24,0.062299226397987115,98.24285714285715,0.9823138711279794,0.9823243699367248
25,0.06280935612422499,98.05714285714285,0.9808100568372234,0.9802607527355528
26,0.060555492650548166,98.18571428571428,0.9819066679105017,0.981651977701268
27,0.060272813057103615,98.12857142857143,0.981377671545887,0.9810332444974037
28,0.057528625623407686,98.3,0.9829494616017215,0.9829196703075012
29,0.058308748850090936,98.22857142857143,0.982204403804818,0.9822668098008025
30,0.059087397649206896,98.24285714285715,0.9824921181429052,0.9822515063704044
31,0.05716033684597774,98.37142857142858,0.9837004389553737,0.983576242309628
32,0.057913005165755746,98.2,0.9819230621058803,0.9819838665707701
33,0.057341860340569505,98.28571428571429,0.9828344840923979,0.9827211091395913
34,0.05389587219211866,98.4,0.983953192884966,0.9838675766022827
35,0.0549568294886161,98.3,0.9829455009274837,0.9828714026199172
36,0.053798727564175024,98.35714285714286,0.9835349343376205,0.9833835099933473
37,0.053353130161254245,98.38571428571429,0.9838079342357939,0.983769080763409
38,0.05412521303038705,98.34285714285714,0.9834056723171425,0.9832790175944354
39,0.05431825381026349,98.3,0.9830090962959052,0.9828382903549358
40,0.052078042945570564,98.5,0.9850158832087326,0.9848457195687905
41,0.05184215778823603,98.35714285714286,0.9835572495234679,0.9834027426168392
42,0.053662144625559446,98.4,0.9839572272052066,0.9838740395896893
43,0.051841875127601356,98.42857142857143,0.9841531458174254,0.984191251900031
44,0.05152904107235372,98.44285714285715,0.9843664329391231,0.9843084563223309
45,0.05292317728850652,98.41428571428571,0.9842719401299599,0.9839586558315375
46,0.05211890776303004,98.4,0.9839499135901771,0.9839069015129202
47,0.05098110264463519,98.42857142857143,0.9843055356784973,0.9841401143954827
48,0.04970058113209565,98.54285714285714,0.9852901153392079,0.985309343625004
49,0.048972414349290457,98.55714285714285,0.9854911758961842,0.9854340179852645
50,0.05113059579902752,98.54285714285714,0.9853545786735844,0.9853517518250197

 Training with LR: 0.001, Batch Size: 64, Optimizer: Adam, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.10450301305814223,97.52857142857142,0.9752091017776291,0.975192509443912
2,0.06796845609152859,98.17142857142858,0.9815181013979422,0.9816684965822471
3,0.05945965967733752,98.14285714285714,0.981506728465457,0.9812877922106388
4,0.053231486805122005,98.37142857142858,0.9835212683039825,0.9837111105391845
5,0.050328083425252274,98.41428571428571,0.9842651671226157,0.9840129096122977
6,0.05136514252729037,98.35714285714286,0.9838359158021588,0.9832912659636349
7,0.04727900131415068,98.52857142857144,0.9852381503401191,0.9851887706597141
8,0.042702282255049795,98.64285714285714,0.9863147116944602,0.9863074866458028
9,0.04813795566812835,98.57142857142858,0.9857360062716264,0.9854343068118651
10,0.0416113491831559,98.74285714285715,0.9873809915449485,0.9873336891198192
11,0.04453793461169963,98.65714285714286,0.9865167154379473,0.9864388671743848
12,0.04254272946749221,98.87142857142858,0.9885961862456026,0.988665437953317
13,0.04150156102497766,98.87142857142858,0.988598019115266,0.9886248202238199
14,0.042237754016109234,98.85714285714286,0.9885305599416949,0.9885013899995954
15,0.04639434259628284,98.65714285714286,0.9864569113395876,0.9864429573150162
16,0.05018049618811347,98.64285714285714,0.9865132188181824,0.9861181940687989
17,0.048171726971155626,98.55714285714285,0.9855039940526874,0.9855282560703011
18,0.04881130518359979,98.61428571428571,0.986047879262831,0.9861948018373632

 Training with LR: 0.001, Batch Size: 64, Optimizer: Adam, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.10679734591394663,97.2,0.97227058719259,0.9716082471397183
2,0.07350893662395802,97.8142857142857,0.978357258110654,0.9778255702723404
3,0.06079632020978765,98.28571428571429,0.982937542394253,0.9825702703659465
4,0.052141447991810065,98.52857142857144,0.985274894798127,0.9851299497706453
5,0.05537459283897823,98.3,0.9831452432156631,0.9827501611256999
6,0.04948941264301539,98.42857142857143,0.9843133839579143,0.9841304137308878
7,0.053517992036755786,98.25714285714285,0.9825385794869469,0.9824657665547033
8,0.04840195096013221,98.41428571428571,0.9841410045809471,0.9839377076090035
9,0.0574255158923651,98.28571428571429,0.982737074797362,0.9828127795139487
10,0.04771158351584084,98.6,0.9859386493015915,0.9859003411747945
11,0.04959588208426298,98.5142857142857,0.9851886603306597,0.9849524905503767
12,0.04878321113064885,98.45714285714286,0.9844427560175241,0.984445418114079
13,0.04547527787720107,98.6,0.9858556057951466,0.9859164375045033
14,0.05248550717118302,98.41428571428571,0.984342680187131,0.9838752818171285
15,0.04452313184685243,98.67142857142858,0.9865664261211553,0.9865302037693506
16,0.05113148205405609,98.54285714285714,0.9853742376526471,0.9852404135131347
17,0.05439583200284026,98.4,0.984061108471771,0.983732100908447
18,0.04801734811791737,98.55714285714285,0.9855954875545265,0.9854004592641115
19,0.05508708382655062,98.57142857142858,0.9857299798687533,0.985467972339157
20,0.04867228108963569,98.75714285714285,0.9874594893066639,0.9874994795015993

 Training with LR: 0.001, Batch Size: 64, Optimizer: Adam, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.09891817185350439,97.55714285714285,0.9753210622146943,0.9755583893339022
2,0.06770187929187986,97.98571428571428,0.9800358886524846,0.9795284916288611
3,0.07099424247545275,97.84285714285714,0.9791919848170906,0.9780691111370207
4,0.052952169254422185,98.28571428571429,0.982893895849509,0.982591639030226
5,0.045385759069838306,98.64285714285714,0.9864536141574061,0.9863325040407578
6,0.05759418059606105,98.21428571428571,0.9823346127069781,0.9820285629385473
7,0.04792467383667827,98.52857142857144,0.985220478404177,0.9852573015514737
8,0.04244788818521721,98.81428571428572,0.9880696086487296,0.9881350516003143
9,0.042640556470459244,98.74285714285715,0.9874000451998418,0.9873573816485999
10,0.04137488198784095,98.78571428571429,0.9878170992399695,0.9877502558551873
11,0.04511463066023266,98.55714285714285,0.9855402804250968,0.9855117410108598
12,0.0392671721025677,98.81428571428572,0.9881483062441319,0.9880534855529703
13,0.048824997906657785,98.5142857142857,0.9851610393290633,0.9849900501514156
14,0.048834520047636366,98.62857142857143,0.9862853089228085,0.9860475916456499
15,0.05040516821847467,98.61428571428571,0.9862873884358226,0.9859372429397781
16,0.04972782502670518,98.57142857142858,0.9857204327511904,0.985620422936259
17,0.04778581588351782,98.7,0.9869912112048149,0.9868762859583127

 Training with LR: 0.001, Batch Size: 128, Optimizer: SGD, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,1.005884896625172,85.55714285714285,0.8601944240510301,0.8517101994011614
2,0.48811448975042865,91.71428571428571,0.9170115591989202,0.9158371032142958
3,0.33270485617897727,93.41428571428571,0.9349118040483848,0.9331029821152497
4,0.25858860422264446,94.87142857142857,0.9488466894063363,0.9482045446801592
5,0.2164742412892255,95.48571428571428,0.9548232746123432,0.9544438646574889
6,0.19015748256986792,95.84285714285714,0.9584930421201368,0.9579662339085342
7,0.1694154211065986,96.2,0.9618394927407656,0.9616794732877132
8,0.15566910871050574,96.35714285714285,0.9635286367223621,0.9632950045498727
9,0.1456805901771242,96.5,0.9649788288992301,0.9646813790575408
10,0.13574261570518667,96.67142857142858,0.9666674884940294,0.9665054286046765
11,0.12750064581632614,96.77142857142857,0.9676552671959499,0.967461972309794
12,0.12177206792614677,96.95714285714286,0.9695072607281693,0.9693547369615642
13,0.11543534939939326,97.05714285714285,0.9705193330191937,0.9703149554961412
14,0.11187918240373784,97.2,0.9718450457768736,0.9718133641379797
15,0.10711703733964399,97.28571428571429,0.9728021215329482,0.9726163832036588
16,0.10254438363692978,97.32857142857144,0.9732098365655558,0.9731060079435473
17,0.10031824782490731,97.3,0.9729054646838871,0.9728597029731869
18,0.0969088266518983,97.41428571428571,0.9739797935954858,0.9739681630305845
19,0.09509197886694562,97.45714285714286,0.9746030903762968,0.9743204020165704
20,0.09126452268524603,97.52857142857142,0.9752632133369433,0.974983183641261
21,0.08869596455584873,97.68571428571428,0.9767764400477195,0.9765921885469051
22,0.08713751807808875,97.78571428571429,0.9778836084722622,0.9776308760456093
23,0.08553673665631902,97.78571428571429,0.9778136550472606,0.9776304153337284
24,0.08332567743279717,97.78571428571429,0.9777933532359533,0.9776737797630709
25,0.08104985586621545,97.75714285714285,0.9775426061480331,0.9773528035882639
26,0.08059368614446033,97.82857142857144,0.9783904350927808,0.9780647552299712
27,0.07935811376029794,97.89999999999999,0.9790110212162716,0.9787505387987417
28,0.07689866481179541,97.97142857142858,0.9796137090477378,0.9795741784299203
29,0.07624572566287084,98.0,0.9799801624437148,0.9798098078741786
30,0.07591093304482373,97.98571428571428,0.9798015943539872,0.9797107803206204
31,0.07515905658629808,97.91428571428571,0.9790787383499984,0.9789623755088153
32,0.07200580875981938,98.1,0.9809826746803958,0.9807710164138275
33,0.07208487360992215,98.12857142857143,0.9812003249577778,0.981118076949725
34,0.07071896236051213,98.12857142857143,0.9812217887291668,0.9810790295823331
35,0.0695726662535559,98.14285714285714,0.9814138140684457,0.9812335864042959
36,0.06850230856375261,98.2,0.9819142054969244,0.9818009430392645
37,0.06983331634917042,98.11428571428571,0.9811758627351332,0.9809622603834948
38,0.06804968169467016,98.21428571428571,0.9820538860666128,0.9820009633857245
39,0.06713081500069662,98.15714285714286,0.9814610566969426,0.9814329624041097
40,0.06636920706792311,98.08571428571429,0.9809058125092124,0.9806345055169089
41,0.06676602803848007,98.2,0.982103928387555,0.9817574265007376
42,0.0645246047526598,98.2,0.9820096107718145,0.981812184894105
43,0.0644805735823783,98.2,0.9819888188250427,0.9818098385957473
44,0.06400712796232917,98.24285714285715,0.982427015698792,0.982276592307725
45,0.06340318864042109,98.2,0.9819761365567938,0.98184314561842
46,0.0625280412421985,98.32857142857144,0.9832187544879988,0.9831418979515412
47,0.06277724363925782,98.25714285714285,0.9825752156877743,0.9824220786610007
48,0.06204292990944602,98.2,0.9820048325527113,0.9818725716403304
49,0.06082140044732527,98.24285714285715,0.9824219378796041,0.9822773829464369
50,0.06057063876227899,98.3,0.9829039206936789,0.9828420485062423

 Training with LR: 0.001, Batch Size: 128, Optimizer: SGD, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.9201239715922963,87.7,0.8827763818700054,0.8739166774575562
2,0.45947762619365345,92.11428571428571,0.9218769117366705,0.9197087743971426
3,0.31830536804415965,93.88571428571429,0.9385784945290148,0.9381706562474447
4,0.25482464351437306,94.88571428571429,0.9486922584293435,0.948481715131065
5,0.2131334361704913,95.51428571428572,0.9549796512949028,0.9547631836595301
6,0.1899968915364959,95.82857142857144,0.9582954358257151,0.9580836413625198
7,0.16890785206447947,96.2,0.9619652387559677,0.9617524108308786
8,0.15466864989562468,96.47142857142858,0.964710315346551,0.9644052470974582
9,0.14395260580561378,96.74285714285715,0.9672638091925864,0.9672368864733745
10,0.1346842309968038,96.71428571428572,0.9669756607928521,0.9669150098904102
11,0.128126260638237,97.01428571428572,0.9701264749868223,0.9698854072031793
12,0.11919209970669313,97.14285714285714,0.9712666070515397,0.9712559061275927
13,0.11689557731151581,97.1,0.970939486136629,0.9708262967013137
14,0.10901293029839343,97.32857142857144,0.9731702385998784,0.973039844881755
15,0.10387355001135305,97.35714285714285,0.973416186238653,0.9733758187041637
16,0.10242042663422497,97.5,0.9748985836259019,0.9748016628029912
17,0.09825572005727075,97.61428571428571,0.9759989773643166,0.9760586830912347
18,0.09601469033143738,97.61428571428571,0.9760401676967405,0.9760293205007983
19,0.09114709706469015,97.78571428571429,0.977714374437517,0.9777196740984421
20,0.08912590003826401,97.82857142857144,0.9782808765748928,0.97802594887376
21,0.08795683593912558,97.87142857142858,0.9786827024857523,0.9785373828693343
22,0.08820363147692246,97.85714285714285,0.9784866599111796,0.9784525972276373
23,0.08399227207357234,97.89999999999999,0.9790094899361674,0.9788099346395436
24,0.08177474323998798,98.0142857142857,0.9801295364644446,0.9799584278945099
25,0.0791672057048841,98.11428571428571,0.9810477906195987,0.9810508850523488
26,0.07885261083191092,98.05714285714285,0.9806046015715537,0.9802591904787163
27,0.07634992108426311,98.12857142857143,0.9812092785990025,0.9811288455422948
28,0.07613281072540716,98.05714285714285,0.9804867794435476,0.9804426923984397
29,0.07663833868097175,98.05714285714285,0.9804176652307973,0.9804613867816151
30,0.07448494800112464,98.14285714285714,0.9812893455927533,0.9813242057523232
31,0.07226499197157947,98.14285714285714,0.9813183654162749,0.9813010853772285
32,0.07168668078427964,98.28571428571429,0.9827039074434911,0.9828280634198592
33,0.07091379135169766,98.2,0.9818655942933041,0.9819044413036156
34,0.06928533295338804,98.25714285714285,0.9824356154193632,0.9824736644266053
35,0.06789762269366871,98.25714285714285,0.9825639090053253,0.9824010004413157
36,0.06826627417044207,98.28571428571429,0.9827897928531453,0.9827204491498399
37,0.06857961084355008,98.24285714285715,0.9824325677612749,0.9822170699779893
38,0.06506471244448965,98.24285714285715,0.9824545206292523,0.9821800563057156
39,0.06447885771366683,98.35714285714286,0.9835204793598399,0.983512015124813
40,0.06588790643621575,98.3,0.9830045297479254,0.982767725439784
41,0.06349505223333836,98.35714285714286,0.9836153972500284,0.9833810729160024
42,0.06661489986899224,98.1,0.9809174939009786,0.9808907425516793
43,0.06234006079083139,98.37142857142858,0.9837927860656939,0.9834096498074368
44,0.06302154287695885,98.42857142857143,0.9842806868851692,0.9840944979674339
45,0.06265471198342064,98.38571428571429,0.9839024156220397,0.983676433365323
46,0.0617835765873844,98.5,0.9849171703358136,0.984936332492657
47,0.061634762517430566,98.32857142857144,0.9833338974099182,0.9831588676190611
48,0.06056994277645241,98.41428571428571,0.9840874957087806,0.9840432701742129
49,0.06071586432782086,98.35714285714286,0.9834807946143759,0.9835119080162892
50,0.058052364889193665,98.58571428571429,0.9857798486736915,0.9857648656559264

 Training with LR: 0.001, Batch Size: 128, Optimizer: SGD, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.7225071744485335,88.64285714285714,0.8878804675959037,0.8844868296951038
2,0.4001538379625841,92.85714285714286,0.9288269547754041,0.9278476573071466
3,0.28574874753301793,94.37142857142857,0.9434956973518288,0.9434300524283369
4,0.23028646301139485,95.25714285714287,0.9526862834142598,0.9521750113404277
5,0.19588887108997866,95.85714285714285,0.9583797400826727,0.9582602135883667
6,0.17260967344045638,96.15714285714286,0.9615272154336483,0.961273638651733
7,0.1559408103877848,96.38571428571429,0.9638481483097667,0.9636307862249615
8,0.1439076977697286,96.55714285714285,0.9655329959746967,0.9653839882202113
9,0.1356001462448727,96.72857142857143,0.9674036892178062,0.9670197341884794
10,0.1251829285513271,96.92857142857143,0.969278782718167,0.9691062680292866
11,0.11939627623016184,97.11428571428571,0.9710985855201061,0.9709010202749777
12,0.1141390705650503,97.08571428571429,0.9709614944666294,0.9705943510780868
13,0.10813786400990053,97.27142857142857,0.9727385593397821,0.9724358209217534
14,0.10368962755257433,97.38571428571429,0.9737222396397858,0.9736539681876353
15,0.10183154662901706,97.35714285714285,0.9735524346335405,0.9733526309885778
16,0.09678933708505197,97.44285714285714,0.9744647665851309,0.9741359941109098
17,0.09418325620618734,97.5142857142857,0.9750383452019464,0.9749840414726311
18,0.09201520403677767,97.6,0.9758773471274538,0.9757780202596917
19,0.08948685181411829,97.72857142857143,0.9773870863581926,0.9770096582448909
20,0.08715253601020033,97.67142857142858,0.9766422721420135,0.9765272859057076
21,0.0855543014678088,97.77142857142857,0.9777789789424229,0.977423300532967
22,0.08314119299704378,97.8,0.9780233932423341,0.9777122661219945
23,0.08217467015439814,97.92857142857143,0.9793345995864786,0.9789621123440208
24,0.08124594014476647,97.97142857142858,0.9797670477880487,0.9794750518041777
25,0.07922623672268607,98.02857142857142,0.98026854541084,0.9800412739145182
26,0.07770183482630687,97.97142857142858,0.9796599631184486,0.9794610382868629
27,0.0771853683008389,98.0142857142857,0.9802012406599564,0.9798938970748562
28,0.0756800352172418,97.98571428571428,0.9798151313631521,0.9796796792553583
29,0.07504447498782114,98.0142857142857,0.980126932750062,0.9799572029198813
30,0.07299766178158197,98.11428571428571,0.9811694022384643,0.9808871638299399
31,0.07320997593077747,98.02857142857142,0.980355144712901,0.980106924145919
32,0.07182259190488946,98.05714285714285,0.980590475312048,0.9803441551762058
33,0.07008087238804861,98.14285714285714,0.9814096252062298,0.9811984104525482
34,0.06991453262215311,98.17142857142858,0.9818446492017416,0.9814739976429021
35,0.06914403946562246,98.2,0.9820291709139612,0.9817139718813248
36,0.06772681701589714,98.18571428571428,0.9818146509212194,0.9816439316404736
37,0.06767231747508048,98.18571428571428,0.9818557552590631,0.9816500260640207
38,0.06767878335985271,98.27142857142857,0.982688930394087,0.9825404037389946
39,0.06638216383077881,98.31428571428572,0.9831272760301258,0.9830036338816687
40,0.06624143472449347,98.15714285714286,0.9815465283256952,0.9813971333679244
41,0.0650357148186727,98.22857142857143,0.9822370314843765,0.9820852479573716
42,0.06408856971697374,98.32857142857144,0.9832597108858936,0.98309487491368
43,0.06418160024014387,98.22857142857143,0.9822586103226897,0.982097729009574
44,0.06413028233430602,98.15714285714286,0.9815849675985321,0.9813986229347531
45,0.06367135488174179,98.25714285714285,0.9825998222848569,0.9823513186543196
46,0.06304140487177805,98.24285714285715,0.9824879768983019,0.9821541171310866
47,0.06299504285508936,98.28571428571429,0.9828413323938104,0.9827438504114607
48,0.06224626428024335,98.28571428571429,0.9828007117561015,0.9827539407745451
49,0.06180798370729793,98.25714285714285,0.9826455824541821,0.9823121820162243
50,0.06100840426304124,98.27142857142857,0.9827176420130843,0.9825437850441373

 Training with LR: 0.001, Batch Size: 128, Optimizer: Adam, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.14712666110558945,96.81428571428572,0.9683864465595395,0.9677502888593711
2,0.09358438768170096,97.5,0.975001287507569,0.9747764153458676
3,0.07041419432921843,98.08571428571429,0.9809973556573741,0.9805512201341287
4,0.061679144305261696,98.1,0.9811130607533449,0.9807871793353732
5,0.05874814120205966,98.34285714285714,0.9833742819617823,0.9831790355083758
6,0.04781911193647168,98.62857142857143,0.9862696238480814,0.9860880476941715
7,0.048187758553434504,98.58571428571429,0.9858884481322614,0.9855629085465244
8,0.04784836802123622,98.57142857142858,0.9855606709714777,0.9856761300233838
9,0.047754622013731436,98.64285714285714,0.9864416513467438,0.9861894350537781
10,0.04570339795371348,98.58571428571429,0.9857372533970885,0.9858665554604749
11,0.045119743726470256,98.6,0.9859559201576442,0.9858066281251834
12,0.042751973270523276,98.54285714285714,0.9854701493572072,0.9852689622643519
13,0.04373421655036509,98.67142857142858,0.9867085486850845,0.9865321655055892
14,0.04059458537958562,98.8,0.9879942984462522,0.9878497930724468
15,0.044198413017544555,98.72857142857143,0.9871803565571785,0.9871355133615486
16,0.05045473657929423,98.55714285714285,0.9856825868553102,0.9852692441594406
17,0.04462407372722572,98.68571428571428,0.9867483333359027,0.9867736862661693
18,0.04670948794280941,98.61428571428571,0.9861459755218369,0.9859114266458286
19,0.04802437281998044,98.67142857142858,0.9866294106292799,0.9865912533752009

 Training with LR: 0.001, Batch Size: 128, Optimizer: Adam, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.14334093603220852,96.82857142857144,0.9683506659422021,0.9681125219826587
2,0.08544576594775373,97.85714285714285,0.9787283604002359,0.9781845815631327
3,0.07187082293358717,97.98571428571428,0.979926326910561,0.9795005097204017
4,0.06798684112727642,98.12857142857143,0.9813974572229821,0.9812079258641877
5,0.05723242370242422,98.4,0.9839674574190745,0.9838303176199809
6,0.05405406921424649,98.31428571428572,0.9832524320482576,0.9828851267338905
7,0.05357345279136842,98.27142857142857,0.9827746817310592,0.9825996895752713
8,0.04932381476021626,98.45714285714286,0.9844866135834145,0.9844427867868347
9,0.0522954254665158,98.4,0.9840592033136103,0.9838322581498626
10,0.04917637152089314,98.5,0.9850804661984673,0.984770051274592
11,0.04419414529322901,98.74285714285715,0.9873687399168805,0.9872190616061879
12,0.04754516578872096,98.62857142857143,0.9862876036583603,0.9860783818607322
13,0.05727437309582125,98.27142857142857,0.9827736180982773,0.982517265951838
14,0.04754367907616225,98.65714285714286,0.9865355218158127,0.9863481654148369
15,0.050620604221793736,98.38571428571429,0.9839480249094867,0.9835141634604625
16,0.05278732666576451,98.31428571428572,0.9832697136916113,0.9829527432360428

 Training with LR: 0.001, Batch Size: 128, Optimizer: Adam, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.146081790598956,96.42857142857143,0.9643848848341706,0.9638191742824882
2,0.09270754591985182,97.45714285714286,0.9747828816602381,0.974089093072281
3,0.06990925026210872,98.04285714285714,0.9802954186503416,0.9802230426940763
4,0.060153787955641747,98.22857142857143,0.9822059485350529,0.9820585089079344
5,0.06229026381942359,98.34285714285714,0.9833277721988752,0.9834492438643687
6,0.05555326127531854,98.31428571428572,0.9831222471697737,0.9829955910374828
7,0.05166167693889954,98.54285714285714,0.985332919536898,0.9853515372265441
8,0.05991140725937757,98.04285714285714,0.9805148720015422,0.980413355841392
9,0.04634780032052235,98.54285714285714,0.985339599728286,0.9851692286660167
10,0.05059623894366351,98.52857142857144,0.9851618917193343,0.985207720648333
11,0.045898978733880956,98.64285714285714,0.986372490231086,0.9862481183037207
12,0.04582774049009789,98.74285714285715,0.9872104448407679,0.9874612906662732
13,0.0459543189287863,98.64285714285714,0.9862658595075737,0.9862736628408456
14,0.046745145748454064,98.65714285714286,0.9863924993388103,0.9864936012501337
15,0.04762533036991954,98.67142857142858,0.9865368772491498,0.9865948890113095
16,0.04837654988196763,98.58571428571429,0.9857809483535955,0.9857417309236043
17,0.05324928165752102,98.54285714285714,0.9852230806493815,0.9853914050630428

 Training with LR: 0.005, Batch Size: 32, Optimizer: SGD, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.10499302084349334,97.52857142857142,0.9751500287958905,0.9750710213425535
2,0.07725048780050044,97.89999999999999,0.9790160069354217,0.9788338194780202
3,0.0700126144754356,98.04285714285714,0.9806193335600378,0.9802993016754638
4,0.06265515251803853,98.2,0.9820026436071172,0.9818777928746829
5,0.05281385061539472,98.4857142857143,0.9848856619117328,0.9847090297301783
6,0.05204617715181281,98.52857142857144,0.9854100582054451,0.9850339673539368
7,0.047857960931676095,98.68571428571428,0.9868730882305752,0.986714164172275
8,0.04777665902885978,98.65714285714286,0.9866981561081009,0.9863583296490301
9,0.0458547614613701,98.64285714285714,0.9863160904790252,0.9863786854866013
10,0.04610751984352841,98.71428571428571,0.9871559819108452,0.9870360374681132
11,0.044618868630232726,98.62857142857143,0.9862220868573699,0.9862625665082498
12,0.048926199033652265,98.54285714285714,0.9855064395181904,0.985165640519621
13,0.045328310063825365,98.65714285714286,0.9865664190336061,0.9865212331775399
14,0.04416553909862712,98.65714285714286,0.986661410522977,0.9863276416128139
15,0.04381831232088907,98.72857142857143,0.9873611466504391,0.9871057391556637
16,0.04352721350002273,98.62857142857143,0.9861314255340499,0.986282833547089
17,0.0429655255555929,98.68571428571428,0.9867625000670088,0.9868815464001848
18,0.043444906712607236,98.67142857142858,0.986567460055063,0.9866840499441825
19,0.04325089661438246,98.7,0.9869790381593793,0.9869211701231627
20,0.0420733204336181,98.68571428571428,0.9867120655414962,0.9867983972383769
21,0.041178285046559,98.77142857142857,0.987697723481513,0.9876621662007935
22,0.04253541560243304,98.75714285714285,0.9876706146704786,0.9874359895020198
23,0.042578009275654936,98.72857142857143,0.9872229486440925,0.9872235889640029
24,0.042843903368790785,98.81428571428572,0.9881577775792174,0.988023793461456
25,0.04268817122903127,98.82857142857144,0.9882935158609906,0.9882195122904711
26,0.041939191158542506,98.82857142857144,0.9883208205066435,0.9881737243126404

 Training with LR: 0.005, Batch Size: 32, Optimizer: SGD, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.1085215104173988,97.28571428571429,0.9728430412566166,0.9726543849702004
2,0.07720837558483594,97.95714285714286,0.9795797518479896,0.9793815783577688
3,0.0649166701438084,98.12857142857143,0.9813105842797629,0.9810345291425454
4,0.06313369407097397,98.28571428571429,0.9829396544248075,0.9825889081063593
5,0.05447657337331439,98.54285714285714,0.9854536874950011,0.9851961846955308
6,0.054599474271393666,98.35714285714286,0.9836641937308703,0.9833624683832302
7,0.04998165805697586,98.67142857142858,0.9865966366251335,0.9865986304469713
8,0.049621661554609495,98.35714285714286,0.983574540703507,0.9834365792624606
9,0.05069721729965608,98.47142857142858,0.9847031888088414,0.9844747697242813
10,0.04756298867404061,98.6,0.9859223393174258,0.9859912454772981
11,0.045301369550323205,98.54285714285714,0.98549846042539,0.985254547366598
12,0.04843093167228165,98.52857142857144,0.9852278322989487,0.9851258737303634
13,0.04597523998411704,98.54285714285714,0.9853672583847939,0.9853308510019272
14,0.04624869206630025,98.61428571428571,0.9861238205139573,0.9860056763992725
15,0.047169853396927426,98.52857142857144,0.9852420048310014,0.9850972367418513
16,0.04868295513261981,98.58571428571429,0.985825572209975,0.9856561227044096

 Training with LR: 0.005, Batch Size: 32, Optimizer: SGD, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.11046051847233893,97.12857142857143,0.9716266207242967,0.9707042153676634
2,0.08334890936318462,97.71428571428571,0.9774689281357954,0.9768373075856926
3,0.06846495014806725,98.14285714285714,0.9814893727892405,0.9812742851850718
4,0.06081648498186714,98.3,0.9828010199330965,0.9829246598046929
5,0.05149521600650666,98.52857142857144,0.9851742065113995,0.9852241170802214
6,0.05330280568153006,98.4857142857143,0.9848239482425836,0.984683460863659
7,0.05232619429878958,98.4857142857143,0.9848902283692482,0.9846797500159161
8,0.04711762353029425,98.64285714285714,0.986494608010142,0.9862595657671577
9,0.05139629815499932,98.47142857142858,0.9847292115795593,0.9846424019497538
10,0.04630999440501644,98.58571428571429,0.985998593999585,0.9856362260170016
11,0.045598359433264304,98.71428571428571,0.9871854228586555,0.9870001481888208
12,0.049784002569397766,98.5,0.9850669840009252,0.984836160631595
13,0.046076592844411235,98.64285714285714,0.9864571301413779,0.9863435052749772
14,0.044541194546063,98.58571428571429,0.9858204241601494,0.9858495783332939
15,0.04881106163391027,98.54285714285714,0.9854042158133666,0.9853497881571787
16,0.04327709023502111,98.78571428571429,0.9879183657904191,0.9877373346704552
17,0.046200479593417144,98.67142857142858,0.9867146171168173,0.9865815164952586
18,0.043400902882751,98.71428571428571,0.9871433103783833,0.9871257954310808
19,0.04483233136330895,98.67142857142858,0.9867258459633698,0.9866057159221884
20,0.04467800421760945,98.68571428571428,0.9868632875287148,0.9867865543938927
21,0.04375125807481414,98.8,0.9879754652134365,0.987976661518388

 Training with LR: 0.005, Batch Size: 32, Optimizer: Adam, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.09038300650432433,97.14285714285714,0.9719499617877201,0.970995283892894
2,0.059686670552399096,97.97142857142858,0.9795192051763169,0.9796927766415674
3,0.04805390238975862,98.44285714285715,0.9843646640668016,0.9842598932011424
4,0.04834655020515553,98.81428571428572,0.9880724607725361,0.9879811400146071
5,0.048584943307209104,98.74285714285715,0.9873985876012487,0.9873030235698093
6,0.05293901449591456,98.57142857142858,0.9857713074764487,0.9855486639247287
7,0.04962739769559934,98.75714285714285,0.9873230680743262,0.987582278676532
8,0.05138723008490389,98.4857142857143,0.9846058027965648,0.9850014700327158

 Training with LR: 0.005, Batch Size: 32, Optimizer: Adam, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.07368142500128512,97.68571428571428,0.9770288827327166,0.9765922829346423
2,0.048905904327208795,98.5142857142857,0.9851326049512859,0.9849986337018555
3,0.04618818886561073,98.62857142857143,0.9862747907246433,0.9861995622305446
4,0.0667143043995246,98.02857142857142,0.9805832562277781,0.9800482620991101
5,0.055710068829642016,98.3,0.983229520667759,0.9828266306265995
6,0.04667671153530639,98.72857142857143,0.9871496263629498,0.9872397425922699
7,0.05448590360395358,98.44285714285715,0.9843058351916959,0.9842856832769081
8,0.051473868557894334,98.52857142857144,0.9853732565740332,0.9851929862806046

 Training with LR: 0.005, Batch Size: 32, Optimizer: Adam, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.06879391762498153,97.84285714285714,0.9786170823051569,0.9781927383059849
2,0.05880937730953561,98.32857142857144,0.9835277564745318,0.9829035744961632
3,0.062461263573777404,98.27142857142857,0.9828329580180851,0.9825982141947222
4,0.05262695570200199,98.42857142857143,0.9843419722922157,0.9840618427527316
5,0.05616108060169372,98.35714285714286,0.9838053447913575,0.9831662074498702
6,0.046706081682490026,98.64285714285714,0.9863301030940059,0.9862841589869429
7,0.057366717001233865,98.5142857142857,0.9853190428324089,0.9848617632642632
8,0.05232231695305375,98.5142857142857,0.985183157546326,0.9849551106286791
9,0.05510335888629509,98.7,0.986925201242056,0.9869179252988765
10,0.05753056876385025,98.47142857142858,0.9845243923899926,0.9846776877153511
11,0.05774841566439069,98.57142857142858,0.9857943185212289,0.9854679054473117

 Training with LR: 0.005, Batch Size: 64, Optimizer: SGD, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.14345201220024717,96.71428571428572,0.9670701869751872,0.9668535196251387
2,0.09830895652147857,97.45714285714286,0.9746349761910867,0.9743963091865713
3,0.0837311247533018,97.62857142857143,0.9763607480534775,0.9761207623199597
4,0.06848517922176556,98.24285714285715,0.9822717456475782,0.9824170031496233
5,0.0649534342979843,98.17142857142858,0.9817074461986046,0.9815810859024705
6,0.05848856509070505,98.47142857142858,0.9846370083694274,0.9845716487919682
7,0.05733247549188408,98.35714285714286,0.983543006043857,0.983439520412373
8,0.0540380505209958,98.54285714285714,0.9853882069133,0.9853535659636943
9,0.0526529224483635,98.42857142857143,0.9841362236160563,0.9841827249355021
10,0.05109820601699704,98.42857142857143,0.9842434776619482,0.9841065837892818
11,0.05024432766420597,98.45714285714286,0.9844120899627574,0.9845774888318315
12,0.04795511001721024,98.58571428571429,0.9858692701080939,0.9857048494109671
13,0.048887304902415385,98.61428571428571,0.9861438099056039,0.9859894874672465
14,0.04725019551432607,98.55714285714285,0.9854305293579563,0.985502263832457
15,0.044982818713073025,98.71428571428571,0.9870173472906225,0.9870978312819677
16,0.04607794858853925,98.64285714285714,0.9863583164635357,0.9863557892670262
17,0.043957947732203385,98.67142857142858,0.9866136576929394,0.9866471381109101
18,0.04412602571855215,98.6,0.9858481458593346,0.9859333630834897
19,0.04568891001928767,98.58571428571429,0.9857843531420374,0.9858620785069517
20,0.043059799676253036,98.7,0.9869528942902844,0.9869089552386054
21,0.04603809646161443,98.61428571428571,0.9859329333054141,0.9860706865838532
22,0.043302745749877594,98.68571428571428,0.9866622880261826,0.9867528136678902
23,0.04321362431457436,98.72857142857143,0.9872748952096286,0.9870921690572729
24,0.04286814853972332,98.68571428571428,0.98666742451512,0.9867956704238197
25,0.04297902607570656,98.71428571428571,0.9870433676295333,0.9870401854678725
26,0.04293725591004741,98.71428571428571,0.9871448423766183,0.9869880805106774
27,0.04590129376050423,98.62857142857143,0.9861270861469833,0.9862311804709272
28,0.04359786938770081,98.58571428571429,0.9858132983114041,0.98573701101964
29,0.04366574633273889,98.65714285714286,0.9864270912262467,0.9864501259548379

 Training with LR: 0.005, Batch Size: 64, Optimizer: SGD, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.15286637202582576,96.34285714285714,0.9636342404184968,0.963210932167114
2,0.09405452324585481,97.72857142857143,0.9772832513858558,0.9770324662321492
3,0.07637499161064625,98.05714285714285,0.9805971428688987,0.9803942584372596
4,0.07513002148744735,97.87142857142858,0.9789670737689928,0.9783997126903967
5,0.06097148708491163,98.28571428571429,0.9829189398831174,0.9826715895300113
6,0.059600177094001665,98.28571428571429,0.9830616341694001,0.9825700438308642
7,0.0564835622060028,98.31428571428572,0.9831446100293469,0.9829977871080992
8,0.0530818727248433,98.44285714285715,0.9843351662069668,0.9843685694714654
9,0.054274575488472525,98.52857142857144,0.9853028353372087,0.9851098218079726
10,0.04982828328131952,98.6,0.9858815007762696,0.9859315285004815
11,0.04820067236538638,98.64285714285714,0.9864323240434725,0.9862360246706391
12,0.04824077336498621,98.62857142857143,0.9863841138411003,0.9861195201480248
13,0.04765218638349324,98.67142857142858,0.9866629735871004,0.9866462976078532
14,0.045398633935573425,98.65714285714286,0.9865705993142739,0.9864211091833497
15,0.04599584295753051,98.68571428571428,0.9868196930525966,0.9867664944770679
16,0.044914811606180265,98.67142857142858,0.9866851712664557,0.9865890405217513
17,0.044041738377630035,98.65714285714286,0.9866102119946893,0.9864647131630437
18,0.04356562866702337,98.75714285714285,0.9874990614520935,0.9874930728986371
19,0.0442183251238682,98.58571428571429,0.9858475434400479,0.9857486001229953
20,0.04347862393637611,98.77142857142857,0.987752149504922,0.9875969956662047
21,0.04431146838575263,98.78571428571429,0.9876718976797706,0.9878398340109525
22,0.043271995839578185,98.62857142857143,0.9862191153094226,0.9861577238845698
23,0.043980708045207643,98.7,0.9868978966058106,0.9869309467502708
24,0.0446826462041248,98.58571428571429,0.9856878748310512,0.9857893196252142
25,0.0448174393333664,98.64285714285714,0.9862298619988138,0.9864098734585423
26,0.04345078314231201,98.57142857142858,0.9854899074603543,0.9856361076632009
27,0.04257911145581271,98.8,0.9878866135739143,0.9879132529365803
28,0.042948021916460924,98.65714285714286,0.9865280041039901,0.9864185829906973
29,0.043610273861982435,98.67142857142858,0.9867539672801231,0.9865259208368184
30,0.042735836817882955,98.74285714285715,0.9873595661981451,0.9874034931063089
31,0.04284538348438218,98.67142857142858,0.9866934441513372,0.9865766078020293
32,0.04313514641570774,98.71428571428571,0.9870444519411136,0.9870611498261022

 Training with LR: 0.005, Batch Size: 64, Optimizer: SGD, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.14922096641226248,96.45714285714286,0.9645721223693735,0.9643704006727711
2,0.10209056711332365,97.37142857142858,0.9738726143107911,0.9734191230899925
3,0.08512298864397136,97.85714285714285,0.9784987355620076,0.9784225569729355
4,0.07554311153732918,97.98571428571428,0.9797720917075707,0.9797728844490937
5,0.0656118912537667,98.25714285714285,0.9824704117084554,0.9825420370434375
6,0.0646255309524184,98.17142857142858,0.9818129715239643,0.9814762366742288
7,0.06056049132126976,98.3,0.9828562377086524,0.9829964948639521
8,0.05777498181401328,98.3,0.9831363949066644,0.982791453760008
9,0.05963651291518049,98.24285714285715,0.9824613577300474,0.9823490034771334
10,0.05984253319911659,98.3,0.9831050841115324,0.9827716984403521
11,0.05463067555630749,98.32857142857144,0.9832367880996898,0.9832180454526416
12,0.05135555880736898,98.5142857142857,0.985037728789124,0.9850212772260954
13,0.05462589313022115,98.42857142857143,0.9843260648962693,0.9840374952904678
14,0.05177027117037638,98.5,0.9849840274096927,0.9848538181207289
15,0.05115355030972172,98.38571428571429,0.9837928024980215,0.9837630763759044
16,0.05095437816555866,98.5,0.9849549468416601,0.9848824153439837
17,0.05325377948412841,98.52857142857144,0.9853220753805119,0.9851807526797437
18,0.049069219687953594,98.57142857142858,0.9857120849553432,0.9855558048698916
19,0.050785256922245024,98.44285714285715,0.9842887626954097,0.9844645341211316
20,0.05015562668612057,98.5142857142857,0.985005628883853,0.9850486991986578
21,0.04946673881812868,98.5142857142857,0.985032916818805,0.9850635947767904
22,0.04885117860341614,98.58571428571429,0.9857855898987784,0.9857714182544506
23,0.04746165081160143,98.57142857142858,0.9856355180688563,0.9855874835162372
24,0.05092511412433603,98.44285714285715,0.9842993949809908,0.9843477682059714
25,0.049703656646042045,98.5142857142857,0.9851715026169934,0.9849113012039934
26,0.050370641953354195,98.5,0.9850058596783924,0.9847197109814511
27,0.05456001792759211,98.32857142857144,0.9832529984126259,0.9830943632537714
28,0.049682786159048024,98.58571428571429,0.9858143138622879,0.9857039279912932

 Training with LR: 0.005, Batch Size: 64, Optimizer: Adam, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.07770775925706733,97.8142857142857,0.9783938001525545,0.9778402344390573
2,0.04560853617943146,98.45714285714286,0.9844735734486617,0.9845300789801215
3,0.057992798542942516,98.31428571428572,0.9833460826754861,0.9828934396297063
4,0.04951673037563027,98.42857142857143,0.9841573434094262,0.9841015082482937
5,0.04896363166811749,98.62857142857143,0.986320311029521,0.9861105177864896
6,0.06678932874082504,98.02857142857142,0.9807998313990522,0.9800614464729254
7,0.05317390563273379,98.52857142857144,0.9852179010370594,0.985302430986575

 Training with LR: 0.005, Batch Size: 64, Optimizer: Adam, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.0715914019129493,97.75714285714285,0.9774585042552129,0.9775466553403263
2,0.05904428229286251,98.25714285714285,0.9826547373761951,0.982434904475378
3,0.053540602975143965,98.41428571428571,0.9840082077406118,0.984132992415032
4,0.04701767266643318,98.52857142857144,0.9852154942552959,0.9851600022894619
5,0.05672170158835466,98.24285714285715,0.9828980358415009,0.9821848833221661
6,0.044749534211058,98.55714285714285,0.9854297456051896,0.985548426544268
7,0.05495861018584533,98.34285714285714,0.9836711739064224,0.9831030494616894
8,0.04815966700552963,98.67142857142858,0.9866470635325492,0.9866812488207696
9,0.05638053986582566,98.38571428571429,0.9837572958542988,0.9839309689945954
10,0.06119098805277397,98.27142857142857,0.9825537066030984,0.9829034164353327
11,0.05405992237858961,98.71428571428571,0.9869438227250111,0.9872041221591804

 Training with LR: 0.005, Batch Size: 64, Optimizer: Adam, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.07031970444050702,97.87142857142858,0.9791131887460601,0.978553259011103
2,0.058553273700685665,98.27142857142857,0.9825902579603829,0.982656483059088
3,0.0680882493076338,98.05714285714285,0.9809230618625134,0.9801519083969744
4,0.05467927470083602,98.41428571428571,0.983931096239677,0.9840925892725304
5,0.056884098186326976,98.38571428571429,0.9839272971269775,0.9836535236874685
6,0.05324026755194857,98.61428571428571,0.9859611204127339,0.9860868149435408
7,0.05371025150684132,98.5,0.9848231215268376,0.9849993163510943
8,0.059504284254150906,98.52857142857144,0.9852411013858344,0.9853258451829732
9,0.06793567190920426,98.35714285714286,0.9834087519701147,0.9835932109041206
10,0.05371872588055505,98.6,0.9858421965321009,0.986029055227136
11,0.05564147271546641,98.62857142857143,0.9862536294394992,0.9860979672642326

 Training with LR: 0.005, Batch Size: 128, Optimizer: SGD, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.2317373982884667,95.05714285714286,0.9503022154834078,0.9499480459666515
2,0.14590928744186055,96.28571428571429,0.962664367792845,0.962512614832993
3,0.11135225756601853,97.07142857142857,0.9705200342113505,0.9703729153366307
4,0.09842945567586205,97.52857142857142,0.9753013222972718,0.9749352539700034
5,0.08820848878134381,97.65714285714286,0.976739327501664,0.9761451582479392
6,0.08390519659627568,97.58571428571429,0.9758553428976487,0.9756389367315528
7,0.07293530543419448,97.95714285714286,0.979615255321794,0.9793053804523835
8,0.07093241709199818,98.18571428571428,0.9818929628644467,0.9815162848112011
9,0.0673220412636345,98.12857142857143,0.9812099370286008,0.981051120168958
10,0.07581679925999858,97.85714285714285,0.9787168867130347,0.9783871423702303
11,0.06113292842426083,98.22857142857143,0.98233957892814,0.9820587180279446
12,0.060734924403103914,98.35714285714286,0.9837469163210297,0.9833022379244291
13,0.06079672991552136,98.2,0.9818309950554449,0.9819472373358202
14,0.06504443010145967,98.15714285714286,0.9819018849841885,0.9811577348064737
15,0.058430790528655054,98.18571428571428,0.9818599739173479,0.9817033643762032
16,0.0599338427524675,98.21428571428571,0.9821153688956226,0.9819865771464984
17,0.05420562093230811,98.47142857142858,0.9845414161833561,0.984622017875554
18,0.05527998984537341,98.47142857142858,0.9846634435032575,0.9845141095839013
19,0.05769869363443418,98.25714285714285,0.9825925304155282,0.9824855363247116
20,0.06171565697613088,98.11428571428571,0.9816303542210878,0.9807620885628273
21,0.05272238069975918,98.54285714285714,0.9853520469266319,0.9852394496885817
22,0.05184126470915296,98.41428571428571,0.9840837404219112,0.9839645186863468
23,0.05106006247753447,98.62857142857143,0.9861890476266403,0.9861648260131229
24,0.05183499155735428,98.54285714285714,0.9853110363818786,0.9852227301018441
25,0.04984817912124775,98.61428571428571,0.9860942063432929,0.9859525938860308
26,0.05089866908436472,98.54285714285714,0.9854379076881443,0.9852729622010219
27,0.050991206108169124,98.52857142857144,0.9851297127545525,0.9851425394620893
28,0.05454443251206116,98.38571428571429,0.984098918721312,0.9835021801875239
29,0.053395622308281335,98.4857142857143,0.9847408652942107,0.9847303832451754
30,0.049497226337817585,98.5142857142857,0.9850695429613697,0.9850027878087937
31,0.04904694520783695,98.54285714285714,0.9852761675557797,0.9852223119078338
32,0.050750026462430306,98.41428571428571,0.9840553901966593,0.9839335908560569
33,0.049690531228076325,98.55714285714285,0.9855194385902921,0.9853818463761426
34,0.052076678731563415,98.5,0.985050722780335,0.9848038486904936
35,0.04906974424692717,98.61428571428571,0.9861409949238477,0.985960655652125
36,0.05036702161993493,98.52857142857144,0.9851877344154849,0.9851000753557511

 Training with LR: 0.005, Batch Size: 128, Optimizer: SGD, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.2308899608525363,94.85714285714286,0.9487785069603263,0.94776768664077
2,0.14400003918192603,96.6,0.965793135698428,0.9655653185975138
3,0.11428680223497477,97.07142857142857,0.9705066372321586,0.9704009242619633
4,0.09684501019391147,97.64285714285714,0.976350260588403,0.9760530964062408
5,0.08579231229695407,97.7,0.9769464758001393,0.97670020067885
6,0.08277178020639853,97.82857142857144,0.9782713885658811,0.9781261808473086
7,0.0745560870590535,97.89999999999999,0.9790340095851002,0.9785186247113378
8,0.0705764699388634,98.07142857142857,0.9807248104185525,0.9804256647519963
9,0.06886712932451204,98.21428571428571,0.9822216448095394,0.9819014178449734
10,0.06332748694853349,98.07142857142857,0.9806262261173366,0.9805096878703203
11,0.0608978541737253,98.14285714285714,0.9814537339643105,0.9810848575326135
12,0.05750986940481446,98.38571428571429,0.983788930671969,0.983648114694615
13,0.05495524066077037,98.32857142857144,0.9832042786875629,0.9830962156752122
14,0.05394227999177846,98.28571428571429,0.9828608697275067,0.9824909430894782
15,0.05556354443119331,98.22857142857143,0.9822172596937463,0.9820591935934843
16,0.05240162677046928,98.37142857142858,0.9837379325463816,0.9835463052364505
17,0.05119566937739199,98.31428571428572,0.983193744661512,0.9829814780773829
18,0.05388068787076256,98.32857142857144,0.9834033110365251,0.9830959096006706
19,0.05088927767832171,98.45714285714286,0.9846128217500176,0.984412630704603
20,0.04729191442443566,98.44285714285715,0.9843666543517061,0.9842302411423187
21,0.0479981774633581,98.4857142857143,0.9847502100568978,0.9847772559103583
22,0.048446036138656466,98.55714285714285,0.9855403708138304,0.9854858855486122
23,0.048724463649771434,98.52857142857144,0.9852714211833294,0.9850544136220879
24,0.04543099370361729,98.67142857142858,0.9866706641164467,0.9866216555773211
25,0.046243017065254126,98.7,0.986977198211003,0.9869052576334596
26,0.04680418336594647,98.57142857142858,0.985768254870014,0.985533338032863
27,0.0448978794569319,98.6,0.9859632928775774,0.9857345280529713
28,0.045123840716074816,98.62857142857143,0.986226046802909,0.986120803398094
29,0.04695925868370316,98.57142857142858,0.9856332402066131,0.9857131639522272
30,0.04666690169410272,98.6,0.9859582961627538,0.9859786202836794
31,0.04847942099652507,98.4857142857143,0.9849067176689943,0.9846472215002814
32,0.044326852228153836,98.7,0.9869064966687737,0.9869269779450885
33,0.04578624967147003,98.57142857142858,0.9856618876418031,0.9856377181385515
34,0.043305063916539606,98.71428571428571,0.987099801289766,0.9870034980896856
35,0.0434720164926892,98.67142857142858,0.9866448859260946,0.986581954013231
36,0.049658566239205275,98.34285714285714,0.9834313493135122,0.9833309983483982
37,0.043655656879259784,98.58571428571429,0.9858455801661121,0.9857467839758156
38,0.04708082780919292,98.41428571428571,0.9842763601871425,0.9838765160713365
39,0.04385447788306258,98.61428571428571,0.9860595647773577,0.9860293669861069

 Training with LR: 0.005, Batch Size: 128, Optimizer: SGD, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.21435184451666744,95.39999999999999,0.9539426264909174,0.9534277259113031
2,0.1434637358242815,96.65714285714286,0.9668365191367675,0.9660218122177792
3,0.10799326957626776,97.25714285714285,0.9723286075381615,0.9723866023211958
4,0.09262342019514604,97.75714285714285,0.9772662193496782,0.9775969042118733
5,0.08401105803522196,97.92857142857143,0.9789873067116204,0.9793140345295142
6,0.07396440248597752,98.0,0.9798295192108171,0.979809541868218
7,0.06968911964107644,98.05714285714285,0.9803241889970391,0.9804302995529873
8,0.06848251433535056,98.12857142857143,0.9810685969048165,0.9812609791454842
9,0.06307439350269058,98.35714285714286,0.983371562429203,0.9834590044990389
10,0.05973957624625076,98.34285714285714,0.9833126613232306,0.9832771541505971
11,0.059187074649063025,98.21428571428571,0.9819721573109099,0.9820083815507171
12,0.054518829895691436,98.44285714285715,0.9842337760399875,0.9842559634286561
13,0.054743526452644305,98.31428571428572,0.9830699377674369,0.9829885134730049
14,0.05173314577815208,98.57142857142858,0.9855839398665175,0.9855288853343197
15,0.05128251370042562,98.58571428571429,0.9857095644547588,0.985729939129319
16,0.04929392205720598,98.57142857142858,0.9855839722477093,0.9855337937212403
17,0.048488685200837524,98.6,0.9859716100315878,0.9858098132665741
18,0.048708700625733896,98.52857142857144,0.9851617020465643,0.9851973465397144
19,0.046200504306365145,98.65714285714286,0.9864465220417351,0.9864077947138451
20,0.0463121225041422,98.62857142857143,0.9862923307764143,0.9860824973947976
21,0.049018068764020095,98.54285714285714,0.9853129894556313,0.9852930140190148
22,0.04587340363386003,98.68571428571428,0.9868378722828309,0.9866456553987497
23,0.045972160614010965,98.58571428571429,0.9857937180274146,0.9856948738508219
24,0.04386670596220277,98.77142857142857,0.9876611004144575,0.9875585169563106
25,0.042283902799879966,98.71428571428571,0.9869865898770518,0.986994920379171
26,0.04287427570670843,98.6,0.9858663786407472,0.9858979241901865
27,0.04440649918873202,98.67142857142858,0.9865603578851113,0.9866226617827852
28,0.041700815739618105,98.8,0.9878930122999048,0.9878261683308697
29,0.044086831681091676,98.7,0.9868102726534431,0.9869439723709631
30,0.04339481374587525,98.68571428571428,0.9867421008220377,0.9867510222402055
31,0.04073342182250186,98.8,0.98791621596536,0.9877982671564679
32,0.042876751754771576,98.7,0.9868078872405984,0.9868885620235159
33,0.045706716848706655,98.58571428571429,0.9858644195979152,0.9856091654571909
34,0.04075984486632726,98.77142857142857,0.987603984923721,0.9875694329567002
35,0.04496270692907274,98.57142857142858,0.9855325719713836,0.985641571849721
36,0.04464517134157094,98.64285714285714,0.9863574221931947,0.9864138833500469

 Training with LR: 0.005, Batch Size: 128, Optimizer: Adam, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.07228492749008265,97.8142857142857,0.9781041204550093,0.9780218630706532
2,0.06012244122949514,98.24285714285715,0.9827630535213234,0.9821338561996356
3,0.05106238527223468,98.55714285714285,0.9856724504626,0.9853717648316789
4,0.04679763232865794,98.67142857142858,0.9866342824607548,0.9865460468050504
5,0.05255790077657862,98.61428571428571,0.9862897219232114,0.9858171075849047
6,0.04919415118003433,98.47142857142858,0.9845644786381325,0.9846219022921584
7,0.056637161720374765,98.37142857142858,0.9839174201380743,0.9834961210394233
8,0.050732817441563716,98.65714285714286,0.9863631606225253,0.986601296377599
9,0.0477230904369869,98.81428571428572,0.9881150988675531,0.9879754211750171

 Training with LR: 0.005, Batch Size: 128, Optimizer: Adam, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.07978841462595897,97.54285714285714,0.9757996596300655,0.9749520435852992
2,0.06289801550182429,98.12857142857143,0.9816605728920489,0.9807623644037538
3,0.04845251659439369,98.55714285714285,0.9854588180934881,0.985479368099235
4,0.051446313173933465,98.4,0.9839676720921677,0.9838631349287293
5,0.046782935910265555,98.61428571428571,0.9862132371649223,0.9859994042885246
6,0.046497969295490875,98.61428571428571,0.9861951888687777,0.9860034941941034
7,0.045191249666227534,98.61428571428571,0.986239104827578,0.9858519027561717
8,0.05266528287479146,98.44285714285715,0.9845205725480597,0.9839908285676671
9,0.05037305956621739,98.6,0.9862510576959144,0.985714093908635
10,0.046155622019432484,98.71428571428571,0.987062733483578,0.9869905765823928
11,0.05237109784290872,98.55714285714285,0.9857406811975661,0.9853011694926689
12,0.051095726844769984,98.54285714285714,0.985191029083295,0.9854707646647419

 Training with LR: 0.005, Batch Size: 128, Optimizer: Adam, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.08909465406428684,97.45714285714286,0.9750252440998564,0.9740999410244753
2,0.06448411806063219,98.2,0.981947385133054,0.9820110316362678
3,0.05134307643906637,98.58571428571429,0.9858277052906395,0.985739405866531
4,0.04907983023334633,98.74285714285715,0.9875416321622318,0.9872119651281401
5,0.04920937314798886,98.52857142857144,0.985316024787499,0.9851970668332898
6,0.05937043375081637,98.18571428571428,0.9819924538409845,0.9815569754257387
7,0.056786779500544074,98.31428571428572,0.9831250605567243,0.9832824880768604
8,0.052020581754517146,98.64285714285714,0.986575783776454,0.9861713193169317
9,0.05513877226039767,98.6,0.9859498527098183,0.9859372463100605

 Training with LR: 0.01, Batch Size: 32, Optimizer: SGD, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.09395559581600504,97.3,0.9729704817822105,0.9729467151441245
2,0.0703816007690921,97.94285714285714,0.9791703283334112,0.9793757616947696
3,0.06910846836771391,98.1,0.9811416760342148,0.9806886121827805
4,0.05507653309128005,98.31428571428572,0.9830671460530459,0.983040585312739
5,0.05493552060627706,98.47142857142858,0.9847922483159444,0.9845666925542608
6,0.05011530661132595,98.64285714285714,0.9863354841240641,0.986380481958706
7,0.05953395104760806,98.21428571428571,0.9825965456682642,0.9816918343253874
8,0.046905469322113584,98.52857142857144,0.9851773226672427,0.9851454118976302
9,0.048581789276928355,98.6,0.9858418416030131,0.9859224391200685
10,0.0513952462580459,98.6,0.9860872786406951,0.9857628889054073
11,0.0477616890418911,98.64285714285714,0.9862513400715274,0.9863710387737399
12,0.04809213769692581,98.65714285714286,0.9864096290310534,0.9865430999787627
13,0.04848904693180594,98.62857142857143,0.9861255741647235,0.9861976549442171

 Training with LR: 0.01, Batch Size: 32, Optimizer: SGD, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.09493457897434428,97.22857142857143,0.9724170619278241,0.9719720335076193
2,0.06332359858363289,98.15714285714286,0.9815039357540847,0.9813565617039129
3,0.06066908151630023,98.27142857142857,0.9827635814858043,0.9825086886569097
4,0.05463511861550311,98.38571428571429,0.9838326093531808,0.9837530253153528
5,0.05148918724504031,98.45714285714286,0.984463607387924,0.9843895550518311
6,0.05047397838919275,98.45714285714286,0.9847100218001522,0.9843458584495052
7,0.05020928651851402,98.58571428571429,0.985908385759928,0.9855461449141714
8,0.04739321266395597,98.58571428571429,0.9856245932603447,0.9858171789609746
9,0.046851392066452786,98.4857142857143,0.9846639599239936,0.9847894561208108
10,0.05063601524263969,98.44285714285715,0.9842883830865651,0.9843344469875938
11,0.049012916181348135,98.6,0.9858882528444166,0.9858632785352913
12,0.05217905144486789,98.4857142857143,0.9848948680372522,0.9845626722581745
13,0.05446654043987512,98.38571428571429,0.9838021672014529,0.9837092126277707
14,0.050208407064347496,98.42857142857143,0.984124582687674,0.9841829714263483

 Training with LR: 0.01, Batch Size: 32, Optimizer: SGD, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.08539776457261004,97.52857142857142,0.9751595200232821,0.9750529118974713
2,0.06683798136878503,98.1,0.981171074080528,0.9808203469464918
3,0.06288353331306243,98.17142857142858,0.9817206501587457,0.9815144088311294
4,0.05356214419390037,98.57142857142858,0.985679040827715,0.9855652596047919
5,0.05773071818543836,98.38571428571429,0.9837773969945334,0.9839260742450042
6,0.04973498602093678,98.6,0.9859812685529207,0.9859168204437317
7,0.053020780528130085,98.5,0.9848405197971319,0.9849550390994823
8,0.05016498014699778,98.45714285714286,0.9844333420873891,0.9844307315407615
9,0.04760342896195686,98.82857142857144,0.9883626980118059,0.9881380512312038
10,0.04740248687847594,98.77142857142857,0.9876717782987348,0.9876360284286083
11,0.04951958618993014,98.64285714285714,0.9864681970618359,0.9863647519856491
12,0.048964515829883565,98.52857142857144,0.9851645875031894,0.9851705221017418
13,0.05021738462847393,98.71428571428571,0.9871593741955553,0.9870480686955798
14,0.04906438487855937,98.75714285714285,0.9875154997581449,0.9874554262527319
15,0.048442090398329786,98.7,0.9868930985617409,0.9869613321481718

 Training with LR: 0.01, Batch Size: 32, Optimizer: Adam, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.07110575210254164,97.72857142857143,0.9771196424963321,0.977344323151349
2,0.0626874643677769,98.18571428571428,0.9814777911983036,0.9819968517770554
3,0.06949252709634729,97.98571428571428,0.9800223618258013,0.979681407387902
4,0.05748722649505787,98.31428571428572,0.9832663612515601,0.9830240416297518
5,0.06969957039129365,98.05714285714285,0.980305086287073,0.9808788284082283
6,0.05361723864295432,98.6,0.9860038960916129,0.9857790245625282
7,0.05468915116751421,98.5142857142857,0.9850952610313263,0.9851468359920486
8,0.06349758112308702,98.37142857142858,0.983859255945372,0.9833266914280326
9,0.07287458959201693,98.18571428571428,0.9816750689749714,0.9818674643767806
10,0.0758229378590854,98.44285714285715,0.9843799977402343,0.9843908373285226
11,0.06949822722228292,98.62857142857143,0.9861609449640782,0.9863068233501935

 Training with LR: 0.01, Batch Size: 32, Optimizer: Adam, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.09823291139787735,97.08571428571429,0.9714704851836226,0.97003949490728
2,0.0640148664678481,98.0142857142857,0.9803251445086689,0.9796841227774665
3,0.08323718235760472,97.61428571428571,0.9764902085221209,0.9758134899235549
4,0.08046070224492274,97.58571428571429,0.9771242164487972,0.9752754486267019
5,0.06227854946078031,98.32857142857144,0.9833730251912142,0.9831554394953643
6,0.059695230583671204,98.44285714285715,0.984494585266885,0.9841816830709839
7,0.0690700779178275,98.18571428571428,0.9817161048520673,0.9817768476091734
8,0.06728477697235169,98.38571428571429,0.9838586713294003,0.9836856895047996
9,0.06966753031316562,98.5142857142857,0.9852080354279747,0.9849664428275962
10,0.07062785593420003,98.4857142857143,0.9849258174049835,0.9846232288246043
11,0.07294849937403283,98.47142857142858,0.9847779395403407,0.9844850472527774

 Training with LR: 0.01, Batch Size: 32, Optimizer: Adam, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.06705179768316788,98.08571428571429,0.9811748702914038,0.9806296979944642
2,0.08764601633543803,97.01428571428572,0.9707660263903959,0.9701699503629377
3,0.062266878204815704,98.08571428571429,0.9807114745189516,0.9809704404650941
4,0.05282981593133781,98.52857142857144,0.9853409631253559,0.9849202601208678
5,0.06251102257255875,98.28571428571429,0.9828930273725213,0.9829542979105057
6,0.06041012259705911,98.45714285714286,0.9844528187161157,0.9844884514472559
7,0.059085571743653996,98.47142857142858,0.9846664044217309,0.9847058650106625
8,0.06629332068092215,98.38571428571429,0.9840526492063042,0.9836579753636313
9,0.07595052830048048,98.15714285714286,0.9818190137106078,0.9814465786107653

 Training with LR: 0.01, Batch Size: 64, Optimizer: SGD, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.10963192704049024,97.14285714285714,0.9714098872315897,0.9710926800605589
2,0.08393007657406006,97.68571428571428,0.9773013600845865,0.9763547385193633
3,0.06858145447278564,97.88571428571429,0.97887917269459,0.9787422077067565
4,0.058572251688350334,98.38571428571429,0.9842045854529642,0.9834402090223271
5,0.05309431083309887,98.41428571428571,0.9840616529966132,0.9840506666166483
6,0.050220382454889745,98.55714285714285,0.9856779488273218,0.9853548946820968
7,0.047390578424727374,98.62857142857143,0.9863038982349057,0.9861374648942419
8,0.04739345345773142,98.71428571428571,0.9871082228400152,0.987057966476392
9,0.0477583381283859,98.47142857142858,0.9848973046650169,0.9844242943298269
10,0.044447298923676666,98.71428571428571,0.9870993172253069,0.9870531445332429
11,0.04629528407769447,98.57142857142858,0.9857443890220576,0.9855505601685618
12,0.041746368468739095,98.74285714285715,0.9873683261895314,0.987340339805099
13,0.04406572858146815,98.74285714285715,0.9873646118663434,0.9873987928163261
14,0.04228945203887468,98.78571428571429,0.9878137076550327,0.9877590140937318
15,0.04193268616535616,98.78571428571429,0.9878347619935341,0.9877073359134266
16,0.03955477915746583,98.81428571428572,0.9880994256042671,0.9880396850601272
17,0.04332999191670255,98.78571428571429,0.9877984684774631,0.9877324421571945
18,0.0397282976699485,98.88571428571429,0.9888744230079372,0.9887236028929172
19,0.04315984462842938,98.71428571428571,0.9870732133608463,0.9869764229043673
20,0.04324322897618086,98.81428571428572,0.988189495470521,0.9880088311774096
21,0.04252115313958546,98.71428571428571,0.9872242277286098,0.986975371050687

 Training with LR: 0.01, Batch Size: 64, Optimizer: SGD, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.11182720200581985,97.22857142857143,0.9730192359026553,0.9716911496303569
2,0.08310657623647288,97.71428571428571,0.977290872384818,0.976793548532943
3,0.06926429755985737,98.05714285714285,0.980694602103027,0.980249247445386
4,0.06716919096017426,98.04285714285714,0.9805520094150658,0.9801215069312603
5,0.054900312855501066,98.28571428571429,0.9828848479938237,0.9825865734291584
6,0.060088428734293715,98.21428571428571,0.9823757790007385,0.9818613857846286
7,0.04990674198647453,98.55714285714285,0.9855514788733745,0.9855074250673853
8,0.04858703513799066,98.67142857142858,0.9867378848753543,0.9864970147130817
9,0.051768096096136355,98.57142857142858,0.9857207588213113,0.9855525216434204
10,0.04985318861859427,98.52857142857144,0.9852946544857215,0.9851496624019755
11,0.04483789318791506,98.78571428571429,0.9879103197822505,0.9876390880805396
12,0.045744699227030984,98.77142857142857,0.9876512292520367,0.9875609626520138
13,0.045565960399637166,98.74285714285715,0.9874955481311183,0.9872114253519341
14,0.045731848088855095,98.74285714285715,0.9873865225608023,0.9873450435361006
15,0.04477702381343327,98.85714285714286,0.9885940684308924,0.9884104600626472
16,0.0440181382434358,98.87142857142858,0.9887206019769661,0.9886311541146323
17,0.04419652580347082,98.77142857142857,0.9876780551375093,0.9876617878222236
18,0.04332675815411759,98.78571428571429,0.9878342605097208,0.987746221234225
19,0.044782940934899006,98.8,0.9880309890367436,0.9878310250496284
20,0.04270512818845666,98.8,0.9879730551995056,0.9878908239540802
21,0.04406473297858611,98.81428571428572,0.9881876998901333,0.9879672849095652
22,0.04650742906166918,98.67142857142858,0.9867579316128609,0.9866227677487054
23,0.044403118783851496,98.9,0.9890254673779222,0.9889700548258888
24,0.04773847819305956,98.8,0.9880266617400599,0.9878152118133388
25,0.04541613061870025,98.81428571428572,0.9882281128855199,0.9880056953549211

 Training with LR: 0.01, Batch Size: 64, Optimizer: SGD, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.1188303631645712,96.75714285714285,0.9677078938487563,0.9673672770451525
2,0.08164588777687062,97.65714285714286,0.9766710105583194,0.9763815738822451
3,0.07001481642099944,97.94285714285714,0.9795784159631079,0.9791233386768461
4,0.06454540002159774,98.15714285714286,0.9814302163354425,0.9814786953415771
5,0.06266688803549517,98.0,0.9799747273018632,0.9798993959443386
6,0.05788211199793626,98.31428571428572,0.9834018321976146,0.9828079298679647
7,0.054769305055114355,98.44285714285715,0.9844371085214823,0.9843441263685723
8,0.04981065219352868,98.58571428571429,0.9859249227754759,0.9856920413563064
9,0.04746669650458815,98.47142857142858,0.9846207508421386,0.9845276811898682
10,0.04485110093373805,98.71428571428571,0.9870229811679166,0.9870511059719472
11,0.045284814419309524,98.74285714285715,0.9873334585610547,0.9873222637675736
12,0.04685437015723437,98.75714285714285,0.987507211178324,0.9875647475205609
13,0.046136669339400464,98.77142857142857,0.987656906811695,0.9876475311547788
14,0.053014455375854266,98.42857142857143,0.9842209531368245,0.9842251612162652
15,0.04711835451360623,98.6,0.9859357330525207,0.985897083697543

 Training with LR: 0.01, Batch Size: 64, Optimizer: Adam, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.07082050109959462,97.77142857142857,0.9778362845709438,0.9779110471654902
2,0.05582483541432091,98.3,0.9833183710516538,0.9825655943019991
3,0.048313525312220336,98.62857142857143,0.9864149382333883,0.986042291958776
4,0.052986129658000376,98.37142857142858,0.9838768301668388,0.9835527837399456
5,0.041437636443350294,98.74285714285715,0.9872991218437033,0.9873420612116931
6,0.052345692662956106,98.62857142857143,0.9863584667649707,0.9861874681497251
7,0.09077665007392749,97.55714285714285,0.9759386802302712,0.9756525027836499
8,0.05572509336317043,98.45714285714286,0.9844467740154546,0.9845619221633625
9,0.07083059137657984,98.21428571428571,0.9823187074145592,0.982023653703258
10,0.057484875118825586,98.4857142857143,0.9846681762335932,0.9848466809308549

 Training with LR: 0.01, Batch Size: 64, Optimizer: Adam, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.07800607722972265,97.54285714285714,0.9759671594837572,0.9750940628106999
2,0.06945345397107303,97.87142857142858,0.9798091186917743,0.9782398410385212
3,0.049990050321635365,98.47142857142858,0.9847653598966133,0.9844661614246035
4,0.05167018010767854,98.54285714285714,0.9854468876569964,0.9853821216850174
5,0.054982298830608754,98.44285714285715,0.9843532596216708,0.9843222362470362
6,0.05645258950058964,98.41428571428571,0.9842898565169176,0.9838074351054129
7,0.049439927033778405,98.55714285714285,0.9855634859740624,0.9853666143106377
8,0.05865812912604518,98.45714285714286,0.984276850576775,0.9846497859226669
9,0.06091864264572822,98.45714285714286,0.9845700133840957,0.9845558482191008
10,0.06859587044216989,98.24285714285715,0.9820757398339532,0.9825956943838052
11,0.06472692268210019,98.3,0.9830374286077956,0.9828992822613813
12,0.06164518441105015,98.55714285714285,0.9856359957933474,0.9852638505922767

 Training with LR: 0.01, Batch Size: 64, Optimizer: Adam, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.06745610206641935,98.05714285714285,0.9804024879322807,0.9805573335956597
2,0.06703831123780798,98.02857142857142,0.9800278419689079,0.980455519373184
3,0.06156990477307276,98.31428571428572,0.9830590568400666,0.9831006538918986
4,0.06631657262332738,98.11428571428571,0.9812027301388465,0.9810356946093421
5,0.05088341947041706,98.5,0.9849023388194741,0.9849180667284025
6,0.059575838123352945,98.2,0.9820549636675239,0.9818216812180374
7,0.05229597832843534,98.54285714285714,0.985475204703509,0.9852447792771247
8,0.059200041457403464,98.6,0.9858634342810267,0.9859354853383573
9,0.07549384256417398,98.08571428571429,0.9810857700569147,0.9806305304362011
10,0.06146125142867359,98.54285714285714,0.9855088464963305,0.9852105843116352

 Training with LR: 0.01, Batch Size: 128, Optimizer: SGD, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.15871965898708865,96.25714285714285,0.962501444993079,0.962337450553133
2,0.10710479352961887,97.24285714285715,0.9727795502249823,0.9721951287236233
3,0.08879266672513701,97.42857142857143,0.9741812512255257,0.9742909614605079
4,0.08039767284962264,97.98571428571428,0.9800380098466892,0.9797728496346911
5,0.06880239525979215,97.97142857142858,0.9797061745776334,0.9794996897866237
6,0.0629415721717206,98.1,0.9809958780690702,0.9808241186049059
7,0.06116567284546115,98.17142857142858,0.9815092466135017,0.9816978781077129
8,0.05769499819725752,98.38571428571429,0.9837834722456972,0.9837528927327241
9,0.053625054217197675,98.4857142857143,0.9847583247140156,0.9848300782513009
10,0.05369502121413296,98.41428571428571,0.9840893226587338,0.984069321898874
11,0.05341462203386155,98.5,0.9850009106439419,0.9848193285430691
12,0.05264151340181177,98.41428571428571,0.9840156760553613,0.9840576773573761
13,0.04907073490321636,98.47142857142858,0.9846707091761342,0.9844870508433878
14,0.051208356132900174,98.44285714285715,0.9843430494383545,0.984299492676287
15,0.04870693143457174,98.5142857142857,0.9850775382760546,0.9849885040500517
16,0.04963139547035098,98.6,0.9858645733878093,0.9859218114904792
17,0.050928500218486245,98.4857142857143,0.9847265918942041,0.9848384805185155
18,0.04786603621799838,98.57142857142858,0.985621474765828,0.9856150030938668
19,0.04983357886191119,98.45714285714286,0.9845856215203812,0.9843909035752981
20,0.05096602556719022,98.41428571428571,0.9839622394980123,0.9840515566920974
21,0.04963584025813775,98.42857142857143,0.9841782626829996,0.9842050824404319
22,0.04869005238975991,98.52857142857144,0.9851644220193029,0.9852264417825106
23,0.049451165870678694,98.54285714285714,0.985486432213615,0.9853109856156801

 Training with LR: 0.01, Batch Size: 128, Optimizer: SGD, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.153062142431736,96.24285714285715,0.9621920848723275,0.9618928585939042
2,0.10837926810437983,97.08571428571429,0.9709185867043326,0.9705825079083956
3,0.08406322970986366,97.7,0.977174097944889,0.9767003414007702
4,0.07979325503110886,97.71428571428571,0.9774007020337228,0.9767812326809059
5,0.07064973410557616,97.97142857142858,0.979856046268069,0.9794151706089519
6,0.06417838372290134,98.27142857142857,0.9825677272887268,0.9826334611882676
7,0.05986179413104599,98.3,0.9828316011248152,0.9829575165381911
8,0.05939531387253241,98.27142857142857,0.9827798111944637,0.9825361240872473
9,0.05793293905867772,98.32857142857144,0.9834473860068528,0.9829845114053827
10,0.056149146282537414,98.31428571428572,0.9830936384089576,0.9830258595639169
11,0.04947570558976044,98.57142857142858,0.9856643462902743,0.9856040983627695
12,0.04846304368905046,98.57142857142858,0.9856274231041852,0.9856097806662639
13,0.050122706253420225,98.52857142857144,0.9852577562387033,0.9851911708386663
14,0.05135309873148799,98.42857142857143,0.9843115661501312,0.9840587054549597
15,0.04705406346951019,98.52857142857144,0.9853894141854227,0.9850507223516617
16,0.04456405035135421,98.65714285714286,0.9865094244627723,0.9865040206145572
17,0.04501460882073099,98.57142857142858,0.9856994755629218,0.9855955497425768
18,0.044258821865713054,98.62857142857143,0.9862845940259966,0.9861201040808399
19,0.048181858387860384,98.57142857142858,0.9857283182518974,0.9855016487728235
20,0.042881387065757406,98.74285714285715,0.9874629347728561,0.9873090995679699
21,0.04649424076249654,98.61428571428571,0.9861814220922435,0.9859121958362934
22,0.043663639058782296,98.67142857142858,0.9867906204279955,0.9865347227411047
23,0.04568989518183199,98.62857142857143,0.9861962950722696,0.9861748705421416
24,0.04655625555579635,98.57142857142858,0.985707966577225,0.9856092143887837
25,0.044241058559749614,98.68571428571428,0.9868775382849639,0.986715997763414

 Training with LR: 0.01, Batch Size: 128, Optimizer: SGD, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.1549435932527889,96.02857142857142,0.9606542065322339,0.9598206692157522
2,0.11209486370736903,96.95714285714286,0.9699090333812033,0.9693388162354737
3,0.08518709662285719,97.8,0.9779541968155261,0.977699005957484
4,0.07457310543818907,97.89999999999999,0.9789851780152942,0.9788424052848343
5,0.07291012440215458,97.97142857142858,0.9797660028319367,0.9794849783226681
6,0.06547150208868764,98.1,0.9810291912659771,0.9808209862488646
7,0.06314556300640106,98.2,0.9819055255116448,0.9818513845287395
8,0.05831449661742557,98.3,0.982889086621402,0.9828443849372388
9,0.06175093705003912,98.28571428571429,0.9827183707209597,0.9827049773500814
10,0.05713661905716766,98.38571428571429,0.9838161411958911,0.9837075021110788
11,0.05293695427138697,98.58571428571429,0.985785365865862,0.9857154830481398
12,0.05272740415212783,98.52857142857144,0.9851941797661297,0.9851472569294796
13,0.05104928890412504,98.67142857142858,0.9866342074217573,0.9865713105659045
14,0.050640594942325895,98.5142857142857,0.9850785652354663,0.9849624425480448
15,0.053177025609395724,98.57142857142858,0.9856740781280434,0.9856567317166448
16,0.05335066878998822,98.5,0.9849667871910228,0.9847933334953052
17,0.052666500447825955,98.4,0.9839266265309228,0.983764018644871
18,0.04821092449128628,98.65714285714286,0.9865888817426789,0.986350473361262
19,0.04876469006253915,98.61428571428571,0.986087247383001,0.9859333940882834
20,0.052273739527233624,98.4857142857143,0.9850412425973077,0.9846412550787782
21,0.04978985999795524,98.55714285714285,0.9855303375329525,0.985412504272014
22,0.04912353792989796,98.61428571428571,0.986213004123034,0.9859354870603895
23,0.04796007076616992,98.64285714285714,0.9864066476798223,0.9862160928591489
24,0.05132075041871179,98.5,0.9851409274833648,0.9846977368457133
25,0.047594555662098255,98.65714285714286,0.9865090507776996,0.9864167615248235
26,0.04710724407129667,98.6,0.9859197663760785,0.9858508366451219
27,0.05819006765430624,98.28571428571429,0.9828729132049101,0.9827854727719402
28,0.04822807488116351,98.7,0.9871163025303987,0.9868124620507338
29,0.04838817022656175,98.6,0.986020773328615,0.9858341792148364
30,0.046935771278698336,98.67142857142858,0.986688493824009,0.9865231994470023
31,0.04676693847656927,98.62857142857143,0.9862310367172705,0.9860351390729362
32,0.04764232378114353,98.65714285714286,0.9865386924693746,0.9864388239683617
33,0.04901064152575352,98.68571428571428,0.9869385804997867,0.9866536650004385
34,0.04913090630857782,98.71428571428571,0.9871228125334595,0.9869804659853105
35,0.051196926933797925,98.61428571428571,0.9861102711934358,0.986045359948465
36,0.047711433241651814,98.72857142857143,0.9872911249587709,0.9871007115592066

 Training with LR: 0.01, Batch Size: 128, Optimizer: Adam, Activation: ReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.07793724902651526,97.62857142857143,0.9769147675718106,0.9756872395305682
2,0.052234142493795266,98.41428571428571,0.9841223421559715,0.9839002374098896
3,0.05545780872079459,98.34285714285714,0.9833746639129952,0.9833979156009433
4,0.05126338623125445,98.65714285714286,0.9867296057315504,0.9861876073004548
5,0.05424563424153762,98.38571428571429,0.9840225761140017,0.9834833295640018
6,0.04691384370354089,98.68571428571428,0.9866440377473777,0.9867556660486789
7,0.050732764293736014,98.62857142857143,0.9860408652164233,0.9862296247309834
8,0.05769143791191957,98.47142857142858,0.9846923851348629,0.9844967786049683
9,0.049421870775668966,98.78571428571429,0.9878110496926938,0.9877069680714119
10,0.058658411173911934,98.6,0.9860186053026412,0.9857837194553616
11,0.05076493975621733,98.72857142857143,0.9872677483084662,0.9870594055609093

 Training with LR: 0.01, Batch Size: 128, Optimizer: Adam, Activation: LeakyReLU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.0748302167112177,97.7,0.9773607290985851,0.9766151376493625
2,0.06517635709182783,98.0,0.9797602585499169,0.9801477799195686
3,0.04698646694252437,98.54285714285714,0.9854204515937269,0.9853327825499635
4,0.049887240546840156,98.52857142857144,0.9851890428197858,0.9851552067957903
5,0.061006044799631294,98.08571428571429,0.9808749764610264,0.9808156592441624
6,0.05431250173450363,98.55714285714285,0.9854910429064404,0.9854973823518918
7,0.0575045220003548,98.34285714285714,0.9835532599351164,0.9833026983240829
8,0.06892255050849846,98.21428571428571,0.9821748272163655,0.9821368861744899

 Training with LR: 0.01, Batch Size: 128, Optimizer: Adam, Activation: ELU
Epoch,Val Loss,Val Accuracy,Val Precision,Val Recall
1,0.08915794390169057,97.5,0.9754896358153624,0.9747017675974075
2,0.07679051873697476,97.68571428571428,0.9776048022399572,0.9760766402959675
3,0.05925582328980619,98.27142857142857,0.9826942459220989,0.9825051981314571
4,0.05189412563869899,98.34285714285714,0.9834611588849581,0.9831777303717258
5,0.06344830195673487,98.21428571428571,0.9822187767467421,0.9817780274637915
6,0.05363337403925305,98.5,0.9848568179620403,0.9849515078019883
7,0.059533148843117736,98.5142857142857,0.9851601121385153,0.9848942201305289
8,0.07925556356256658,97.98571428571428,0.9800751465863501,0.9797301143539743
9,0.05977278314742514,98.37142857142858,0.9838359022724739,0.9834314419787036
