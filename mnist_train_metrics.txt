
 Training with LR: 0.001, Batch Size: 32, Optimizer: SGD, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.7661373776532029,85.14489795918368,0.8539232429767502,0.8489484405711771
2,0.21667324894839807,95.18571428571428,0.9514348045698959,0.9513710851879541
3,0.15134073521299946,96.43061224489796,0.9640474246394793,0.9640106829655448
4,0.12155274718248482,97.08163265306122,0.9706040493790858,0.9706091669462736
5,0.10335648790860243,97.38163265306122,0.9736714282076433,0.9736269771281233
6,0.09004190850786514,97.73877551020408,0.9772577152333675,0.977225607737245
7,0.08102978966940515,98.0,0.9798549429834094,0.979879984955111
8,0.07352104887284834,98.10612244897959,0.9809545035827693,0.9809474877314237
9,0.06772988558231365,98.28367346938775,0.9827644281628676,0.9827273551205652
10,0.06255084479211856,98.43673469387755,0.9843031470567934,0.9842635018398218
11,0.057557005160451716,98.57551020408162,0.9856854615399925,0.9856494721046773
12,0.05407564774947119,98.67551020408163,0.9866820889915481,0.9866730263694541
13,0.05051442785200714,98.75102040816327,0.9874464029772352,0.987408880874961
14,0.047766938803452445,98.82244897959184,0.9881728121027725,0.9881498354081506
15,0.04480105641224438,98.83877551020407,0.9883404300295732,0.9882776404987131
16,0.04195199713220956,98.98979591836735,0.9898685324359391,0.9898283060664191
17,0.03945659961168139,99.06122448979592,0.9905696075821938,0.9905599123675778
18,0.03789368195701804,99.06530612244899,0.9906044947791279,0.9905974588905708
19,0.03587670777769341,99.13877551020408,0.9913669716301661,0.9913085452424854
20,0.03398264240362261,99.2265306122449,0.9922504147822124,0.9922158277958877
21,0.03260631542055571,99.21224489795918,0.9920889159928695,0.9920643309717561
22,0.030830723364830174,99.26938775510204,0.9926598175446781,0.9926440330321524
23,0.0291351368497296,99.35306122448979,0.9935040366727174,0.9934896024156658
24,0.02765331046160933,99.40204081632653,0.9940059119162796,0.9939727080155482
25,0.026667328332335014,99.40816326530613,0.9940647861039837,0.9940502219477363
26,0.025302382136282314,99.47755102040816,0.9947673677276179,0.9947526799700743
27,0.02416886872120746,99.4938775510204,0.9949270252571653,0.9949164015839411
28,0.022614638967313087,99.56530612244899,0.9956429820704497,0.9956094567627061
29,0.021519324489023873,99.61224489795917,0.9961135393399603,0.9960930512596562
30,0.020851358957573476,99.61632653061224,0.9961535888338655,0.9961412637677256
31,0.01997321429337173,99.66122448979591,0.9965998048648818,0.9965942191536756
32,0.018961350767386594,99.68367346938776,0.9968427135854183,0.9968194015964149
33,0.01817647697759352,99.70204081632653,0.997008501143912,0.9970004183553488
34,0.017406263018892313,99.7265306122449,0.997259549835203,0.9972595343508892
35,0.01639485325467926,99.76938775510204,0.9977056342544236,0.997684845568874
36,0.016052147211016377,99.76326530612245,0.9976367611457698,0.9976147916773656
37,0.015317235888737587,99.77551020408163,0.9977441517642216,0.9977470562273737
38,0.014665472949300309,99.81224489795918,0.998119670735151,0.9981219880876256
39,0.013739388356746391,99.86326530612246,0.9986321796046352,0.9986287329227024
40,0.013387088712813047,99.84081632653061,0.998415938334188,0.9983965296901989
41,0.012782495129316548,99.85714285714286,0.9985814407930199,0.9985623543760536

 Training with LR: 0.001, Batch Size: 32, Optimizer: SGD, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.7839731249481673,84.94081632653061,0.8504420420497263,0.8466273401786063
2,0.21741148715658848,95.25510204081633,0.9522314762403852,0.9521468910634315
3,0.1501762437823839,96.53469387755102,0.9651539340997409,0.9651002928591994
4,0.1201521799688084,97.08163265306122,0.9706711812000993,0.9705916594098805
5,0.10228299616724155,97.41836734693877,0.9740691195214929,0.9740021785372738
6,0.08975904407624068,97.73061224489797,0.9772069671195857,0.9771464623789188
7,0.08036374112903615,98.01224489795919,0.9800396396566416,0.9799738339049014
8,0.07291874541674909,98.15102040816328,0.9814307236507265,0.9813764412424684
9,0.06696714668087272,98.30816326530612,0.9830107032180246,0.9829870602497037
10,0.06214629580004155,98.40816326530613,0.9840325678586515,0.983989870547226
11,0.05771339088362245,98.5142857142857,0.9851000074922917,0.985067993814088
12,0.05387970269703265,98.62244897959184,0.9861882732943903,0.9861637045125938
13,0.05021471787255024,98.73877551020408,0.9873520957834339,0.9873239664040371
14,0.04797536965265661,98.79591836734693,0.9879095993397671,0.9879001110441864
15,0.04480840405449271,98.91428571428571,0.9891210801071214,0.989084588317281
16,0.04254347944523356,98.97142857142858,0.9896928695078897,0.9896559222788481
17,0.04009599172326009,99.02448979591837,0.9902511790591484,0.9902042171731038
18,0.03808953612830062,99.07755102040817,0.9907455783476035,0.990725147991599
19,0.036495080094616716,99.14489795918368,0.9914142788367102,0.9914171810679718
20,0.034634602830900904,99.21632653061224,0.9921350319699467,0.992130821020673
21,0.03321927650863555,99.2204081632653,0.9921953497263603,0.992155634659339
22,0.03120202514382174,99.35918367346939,0.9935980269137188,0.9935814101196584
23,0.029731101559185697,99.34897959183674,0.9934909197363181,0.9934719673611513
24,0.02889102284166434,99.37142857142857,0.9937245739220189,0.9936954278686715
25,0.027435226331272846,99.43265306122449,0.9943393122157052,0.9943086956029701
26,0.02578816427744368,99.4857142857143,0.9948765191169141,0.9948590121602441
27,0.024690761063253998,99.5,0.9950165184743058,0.9949931995542686
28,0.02349596695271418,99.5530612244898,0.9955544159159844,0.9954954572706557
29,0.02260572761645256,99.57551020408162,0.9957694419499049,0.9957552816089985
30,0.02176423976140847,99.57551020408162,0.9957623204904026,0.9957507870856173
31,0.020763678949170652,99.62448979591836,0.996273833316013,0.9962374949953828
32,0.01981374542624781,99.65306122448979,0.9965365081229527,0.9965229590091
33,0.018912847096698635,99.68571428571428,0.9968847305273663,0.996854862370579
34,0.018056665546584184,99.72244897959183,0.997227048816803,0.9972290464167335
35,0.01736323150777861,99.73673469387755,0.9973935342411074,0.9973614565506631
36,0.016535925955965133,99.76326530612245,0.9976437707146278,0.9976331807393226
37,0.016140554980836885,99.76122448979592,0.9976226441570569,0.9976172503913776
38,0.015210001346671604,99.78979591836735,0.9979084075173852,0.9978932071714913
39,0.01465713206357043,99.81428571428572,0.9981566687554645,0.9981390646143845
40,0.013968447424790836,99.8265306122449,0.9982773924470723,0.9982696878730757
41,0.013523199776555023,99.85918367346939,0.9985995449737596,0.9985871407596048
42,0.01297315766296806,99.85306122448979,0.9985291552680643,0.9985297211259592
43,0.01253634535975547,99.8734693877551,0.9987412643321536,0.9987287875322662
44,0.011795532292617709,99.90408163265306,0.9990496874131061,0.9990388347732597
45,0.011452345322632455,99.9,0.9990080593278258,0.9989995959882071
46,0.011013203159765846,99.92448979591838,0.9992582391352819,0.9992505533266787
47,0.010559135627473569,99.93469387755101,0.9993607760218733,0.9993517611697659
48,0.010245314785191187,99.95102040816326,0.9995185352859091,0.9995187338405399
49,0.009952956973837218,99.94081632653061,0.999417273688269,0.9994150914746225
50,0.009605698475750058,99.9469387755102,0.9994787211157984,0.999470275232131

 Training with LR: 0.001, Batch Size: 32, Optimizer: SGD, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.6055747510685389,88.67142857142856,0.8878014121470619,0.8847187606521967
2,0.19251081631482425,95.56122448979592,0.955299101695726,0.9552375398119025
3,0.13950129485793664,96.54897959183674,0.9652656692753283,0.9652633467938114
4,0.11429511722208878,97.06326530612245,0.9704750058731824,0.9704534651436308
5,0.09835257811967876,97.47755102040816,0.9746407294961165,0.9746212213408999
6,0.08690860433359301,97.77142857142857,0.9776199636080041,0.9776030735946982
7,0.07884435947192954,98.0142857142857,0.9800546270475585,0.9800406270826094
8,0.07165288444494163,98.15510204081632,0.981484496254413,0.9814377178902042
9,0.06650856982669781,98.21836734693878,0.9821046292920437,0.9820929731004592
10,0.06198746576150223,98.35918367346939,0.98352927566531,0.9834896007811945
11,0.05759797576014269,98.5530612244898,0.9854761240312202,0.985452500006021
12,0.05452444507572046,98.59591836734694,0.9859301421267904,0.985879640300257
13,0.05076978603005895,98.74285714285715,0.987404453899676,0.9873674589846821
14,0.048403205132560544,98.78571428571429,0.9878261366058739,0.9877904078448909
15,0.04562357918668767,98.85102040816327,0.9884766474736078,0.988449992017544
16,0.04369261866926602,98.90816326530613,0.9890497257822014,0.9890123061294869
17,0.04163059900002919,98.95510204081633,0.9895257205799111,0.9894938988205203
18,0.03965600391007308,99.03265306122448,0.9903066939386986,0.9902804662406275
19,0.037653661252779996,99.07142857142858,0.9906895285820536,0.9906925296312703
20,0.03557432812598155,99.17346938775509,0.991719957369426,0.9917030070455624
21,0.03391694164422752,99.21224489795918,0.9921122565679168,0.9920872333717469
22,0.03229518100821751,99.2265306122449,0.9922359829007579,0.9922307292239625
23,0.03101404089343554,99.28979591836735,0.9929006546247395,0.992888200851397
24,0.029871240316500507,99.32448979591837,0.9932355845959482,0.9932207651512492
25,0.028915053391181705,99.36326530612246,0.9936269823253674,0.9936298300107552
26,0.027970452193160453,99.41836734693878,0.9941614023424931,0.9941598647465801
27,0.026086234115360502,99.46938775510205,0.9946910465511791,0.9946749199282973
28,0.025716926484440475,99.46122448979592,0.9945976621825412,0.9946057231472695
29,0.024608884492005142,99.50408163265307,0.9950462796529408,0.9950161205864317
30,0.023238053361082197,99.54285714285714,0.9954090200269252,0.9954290140044344
31,0.02238405540548435,99.60204081632654,0.9960135741822205,0.9960080237447915
32,0.021858809929252626,99.57755102040817,0.9957794753439672,0.9957539725431577
33,0.020746597451569426,99.61224489795917,0.9961263706391389,0.9960966442281045
34,0.01993329398811694,99.65918367346939,0.9966059981475602,0.9965847548173151
35,0.019194328491996995,99.67551020408163,0.9967566533510374,0.9967620328331639
36,0.01835302362721091,99.67551020408163,0.9967436246018672,0.9967401467228914
37,0.017927968302641643,99.70204081632653,0.9970252165201687,0.9970165187202029
38,0.01711708963747585,99.73061224489796,0.997308777718042,0.9972996320417886
39,0.01640292634291899,99.76734693877552,0.9976815092979885,0.9976812230929852
40,0.016032106436428238,99.76938775510204,0.9976847993279228,0.9976842577248657
41,0.015145337141323203,99.78163265306122,0.997825812242785,0.9978164255469736
42,0.01457256351395628,99.80408163265307,0.9980302149164384,0.9980431994394081
43,0.013951146252579165,99.81020408163266,0.9980936949056674,0.9981098489186995
44,0.013392598702617576,99.84081632653061,0.9984042572540395,0.998402330439507
45,0.013216940627576067,99.83877551020409,0.9983904790188418,0.9983927869634523
46,0.012581417073776694,99.84285714285714,0.9984305867442617,0.9984258558711485
47,0.012335038702955041,99.85510204081632,0.9985628146428862,0.9985572453545117

 Training with LR: 0.001, Batch Size: 32, Optimizer: Adam, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.2816157941761191,94.1938775510204,0.9416028250237025,0.941232540393967
2,0.07418642676521735,97.88979591836735,0.9787735734534667,0.9787649345601765
3,0.05337383017555188,98.40204081632653,0.9839266159813723,0.9838815414394171
4,0.04071546399050365,98.80408163265307,0.987991525751639,0.9879697769530014
5,0.03347184204632236,99.0142857142857,0.9900986952597723,0.9900859237337774
6,0.02647631637042014,99.25510204081633,0.992517633096865,0.9925180979355444
7,0.022747104811264348,99.31224489795918,0.9930929286463567,0.9930924931143625
8,0.018357664121453714,99.46326530612245,0.9946127290192937,0.9946023244152922
9,0.01517107709777788,99.59183673469387,0.9959015512067925,0.9958993678463148
10,0.012319410055481091,99.68979591836735,0.9968903444295683,0.996889459269795
11,0.010467525960848434,99.73877551020408,0.9973779032931557,0.9973666147566732
12,0.008718778336470124,99.79183673469387,0.9979144916184414,0.9979139721153023

 Training with LR: 0.001, Batch Size: 32, Optimizer: Adam, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.2741475273063528,94.08367346938775,0.9402893288823242,0.9400571178685044
2,0.07296521016612391,97.88367346938776,0.9787475164376245,0.9786553404138385
3,0.051730901796970145,98.47142857142858,0.9846377663479254,0.9846027353079464
4,0.04095319484027836,98.76734693877552,0.9876148261770694,0.9875725266803068
5,0.034486650346525136,98.96326530612245,0.9895872862251972,0.9895335640051816
6,0.028780876047904396,99.16938775510205,0.9916528934786637,0.9916357547129394
7,0.023617542242645298,99.26734693877552,0.9926409054706653,0.992633465019361
8,0.02010875118353385,99.42857142857143,0.9942641396722427,0.9942355675861408
9,0.01714639638185224,99.51020408163266,0.995048313311168,0.9950644292852312
10,0.015656168353703766,99.53061224489797,0.9952687345220766,0.9952575342037117
11,0.011952313362313984,99.67142857142856,0.9967253445155488,0.9967031490431199
12,0.010613957245241466,99.68163265306123,0.9968214312232305,0.9967910855594765

 Training with LR: 0.001, Batch Size: 32, Optimizer: Adam, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.2445801806480529,94.37551020408164,0.9438080032078473,0.94301214983303
2,0.07315949286065519,97.87755102040816,0.9786924604146628,0.9785938063146761
3,0.05273106394345658,98.39387755102041,0.9838597388946739,0.9838195051572868
4,0.04275781412175936,98.7061224489796,0.9869863162296196,0.9869771845692819
5,0.03591864869783799,98.9,0.9889490253945384,0.9889370168291522
6,0.029481577030362534,99.13877551020408,0.9913483146571123,0.9913142969940185
7,0.025565370028998016,99.28571428571429,0.992816643022004,0.9928056842120704
8,0.02201213339587326,99.34693877551021,0.9934571047438379,0.9934238086848189
9,0.018577566962627155,99.45510204081633,0.9945121100600464,0.9945247134979684
10,0.016477336620665525,99.54081632653062,0.9954055503942794,0.995388120514303
11,0.013632918135011501,99.61836734693877,0.9961573276642639,0.9961538770001871

 Training with LR: 0.001, Batch Size: 64, Optimizer: SGD, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,1.0781041169757943,80.08163265306123,0.8144713984073254,0.7979078782581869
2,0.33587980332636025,93.8469387755102,0.9379661424488479,0.9378816999760347
3,0.21636166794142897,95.54285714285714,0.9550804530605135,0.9551041370409912
4,0.16822788628990282,96.36530612244898,0.9633888505735498,0.9633898197963935
5,0.1414744809814595,96.74285714285715,0.9671785364728509,0.9672087534220356
6,0.12368744856850597,97.08775510204082,0.970694233341964,0.9706840635710865
7,0.11107403925053444,97.36122448979592,0.9734473863049905,0.9734790009984664
8,0.10133115817882685,97.55510204081632,0.9754072432648113,0.9754109633612238
9,0.09305592903541522,97.7408163265306,0.9772943733948379,0.9772416921171319
10,0.08710533459780266,97.89183673469388,0.9788079600332564,0.9787822052080253
11,0.08102964810472633,98.0265306122449,0.9801800991056536,0.9801286431930816
12,0.07636810262753159,98.15306122448979,0.9814569118850931,0.9814100109534699
13,0.07236553116290594,98.25306122448978,0.9824796734368639,0.9824247963720687
14,0.06829138080572451,98.35918367346939,0.9835424206271695,0.9834893296981508
15,0.06508830739014998,98.43061224489796,0.9842644577769832,0.9841998889276022
16,0.06212931267999832,98.51836734693877,0.9851045206954767,0.9850758867224327
17,0.05914548088677286,98.57142857142858,0.9856554989585099,0.9856203607729557
18,0.05684165837116754,98.61224489795917,0.9860984379766083,0.9860310280896961
19,0.05454843722444329,98.74285714285715,0.9873884842769118,0.987346828970888
20,0.05230280664486825,98.77755102040815,0.9877526992641709,0.9877024610032045
21,0.05036926600661411,98.84897959183674,0.9884616513975313,0.9884102505908446
22,0.0481856402809739,98.87142857142858,0.9886940945487153,0.9886361270615446
23,0.04642980580592611,98.92040816326531,0.9891901750075839,0.9891363038363732
24,0.0451090924402908,98.97551020408163,0.989716651101101,0.9896998838439263
25,0.04324218613161236,99.03469387755102,0.9902957381780266,0.9902867604958839
26,0.04170879819758684,99.09183673469387,0.9909176437745095,0.9908570477681738
27,0.040299245610458695,99.12448979591836,0.9912239801857277,0.9911846995305581
28,0.038995473485746404,99.15510204081632,0.9915286609636773,0.9915013834630233
29,0.037720967961387714,99.18163265306123,0.9918081576780633,0.9917683842904763
30,0.036509427977555645,99.2530612244898,0.9925263969637911,0.9924769840652024
31,0.035285393122034076,99.2795918367347,0.9927932733524358,0.9927610325081963
32,0.03420791955051978,99.28775510204082,0.9928793925530618,0.9928399512449971
33,0.033111451084265976,99.33877551020409,0.9933862952490646,0.9933354291583107
34,0.03222621437320218,99.31632653061224,0.9931514357905883,0.9931251887394371
35,0.0313869384281561,99.36530612244898,0.9936553213967944,0.9936203241855559
36,0.030498199355752053,99.39183673469387,0.9939314519529496,0.9938788827065265
37,0.029376856574190504,99.44489795918368,0.994436121840001,0.9944154588073154
38,0.028602851255050334,99.45510204081633,0.9945452564663537,0.9945120188928204
39,0.027787063182051982,99.4734693877551,0.9947494966717031,0.9946962862365043
40,0.026927503469332023,99.51836734693877,0.995194166545726,0.9951415418501682
41,0.025917104286428627,99.53673469387755,0.9953696791453345,0.9953440291889267
42,0.025667319241145202,99.51836734693877,0.9951837162845883,0.995160833072614
43,0.024552727864347593,99.57551020408162,0.9957796293901342,0.9957142591228478
44,0.02403110959816374,99.58163265306122,0.995828709034071,0.995788087632881
45,0.02339425888526504,99.61224489795917,0.9961318619576558,0.9960816930861898
46,0.022497976703664126,99.62244897959184,0.9962418079645271,0.996205352996314
47,0.02200982691391855,99.65306122448979,0.9965495992632721,0.9965073154394608
48,0.021391655608413464,99.66122448979591,0.9966300785496948,0.996591380583296
49,0.0207203016400595,99.68775510204082,0.9968972071891375,0.9968672751034682
50,0.02010334446642052,99.72857142857143,0.9973014680772723,0.9972588251765687

 Training with LR: 0.001, Batch Size: 64, Optimizer: SGD, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,1.1149666349819372,79.64081632653061,0.7972811523666381,0.7927939331377933
2,0.33611095910673044,93.60204081632652,0.9354155356247155,0.9352621820290326
3,0.22056071598364851,95.26326530612245,0.9522255693753202,0.9521856979878786
4,0.17330834767525874,96.11632653061224,0.960886516059503,0.9608639992647479
5,0.14574601814423155,96.61224489795919,0.965914769588917,0.9658788327409649
6,0.12735186084890956,97.01428571428572,0.9699908148081814,0.9699156854141044
7,0.11400695847877479,97.26122448979592,0.9724891978639214,0.9724188158352381
8,0.10397007615930418,97.49795918367347,0.9748566661995925,0.9748221136970313
9,0.09565159134498698,97.68367346938776,0.9767379655094484,0.9767045779120481
10,0.08865195943538692,97.82244897959184,0.9781239544872202,0.9780520904336243
11,0.08355769225427827,97.9469387755102,0.9793785396159198,0.9793489568380795
12,0.07853697593914778,98.05102040816327,0.9804325945694016,0.9803861340691136
13,0.07433304958429683,98.2122448979592,0.9820338750592372,0.9819902067776356
14,0.07028873332632662,98.2938775510204,0.9828336036820495,0.982843757614479
15,0.06729917106152981,98.36326530612244,0.9835517726448011,0.9835289323275427
16,0.06434574991576471,98.42857142857143,0.9842150683824069,0.9841705093722142
17,0.061651264423110544,98.4938775510204,0.9848899116015968,0.9848311496277613
18,0.059073637558181354,98.53265306122448,0.9852747014334475,0.9852263561510778
19,0.05660794997908778,98.62040816326531,0.9861639006549237,0.9861143003053824
20,0.054543660695277954,98.69591836734693,0.9869070979224478,0.9868738036536329
21,0.05302287435995575,98.73877551020408,0.9873403079725396,0.9872954059811707
22,0.051020847064474545,98.75918367346938,0.987546174061273,0.9874996406295351
23,0.049328070838495545,98.82448979591837,0.988223099643424,0.9881774722071217
24,0.04741514052140378,98.86734693877551,0.9886361333179338,0.9885968684092326
25,0.04608863584366542,98.91224489795918,0.9890898122423017,0.9890617544422913
26,0.044346554936140814,98.94081632653061,0.9893685867699056,0.9893563610514274
27,0.04286319640156261,98.97755102040816,0.9897405639935808,0.9897107900683798
28,0.04175116247029406,99.0204081632653,0.9901871447644724,0.9901492476052688
29,0.04048962450608144,99.05102040816327,0.9904875256030339,0.9904486412530138
30,0.03944676967918892,99.08163265306122,0.9907817639033535,0.9907537858147046
31,0.03826343821356798,99.11632653061224,0.9911198649792347,0.9911079243743363
32,0.03717345794037899,99.14897959183673,0.991462405240128,0.9914416667565409
33,0.03594588493690012,99.1938775510204,0.9919302329272301,0.9918970431099705
34,0.03512201096264368,99.19795918367346,0.9919424260556011,0.9919284194599504
35,0.03416279359421554,99.21632653061224,0.9921563295428835,0.9921315337030958
36,0.03316992820561535,99.29183673469387,0.9929078168508717,0.992868512314136
37,0.03257369852440028,99.29795918367347,0.9929658424927377,0.9929443108928272
38,0.03130925391185494,99.34285714285714,0.9934106131123241,0.9934069535142112
39,0.030646426487390643,99.33469387755102,0.9933372518617691,0.9933168661421423
40,0.02969041015732761,99.38775510204081,0.9938643844414671,0.9938485578663272
41,0.0290970072285795,99.37755102040816,0.9937432351975293,0.9937341555780412
42,0.028167714917115557,99.42448979591838,0.994236493235108,0.9942247342692138
43,0.02745905214696928,99.47755102040816,0.9947525626163672,0.9947456376478593
44,0.02707800685091299,99.44897959183675,0.9944884566800051,0.9944623631464354

 Training with LR: 0.001, Batch Size: 64, Optimizer: SGD, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.9404885555294101,82.95102040816327,0.8356653855048514,0.8273233291705455
2,0.3070256348028195,93.86530612244897,0.9382954517054409,0.9382230610104457
3,0.20860497836344546,95.37346938775511,0.9534910727408816,0.9534243438708924
4,0.166560259713322,96.1530612244898,0.9613056288983548,0.96129319242071
5,0.1420072859381727,96.59591836734694,0.9657917492260021,0.9657614575346007
6,0.1250759514228638,96.99387755102042,0.9697937372578028,0.9697477783559698
7,0.1133724402723829,97.24285714285715,0.9723151994881702,0.9722681710847982
8,0.10364347289002673,97.42857142857143,0.9741536547836815,0.9741304849230827
9,0.09597222076840796,97.67959183673469,0.9766773141793486,0.9766836593425635
10,0.09005391726625339,97.81224489795919,0.9780098586481628,0.9779900064688004
11,0.08428521552086654,97.9469387755102,0.9793829691045692,0.9793542426700089
12,0.07970732641369882,98.02448979591837,0.9801518344378343,0.9801060444657109
13,0.07573947095976019,98.14897959183673,0.9814238477189614,0.9813607190934839
14,0.07233074656140555,98.2061224489796,0.9820084273337765,0.9819503175191462
15,0.06906348988948774,98.2326530612245,0.9822683127264675,0.9822068760875418
16,0.06627684500671475,98.32857142857144,0.9832411087125825,0.9831842080953299
17,0.06351064737307457,98.38571428571429,0.9838091438734144,0.9837698879946444
18,0.060819486390760374,98.49795918367347,0.9849290263536711,0.9849021389522321
19,0.05851333859369314,98.57959183673469,0.9857382769390505,0.9857029291471875
20,0.05650671404438682,98.64897959183673,0.9864462258893163,0.9863881478983147
21,0.054595088690772224,98.64285714285714,0.9864004638846614,0.9863243642240678
22,0.05289748092498096,98.72857142857143,0.9872594068480719,0.9871979461896947
23,0.050634482310107344,98.78367346938775,0.9878427846458461,0.987755664640309
24,0.049530630060726916,98.8,0.9879946755580973,0.9879117462008186
25,0.0477055030365477,98.86734693877551,0.9886549236663038,0.988618602061966
26,0.04603604519892941,98.93061224489796,0.9893141198825962,0.9892192515370274
27,0.04492666995257392,98.95714285714286,0.9895425584230255,0.9895139594912052
28,0.0436374436676084,98.96530612244898,0.9896598782151196,0.9895784229734932
29,0.042554947486823286,99.03265306122448,0.9903057899435911,0.9902575604297722
30,0.041312102338435325,99.06326530612245,0.9906389440253379,0.9905779253819691
31,0.040013638118345185,99.08775510204082,0.9908488782131318,0.9908218398321301
32,0.038899356895369566,99.12040816326531,0.9912244684140237,0.9911636347387922
33,0.038018892845017326,99.13673469387754,0.9913593645758484,0.9913176699394459
34,0.03676404506478741,99.18163265306123,0.9918187145157218,0.9917633514352298
35,0.03609924996393312,99.16326530612245,0.9916299763506433,0.9915972989985651
36,0.035163098366568765,99.2469387755102,0.9924799543166616,0.9924373660568431
37,0.03417639261963911,99.2530612244898,0.9925282690804297,0.9924728712059517
38,0.03322875935963644,99.29591836734694,0.9929626472098934,0.9929248413704974
39,0.03264952106000102,99.28775510204082,0.9928744271743992,0.9928298727553792
40,0.03175294788264944,99.3265306122449,0.9932855552501891,0.9932284581590458
41,0.030569305855600897,99.38571428571429,0.9938594504014446,0.9938181439549247
42,0.030067584466422586,99.39183673469387,0.9939417904501445,0.9938876440658724
43,0.029128795817333904,99.44081632653061,0.9944276996107038,0.9943785433518013
44,0.02824945993023601,99.44081632653061,0.9943986090665426,0.9943703908723268
45,0.027692484511937898,99.46938775510205,0.9947143801835658,0.994655755425077
46,0.027412739011833526,99.45306122448979,0.9945323856526306,0.9944942551901838
47,0.02628064406555457,99.5,0.9950001285297955,0.9949680619285605
48,0.026020171705271086,99.50204081632653,0.9950353187716002,0.9949892137925312
49,0.025325973575944495,99.51224489795918,0.9951368731923569,0.9950985263457319
50,0.0243153046044842,99.56938775510204,0.9957183755204244,0.9956734876351827

 Training with LR: 0.001, Batch Size: 64, Optimizer: Adam, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.3492049767998079,93.28163265306122,0.93336362307055,0.9318351196954584
2,0.08462572985088,97.6734693877551,0.976590213480954,0.9765639587254281
3,0.05882726742657431,98.38571428571429,0.9838108344796381,0.9837504085068784
4,0.04629980113178579,98.69183673469388,0.986874657496854,0.9868476431606241
5,0.038271287901451026,98.91632653061224,0.9891115108602211,0.9891015748547236
6,0.03149626882459273,99.10408163265306,0.9909761496274296,0.9909866583992055
7,0.02634580325099394,99.2734693877551,0.9927133912404958,0.9926750546785762
8,0.021457243728613743,99.39795918367346,0.9939704671732272,0.9939515983838891
9,0.018605680025593613,99.4857142857143,0.9948491172673176,0.9948422663818475
10,0.014619371912736377,99.65510204081632,0.996548019699787,0.9965358195140851
11,0.012776009655275197,99.68367346938776,0.9968326268589223,0.9968269266537432
12,0.01099130834089428,99.73673469387755,0.9973488171232472,0.9973471486776665
13,0.008909797271193546,99.78571428571429,0.9978539136569597,0.9978451786415615
14,0.008589209843042135,99.81428571428572,0.9981346338425114,0.998129584603291
15,0.006671869386217463,99.87551020408164,0.9987436029429875,0.9987507724452283
16,0.005034502610898888,99.91632653061224,0.9991512734307436,0.9991592399621887
17,0.006104801533048135,99.87142857142857,0.9986991364503958,0.9986908444542347
18,0.004474487062119042,99.92244897959183,0.9992227963550736,0.9992245788412963

 Training with LR: 0.001, Batch Size: 64, Optimizer: Adam, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.35808588520139845,92.91428571428571,0.9295254105770473,0.92810338459502
2,0.08773503969508581,97.7122448979592,0.9770853859544033,0.9769458847459715
3,0.06159226668575492,98.25714285714285,0.9825015429359263,0.9824510809868974
4,0.04830169822478438,98.65918367346939,0.9865669408628133,0.9865005636152185
5,0.03905250189562058,98.90612244897959,0.9890107862645733,0.9889822199839345
6,0.032146000916256225,99.0938775510204,0.9909053794307793,0.9908890026759147
7,0.02818933695292723,99.18775510204082,0.9918404994003496,0.9918322565684594
8,0.023948111825175193,99.30816326530612,0.9930667165819547,0.9930288288107196
9,0.019810683954161818,99.4795918367347,0.9947834044769109,0.9947418977134109
10,0.01880103618048822,99.47142857142856,0.9946985810195494,0.9946692993960319
11,0.014843061787025229,99.6,0.9960006545297887,0.9959837982643928
12,0.01275817455380259,99.69591836734693,0.9969550054053681,0.9969472450055757
13,0.010515297414259571,99.75102040816326,0.9975009053135885,0.997486586303712
14,0.010117533806846392,99.75918367346938,0.9975918929064461,0.9975637817419521
15,0.008117168367858283,99.83469387755102,0.9983526298701435,0.9983375497064155
16,0.006842047455542789,99.86938775510204,0.998689589447386,0.998681634730389
17,0.007301474408269829,99.81224489795918,0.9981136820809494,0.9981113215145356
18,0.005408573035496061,99.90816326530613,0.9990929694470883,0.9990699872094548
19,0.005173177675826732,99.90204081632653,0.9990178923569442,0.9990083228161275
20,0.004255145457806332,99.93673469387755,0.9993566590713268,0.9993598477011627

 Training with LR: 0.001, Batch Size: 64, Optimizer: Adam, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.33292096938364035,93.14285714285714,0.9314576489728028,0.9305435779281795
2,0.0868011830622627,97.65510204081632,0.9764247120556571,0.9763691823735835
3,0.061565631828526174,98.28367346938775,0.9827585811078681,0.9826861432381895
4,0.04793062725580995,98.65306122448979,0.9864815677051599,0.9864350371071444
5,0.04010457296122605,98.87551020408164,0.9887137002930437,0.988676269618862
6,0.0328469561521139,99.08979591836736,0.9908519358974133,0.9908198658215877
7,0.029051443193212404,99.18775510204082,0.9918346756079147,0.9918364295573427
8,0.02395158074264276,99.33877551020409,0.9933461984128563,0.9933292720244786
9,0.02041202601415893,99.4265306122449,0.9942289410993901,0.9942129129167
10,0.017780204064880834,99.5142857142857,0.9951211502174064,0.9951076324551087
11,0.01580228198505999,99.54285714285714,0.9953961760223352,0.9953855176736927
12,0.012828551764168665,99.66326530612245,0.9965986546021733,0.9966072670302702
13,0.011090400783573375,99.75102040816326,0.9974977689107336,0.9974851240848539
14,0.009986215211100288,99.76530612244898,0.9976550797272589,0.9976327510045264
15,0.007811794902544375,99.84285714285714,0.998427148997233,0.9984069925663845
16,0.007850206144858186,99.8061224489796,0.9980362153153732,0.9980254348514015
17,0.005895651194069251,99.90204081632653,0.9990179094314822,0.9990150905528129

 Training with LR: 0.001, Batch Size: 128, Optimizer: SGD, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,1.6332081016298996,66.46122448979592,0.7057272862235493,0.659510399117037
2,0.699505018580987,88.98163265306123,0.8899125300711628,0.8877801828343592
3,0.4077788272741258,92.63877551020408,0.9258672105579082,0.9256066070160113
4,0.29984228126218365,94.16326530612244,0.9412194947121613,0.9411393017548679
5,0.24353217728455445,94.95102040816327,0.9491528802933891,0.9491198460753487
6,0.2085838567261285,95.5204081632653,0.954884642867807,0.9548861450578473
7,0.1842920865776022,95.95918367346938,0.9593462950415892,0.959295918216424
8,0.16666464507579803,96.2734693877551,0.9624989474709172,0.9624705834984979
9,0.15248452311785352,96.56326530612245,0.96542044633369,0.9654288352985596
10,0.141359166662858,96.69183673469388,0.9667297766782641,0.9667058616623798
11,0.13189958943438282,96.9326530612245,0.9691578587695305,0.9691418763683203
12,0.12405968713270155,97.07142857142857,0.9705570460635495,0.9705457985430144
13,0.11734496930482805,97.19795918367346,0.9718264467496157,0.9718116445152472
14,0.11144487328302144,97.35510204081632,0.9734246840933306,0.9734153644895045
15,0.10619202172553882,97.4673469387755,0.9745373020578002,0.9745346629711559
16,0.10131508020523634,97.5530612244898,0.9754087569854295,0.9754118354907941
17,0.09733621495977705,97.61836734693877,0.9760769848343449,0.9760412138526121
18,0.09330601445532966,97.7265306122449,0.9771624402324497,0.9771578464129302
19,0.08987168592276834,97.80408163265307,0.9779518543776395,0.9779210632552859
20,0.08669213600962498,97.86530612244898,0.9785852297328127,0.9785410841580495
21,0.0837979464653111,97.96326530612245,0.9795516592946871,0.9795157236368469
22,0.08111254268814627,97.99183673469388,0.9798515977798858,0.9798242088530909
23,0.0783656742569672,98.13061224489796,0.9812355226044547,0.9812012527718688
24,0.07576391150975507,98.15510204081632,0.9814898051721856,0.9814596212360485
25,0.073812202577219,98.2326530612245,0.982260614838266,0.9822519083763355
26,0.07142551991767579,98.28571428571429,0.9827894165464341,0.9827669309335088
27,0.06948110918385553,98.36122448979592,0.9835497116663945,0.9835329957310333
28,0.06778102527146396,98.37959183673469,0.9837420981446489,0.9837149328975178
29,0.06595340238850048,98.41836734693878,0.9841389741502683,0.984111927629033
30,0.06434799099034647,98.4265306122449,0.9842077949806984,0.984191263553142
31,0.06252273897258638,98.51224489795919,0.9850802756179219,0.9850570296839098
32,0.06111156958454427,98.55510204081632,0.9855197282563914,0.9855015121077624
33,0.05960340787931382,98.61632653061224,0.986126994640925,0.9860980363251832
34,0.05800976177711555,98.65102040816328,0.9864749842604514,0.9864399216950777
35,0.05662340444194119,98.68571428571428,0.9868071847061014,0.9868129981028952
36,0.05554769051506843,98.71836734693878,0.9871364768756143,0.987118238255842
37,0.05426742258547336,98.7469387755102,0.987415970982305,0.9874125753955442
38,0.05310036307176473,98.7734693877551,0.9877132333180484,0.9876784592190159
39,0.05202933562331038,98.81632653061224,0.9881233232376083,0.9881100932125513
40,0.051123545575624346,98.84081632653061,0.9883711313805676,0.9883567173847025
41,0.04973331430571898,98.88367346938776,0.9888011028540176,0.9887963492730767
42,0.04895292014593633,98.87959183673469,0.9887818403867294,0.9887417284162137
43,0.0477643218329152,98.9469387755102,0.989429334076292,0.9894113184953579
44,0.047007092211502496,98.95714285714286,0.98952358239174,0.9895246825653775
45,0.04573520911765083,98.97755102040816,0.9897470732291138,0.9897238153600799
46,0.04479224374396216,99.0265306122449,0.9902370653202539,0.9902232641396825
47,0.04414596002762918,99.03673469387755,0.9903379068662856,0.9903285023713251
48,0.04329243180033199,99.04081632653062,0.9903965951390312,0.9903723014646031
49,0.04238145159406699,99.10612244897959,0.9910503387605875,0.9910141702287459
50,0.04165385524418896,99.10204081632654,0.9910160413869253,0.9909890300687302

 Training with LR: 0.001, Batch Size: 128, Optimizer: SGD, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,1.5500660185403052,70.64285714285714,0.7202995763131861,0.7032328672575612
2,0.648500713527047,90.2204081632653,0.9027460322709342,0.9006487493485684
3,0.3889328382967658,92.97755102040817,0.9294432594540887,0.929038146000568
4,0.2915201220204251,94.19999999999999,0.9416562172558898,0.941515399808203
5,0.24002225658134133,94.9265306122449,0.9489273375261981,0.9488964337747975
6,0.20692170067026472,95.50816326530612,0.9548026253381904,0.9547943106549447
7,0.18363166777490014,95.91020408163266,0.9588583456723624,0.9588776300002626
8,0.16604655846836672,96.20612244897958,0.9618314894520799,0.9618330129402629
9,0.15200395438596412,96.51632653061225,0.964952622070739,0.9649714638433847
10,0.14085876712132994,96.73877551020408,0.9671850846310444,0.9671865861526042
11,0.1314670247932794,96.93673469387754,0.9691855918391058,0.9691745014825013
12,0.12335583832183021,97.12244897959184,0.9710711394732338,0.9710614905391042
13,0.11636142105875688,97.25918367346938,0.972454565469451,0.9724368690840152
14,0.11032180230354516,97.3530612244898,0.9734029926907632,0.9733836157813244
15,0.10501284095855046,97.48979591836735,0.9747770435968819,0.9747684607926619
16,0.1003399969081032,97.57142857142857,0.9755963640194333,0.9755646938189619
17,0.09611725364629345,97.68163265306123,0.9767143448914958,0.9766870014900861
18,0.09236119871390083,97.74489795918367,0.9773435344118925,0.9773275591798566
19,0.08882056893513346,97.85714285714285,0.9784726504634158,0.9784605783683997
20,0.08574722826908836,97.93877551020408,0.979290794543257,0.9792999604033008
21,0.08266127369227982,98.0,0.9799251883658326,0.9799063192763684
22,0.07984153694392962,98.03469387755102,0.9802613124325521,0.9802372500105392
23,0.07763457710686925,98.14693877551021,0.9813831863055242,0.9813722187773253
24,0.0752600597475434,98.2204081632653,0.9821256460535791,0.9821194012236756
25,0.07303073854421512,98.22857142857143,0.9822016050313392,0.9821690797974991
26,0.07090664738132654,98.27755102040815,0.98271972035974,0.9826785499148464
27,0.06903795154847925,98.34693877551021,0.9834282880360969,0.9833873527956467
28,0.06709460521666406,98.40204081632653,0.9839545913665797,0.9839276429444496
29,0.06548040417112974,98.41836734693878,0.9841478414976443,0.9841031588655635
30,0.06397370918223504,98.46122448979592,0.9845480468024139,0.9845330145822506
31,0.06241444102427667,98.51020408163265,0.9850482269691268,0.9850239832338372
32,0.06100942699272701,98.56938775510204,0.9856352345315983,0.9856191051241684
33,0.059637129297066604,98.60408163265306,0.985998090236728,0.9859708862564321
34,0.05789791079670891,98.63061224489796,0.9862834107009503,0.9862411147213257
35,0.05691441670595121,98.67755102040816,0.9867486533941616,0.9867042892284568
36,0.05550933860767603,98.68163265306123,0.9867805118226644,0.9867406418638474
37,0.05443114165810008,98.71632653061224,0.9871153199210936,0.9870892346980188
38,0.053303951266229,98.8,0.9879832580646564,0.987922912296334
39,0.052218024100981864,98.7795918367347,0.987781228789372,0.9877429037419896
40,0.0512472050381197,98.83673469387755,0.9883407713668217,0.9883024322187435
41,0.050315727212274196,98.84897959183674,0.9884631854181587,0.9884333408092733
42,0.049291277861139945,98.88163265306122,0.988783799699284,0.9887491790720029
43,0.04840685817712125,98.96326530612245,0.9896118818528203,0.9895776625585355
44,0.04740656067084706,98.92040816326531,0.9891810250422763,0.9891550354483002
45,0.046498365177439806,99.00204081632653,0.9900230644620525,0.9899702014216777
46,0.04539925732477215,98.98163265306123,0.9898037271399754,0.9897617461837281
47,0.044870024605340494,98.99183673469388,0.9898971779995762,0.9898666216836809
48,0.04374796987873534,99.0734693877551,0.9907343848361437,0.9906765597702687
49,0.04315768548484415,99.04285714285714,0.990434847719593,0.990385119083499
50,0.04248356300481539,99.0530612244898,0.9905296715145326,0.9904889230225496

 Training with LR: 0.001, Batch Size: 128, Optimizer: SGD, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,1.3271040788829793,72.64489795918368,0.7290599912735394,0.7220050870211366
2,0.5380479053791136,90.73673469387755,0.9071542601973721,0.906235429517771
3,0.34239707179075746,93.3265306122449,0.9328630104775184,0.9326802481171532
4,0.26131496494806156,94.56734693877551,0.9453160651709899,0.9452302685613903
5,0.21688379304527303,95.31632653061224,0.9528633954985037,0.9528000710840339
6,0.1879709785702023,95.78571428571429,0.9575865848286391,0.957532842088637
7,0.16733928752318997,96.17142857142858,0.9614616104461942,0.9614256483899393
8,0.15212542845748422,96.44489795918368,0.9642356782194732,0.9641787301855441
9,0.14014045431159494,96.7469387755102,0.9672753157038118,0.9672316997713578
10,0.13034757903677366,96.96938775510205,0.9695277297623888,0.9694950415344016
11,0.1219883290637411,97.14897959183673,0.9713257509038098,0.971281651550046
12,0.11524645216743566,97.29387755102042,0.9727713954396879,0.9727449349625491
13,0.10920667659014698,97.45510204081633,0.9743957783466062,0.9743682830418162
14,0.10390704206869435,97.56122448979592,0.9754902225393274,0.9754635723172012
15,0.09963250482167961,97.67959183673469,0.9766708147684555,0.9766400898840237
16,0.09546087801884422,97.77346938775511,0.9776239117405862,0.9775868349495512
17,0.09164714342464667,97.85714285714285,0.9784534042935713,0.9784378945208134
18,0.0885231035029608,97.91224489795918,0.9790385286681154,0.9789911496393897
19,0.08538238772290804,97.99183673469388,0.9798173600723086,0.9797840678387901
20,0.08228140439128129,98.07142857142857,0.9806472728041482,0.9805851244273682
21,0.07962333979012139,98.12448979591836,0.9811635765623403,0.9811215982911676
22,0.07750381014307392,98.1265306122449,0.981196998178558,0.9811295886634323
23,0.07530018207726528,98.2265306122449,0.982184997705725,0.9821550591950995
24,0.0730544950316998,98.2734693877551,0.982689333005028,0.9826138940112641
25,0.0712560036173455,98.3204081632653,0.9831315900366263,0.9830733434280564
26,0.06950976747737385,98.35918367346939,0.983545602573885,0.9834817226651431
27,0.06751859829549534,98.39591836734694,0.9838818591979729,0.983849345170819
28,0.06576295983406177,98.44081632653061,0.984352191676544,0.9843030177201152
29,0.06422685697071702,98.47551020408163,0.9846997416167316,0.9846768127160196
30,0.06269207080782394,98.53265306122448,0.9852699804041543,0.9852505334800211
31,0.06142851519678031,98.55510204081632,0.9855010225614885,0.9854638686976749
32,0.060176588385791444,98.58979591836736,0.9858486459525754,0.9858169986962098
33,0.058779300455558396,98.61632653061224,0.9861119285478338,0.9860802600425222
34,0.05760123089014239,98.63061224489796,0.9862506321428468,0.986224764183396
35,0.056470392544221315,98.67142857142858,0.9866773058258179,0.9866495561098414
36,0.05509121090601692,98.72448979591837,0.9871828133607788,0.9871855074252858
37,0.054333409168040164,98.7204081632653,0.9871655997363552,0.9871085315717162
38,0.05340312571111609,98.73877551020408,0.9873535424592106,0.9873214906307979
39,0.052130616673659876,98.76938775510204,0.9876369594961829,0.9876302554480176
40,0.051201248132956866,98.8265306122449,0.9882136168756219,0.9881982482573575
41,0.050009668880086344,98.84489795918367,0.9883958823530736,0.9883847384688427
42,0.04936003253622559,98.8,0.987935865983002,0.9879321110984227
43,0.048265524758098956,98.85918367346939,0.9885647069746749,0.9885212047223672
44,0.047832464281343134,98.90612244897959,0.9890230229928776,0.9890018379718246
45,0.04678877691589977,98.91632653061224,0.9891179953714854,0.9891051478169979
46,0.0460629817657659,98.92244897959183,0.9891857882375936,0.9891729439428504
47,0.045016384126701184,98.96122448979592,0.9895681643206717,0.9895574625315401
48,0.04432712373501249,98.9795918367347,0.9897598887814592,0.9897292343251101
49,0.04357083420471018,99.00204081632653,0.9899862662100499,0.9899732660342666
50,0.04275873359098213,98.99591836734693,0.9899360723959434,0.9899058127443838

 Training with LR: 0.001, Batch Size: 128, Optimizer: Adam, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.5297703178059651,90.45102040816326,0.9056628220889129,0.9032703839849306
2,0.11408026228529977,97.2204081632653,0.9721251785667272,0.9719983278013702
3,0.07506544077793238,98.05102040816327,0.9804316583114886,0.9803975283864477
4,0.056801378889879885,98.48367346938775,0.9847792406183611,0.9847614892962655
5,0.04584696532200351,98.78979591836735,0.9878488349681553,0.9878194563555669
6,0.03839241303795311,98.98367346938775,0.9897990614064289,0.9897864066154787
7,0.03307673876482614,99.14489795918368,0.9914313980724915,0.9913993439659127
8,0.027720705545252047,99.2938775510204,0.9929165405318867,0.9929052567802111
9,0.023901838761226667,99.41632653061224,0.9941591970734812,0.9941237778345794
10,0.02011195734792508,99.48163265306123,0.9948185532570397,0.994782118826589
11,0.017131006753670328,99.64489795918368,0.9964296501530308,0.996440821272669
12,0.014637268804300664,99.70204081632653,0.9969984423872124,0.9970021100007571
13,0.012861906370274508,99.72448979591837,0.9972299018123947,0.9972490123105988
14,0.010467398468546043,99.81632653061224,0.9981580274989532,0.9981521801557228
15,0.009070625581885578,99.84693877551021,0.9984613014327854,0.9984564049915153
16,0.0072341671860326985,99.90204081632653,0.9990192910782026,0.9990171881183416
17,0.006178159480087712,99.92857142857143,0.9992852046494543,0.9992722578170735
18,0.005792301973417966,99.91836734693878,0.9991796066735947,0.9991783944375922
19,0.004654148587389842,99.95918367346938,0.9995978819507796,0.9995872189621366

 Training with LR: 0.001, Batch Size: 128, Optimizer: Adam, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.5302270193907673,90.03469387755102,0.9035481020338354,0.8987526197201092
2,0.11051483614754427,97.38571428571429,0.9737300298789104,0.9736990302004951
3,0.07503624065893437,98.06734693877551,0.9805820190578366,0.9805632943213493
4,0.05785003198704661,98.5061224489796,0.9849771130688201,0.9849633854935916
5,0.04786576451758025,98.7408163265306,0.9873893743299786,0.9873307558789142
6,0.04070483273084886,98.94285714285715,0.9894168884963104,0.9893641569264069
7,0.03426655415474746,99.0938775510204,0.9908836839426319,0.9908778820937485
8,0.03013786725096852,99.19183673469388,0.9918813410865057,0.9918851786521984
9,0.026091335396046505,99.2938775510204,0.9929212032155643,0.9928991927447086
10,0.022903336118420405,99.4265306122449,0.9942506687941393,0.9942238001336117
11,0.019128338717089542,99.5142857142857,0.9951471016302589,0.9951116683318361
12,0.01626530951910285,99.63673469387754,0.996343042951047,0.996354638534067
13,0.014100578796257103,99.69795918367346,0.9969690845288547,0.9969706401237051
14,0.012735994453371719,99.73673469387755,0.9973609289515606,0.9973571428050183
15,0.010546854818142541,99.79795918367347,0.9979792177549978,0.9979636115717181
16,0.009163517411007951,99.82857142857144,0.9982864579293356,0.9982882862035118

 Training with LR: 0.001, Batch Size: 128, Optimizer: Adam, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.45582888289002155,91.34285714285714,0.9143075509698206,0.9122084962083598
2,0.11333771228945909,97.10408163265306,0.970860553445933,0.9708561035820595
3,0.07806717929267386,97.89591836734694,0.9788297491495104,0.9787880970684345
4,0.06118957525211588,98.3061224489796,0.9829469899507426,0.9829341496319752
5,0.05011411525513344,98.60816326530613,0.9860153181954188,0.9859823508771977
6,0.04331371320202441,98.80204081632652,0.9879729107117814,0.9879138393599105
7,0.03746310980411796,98.9469387755102,0.9894066116070961,0.9893917527517917
8,0.03206917779233219,99.11428571428571,0.991116364473229,0.9910653356254606
9,0.028011395390493205,99.28367346938775,0.9928124385573127,0.9927742839253131
10,0.02494409373431289,99.31632653061224,0.9931483506380921,0.9931190501525495
11,0.022116750198496658,99.41224489795918,0.9940939528020631,0.9940846298452566
12,0.019347341044857008,99.48163265306123,0.9948044962556384,0.994771665063063
13,0.016237188458890113,99.60408163265306,0.9960363812162454,0.9960144055829396
14,0.01451500333959903,99.63469387755102,0.9963414258579977,0.9963131044178555
15,0.01294698845807891,99.67959183673469,0.9967918247242447,0.9967854664176803
16,0.010528138511651257,99.78571428571429,0.9978662473006541,0.9978562249221101
17,0.00978830874217893,99.7938775510204,0.9979323166971742,0.9979290075338927

 Training with LR: 0.005, Batch Size: 32, Optimizer: SGD, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.3157776577553807,92.88979591836734,0.9288411915041003,0.9281093940860519
2,0.09471533383369232,97.49591836734693,0.9748403675330154,0.9747669663406505
3,0.0703811944649596,98.09183673469389,0.9808385082387231,0.9807907451411548
4,0.05739607809958906,98.4265306122449,0.9841713266636145,0.984151618242942
5,0.049201419924804694,98.59183673469389,0.9858581190821815,0.9858217168590835
6,0.04201883321044986,98.83061224489796,0.9882533412963369,0.988232395649437
7,0.036174800871888436,99.04693877551021,0.9904069600126462,0.9904025442657579
8,0.03222496181371739,99.12857142857143,0.9912449294182732,0.9912215641024261
9,0.02802834314660883,99.25714285714285,0.9925383087864654,0.992517040630849
10,0.024628659386156486,99.4,0.993955933702767,0.9939461086190488
11,0.02188350829286999,99.47755102040816,0.9947710168924839,0.9947419173612151
12,0.019050158702993085,99.56122448979592,0.995601694557201,0.9955704107817279
13,0.016646679283268906,99.63673469387754,0.9963548436485045,0.9963495565160846
14,0.014206705880753347,99.70816326530613,0.997079249963582,0.9970786739381925
15,0.012784649106762727,99.78163265306122,0.9977979523039453,0.9977989547228041
16,0.011625073825239945,99.83061224489795,0.9983146352078404,0.9983027205840316
17,0.009838865718140306,99.86530612244898,0.9986486868859025,0.9986497946298283
18,0.00856624633100327,99.92040816326531,0.9992146564171588,0.9991988468810167
19,0.007570502190922979,99.93469387755101,0.999353745635703,0.9993468382864151
20,0.0063376949379583,99.95918367346938,0.9995940129428831,0.9995967502543669
21,0.005924070466657018,99.96122448979592,0.9996106114719769,0.9996049167908827
22,0.005180876261713324,99.98775510204082,0.9998861452080705,0.9998718275935696
23,0.004582323888989919,99.99591836734693,0.9999590871279903,0.9999593454375869
24,0.004119237247268709,99.99183673469388,0.9999216605377477,0.9999162189276163
25,0.003724099000880341,99.9938775510204,0.9999382146587772,0.999941415804973
26,0.0033333303064137947,100.0,1.0,1.0

 Training with LR: 0.005, Batch Size: 32, Optimizer: SGD, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.30869947850106005,92.99795918367347,0.9295614749970305,0.9291892893250345
2,0.09588528963385816,97.35918367346939,0.9735144616494008,0.973384051753151
3,0.07087367471075294,97.97755102040816,0.9796628046437512,0.9796040579315175
4,0.057977313841766055,98.39795918367346,0.9838958338454586,0.9838673841317064
5,0.04961941417111521,98.61836734693877,0.9861187644383481,0.9860614644171003
6,0.04323979265539234,98.80816326530612,0.9880143549139706,0.9879970624465464
7,0.03843119275003432,98.94285714285715,0.9893643721470203,0.9893448293372341
8,0.03441869797255429,99.06938775510204,0.9906606020295422,0.9906250548081694
9,0.029825969789312137,99.23265306122448,0.9922704152365427,0.9922726168085315
10,0.027084987579954926,99.3061224489796,0.9930395225779609,0.9930037924564719
11,0.024540906136178573,99.38367346938776,0.9938033646776916,0.9937769324231311
12,0.02150072719149584,99.47142857142856,0.9946882683851423,0.9946882024105156
13,0.019928613729369472,99.53469387755102,0.995332272714653,0.9953070905325984
14,0.017706014506614055,99.58367346938776,0.9958290439289831,0.9958134069360444
15,0.016127833807412364,99.65918367346939,0.9965774085644549,0.9965713233311015
16,0.014522538544227841,99.73877551020408,0.9973776397020566,0.9973787035450101

 Training with LR: 0.005, Batch Size: 32, Optimizer: SGD, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.2739387445046029,93.5530612244898,0.9351832019491774,0.9347621144035433
2,0.093240414255216,97.43877551020408,0.9742740647032093,0.9741716093876933
3,0.06991020263724063,98.07959183673469,0.9807147080918002,0.9806568905638875
4,0.05830109203725205,98.33061224489796,0.9832384003824588,0.9831880677904735
5,0.050057488008126906,98.58367346938776,0.9857797585489179,0.9857604986023878
6,0.04343447756805207,98.79795918367347,0.9879319106803462,0.9878882986276292
7,0.03777652888758808,98.99591836734693,0.9899091845671946,0.9898903276702627
8,0.03400644797270366,99.06326530612245,0.9905910712024415,0.9905483162586666
9,0.030351303341827663,99.18775510204082,0.9918512198377369,0.9918302447877476
10,0.027134449829524638,99.29795918367347,0.9929647022637133,0.9929325761101545
11,0.02414564066433546,99.37959183673469,0.9937880703737761,0.9937497860180198
12,0.02165150293204146,99.48163265306123,0.9948218765625955,0.9947987545356369
13,0.019850125079210083,99.5142857142857,0.9951511931940326,0.9951149410501307
14,0.01757530405798361,99.61020408163266,0.9961180577702138,0.9961074381068109
15,0.01570355444298712,99.65918367346939,0.9965997697276817,0.9965688358504143
16,0.014115371760674698,99.73265306122448,0.9973313331448359,0.9973123485837403
17,0.01271188074339654,99.77551020408163,0.9977526309784268,0.9977533245548376
18,0.01152545008706359,99.81224489795918,0.9981247567269195,0.9981098703896908
19,0.010225900728593662,99.86122448979592,0.9986117101382043,0.9986089764337491
20,0.00902268965218504,99.88979591836735,0.9989085668423952,0.9988989806907664
21,0.008100463534234513,99.89387755102041,0.9989440051249672,0.9989391790411905

 Training with LR: 0.005, Batch Size: 32, Optimizer: Adam, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.14875927958567567,95.91632653061225,0.9589931164614844,0.9586875950873701
2,0.05903037566893464,98.14693877551021,0.9813315917351659,0.9813427642215414
3,0.04477496683843694,98.63877551020408,0.9862901270531742,0.9862658460911131
4,0.03834031916269022,98.73877551020408,0.987306075785361,0.9872692286306674
5,0.03072372888915772,99.03265306122448,0.990253865594162,0.9902652201656814
6,0.026615600474865542,99.1265306122449,0.9912087130460161,0.9911769739951662
7,0.023629114776393574,99.17959183673469,0.9917359786150767,0.9917365414244326
8,0.021280812015738632,99.25918367346938,0.9925310396571436,0.9925398557728171

 Training with LR: 0.005, Batch Size: 32, Optimizer: Adam, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.15563688184409438,95.66326530612244,0.9564272900547207,0.956160417049795
2,0.060745181958895896,98.07755102040817,0.9806302830837191,0.9806097116898401
3,0.04552377749262706,98.53877551020408,0.9853141329812998,0.9852863129036166
4,0.0393438479456252,98.76530612244898,0.9875657043408879,0.9875560744395443
5,0.030840817797279457,98.97755102040816,0.989704458190525,0.9896785344743714
6,0.029220474920759215,99.05714285714285,0.9905046377137847,0.9904888913081301
7,0.022527545030937932,99.25714285714285,0.9925151028004976,0.9925005182706952
8,0.020354835243300742,99.29591836734694,0.9928884731327681,0.9928952550857002

 Training with LR: 0.005, Batch Size: 32, Optimizer: Adam, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.13751680918819667,96.11224489795919,0.9609601205749003,0.960725196187523
2,0.06002135942192726,98.08367346938776,0.9806942162492831,0.980684276038059
3,0.04784057944914336,98.47755102040816,0.9846814585005902,0.9846424457945002
4,0.040289524908650357,98.7469387755102,0.9873657896191048,0.9873424078377706
5,0.03360223788290651,98.9,0.9889437504622416,0.9889134752757665
6,0.02866904058044255,99.05102040816327,0.990461849395525,0.9904270859350591
7,0.02428254495854986,99.16122448979591,0.9915507850201226,0.9915287224505818
8,0.02084770991626531,99.31428571428572,0.9930907175087276,0.9930826729098519
9,0.018146702160442913,99.39795918367346,0.9939328824488193,0.9939212941127064
10,0.016253840576225843,99.4,0.9939602401208136,0.9939372047260162
11,0.014045479233921465,99.49795918367347,0.9949340416203485,0.9949344921908561

 Training with LR: 0.005, Batch Size: 64, Optimizer: SGD, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.4799517137205165,90.0673469387755,0.9016898470990864,0.8994497109148346
2,0.1234695284795162,96.89591836734694,0.9687719081932276,0.9687445565034146
3,0.08915076961658175,97.69795918367346,0.976847545129754,0.976833307985651
4,0.07229822894738253,98.12040816326531,0.9811173612310938,0.9810789417074502
5,0.06147670518976512,98.38163265306122,0.9837288251911447,0.9837230265264909
6,0.05404310651468818,98.58775510204082,0.98580427876827,0.9857691446123387
7,0.047323383244396465,98.76326530612245,0.9876003634169471,0.987573446144016
8,0.04239768489062125,98.90816326530613,0.9890322487356004,0.9890361356776334
9,0.038538981207789896,98.98979591836735,0.9898509865890999,0.9898613668988429
10,0.034954900244207124,99.11632653061224,0.9911608235319536,0.9911340216851336
11,0.03192763211869443,99.18571428571428,0.9918426223765036,0.9918110872289656
12,0.029125668563182144,99.25102040816327,0.992486236233793,0.9924775346049962
13,0.026339203561534595,99.37959183673469,0.9937903877412648,0.9937638009369417
14,0.024356321363002257,99.45918367346938,0.9945933216873929,0.9945510624327417
15,0.02213631584731541,99.48163265306123,0.9948109245618951,0.994781134003033
16,0.02058807195801964,99.55510204081632,0.9955433028941956,0.9955308116498081
17,0.018591487746322213,99.63673469387754,0.9963754055897528,0.9963522437990049
18,0.017306988407473516,99.67346938775509,0.9967409652454142,0.9967190924182046
19,0.015379059670417625,99.7204081632653,0.9972051422662348,0.9971905143782136
20,0.014406018892872116,99.7795918367347,0.9977956344016292,0.9977993860078899
21,0.013244440915718353,99.78979591836735,0.9979032324004813,0.9979024661421374
22,0.012360742143610633,99.82244897959184,0.9982252623820733,0.998225245515248
23,0.010965861810882535,99.86938775510204,0.9987003456176566,0.9986931722585431
24,0.01031634711267429,99.87959183673469,0.9988041186904763,0.9987874936182749
25,0.009733582096883794,99.88979591836735,0.9989092013306031,0.9988957638032143
26,0.008820643859526979,99.91020408163264,0.9991110811332797,0.9991060608391681
27,0.007991113882270513,99.94489795918368,0.9994617881669157,0.999453333501448
28,0.007423407315336138,99.95102040816326,0.9995090244164491,0.9995020663050831
29,0.006866194197087969,99.95306122448979,0.9995399029174171,0.9995338365053161

 Training with LR: 0.005, Batch Size: 64, Optimizer: SGD, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.46160941862795435,90.00408163265307,0.9003413356975667,0.8989719358249223
2,0.12309148966021077,96.93877551020408,0.9693171605695874,0.9692329591736328
3,0.08948546930583433,97.65102040816328,0.9764562954154126,0.9763917264676769
4,0.0725822925176131,98.08979591836734,0.9808656955826377,0.9807946806114275
5,0.06270543105448001,98.31836734693877,0.9831410515906308,0.9830986701295894
6,0.05439904119269849,98.57959183673469,0.9857423239358735,0.9857264174306865
7,0.04871238339765304,98.67959183673469,0.9867435619225882,0.9867224922083822
8,0.04388600694442377,98.85102040816327,0.988492773465526,0.988453528138208
9,0.039473604072279275,98.96530612244898,0.989627078452564,0.9895984009602732
10,0.03612392787777821,99.1,0.9909931215564697,0.9909500287280719
11,0.0332097702817116,99.11836734693877,0.9911588394284919,0.9911323974073782
12,0.030479316670488928,99.21836734693878,0.9921753068222243,0.992147843815143
13,0.02779668987869691,99.34897959183674,0.9934754327461551,0.9934670206960232
14,0.025669228158497273,99.39183673469387,0.9939215357991685,0.9938843479125191
15,0.02348239808774969,99.46938775510205,0.9946867911068855,0.994675182700948
16,0.02183560642301939,99.5204081632653,0.9952181163131387,0.9951999356052618
17,0.020318830151453752,99.57959183673469,0.9958013249681171,0.9957801560131049
18,0.018388834607017814,99.62040816326531,0.9962273082465526,0.9961916579639695
19,0.017153856309414076,99.68163265306123,0.9968309242575014,0.9968129834200814
20,0.01585862482821948,99.71020408163265,0.9971003517707148,0.9970994757344155
21,0.014415374664618943,99.76734693877552,0.9976855601490074,0.9976600627312475
22,0.013624993254285908,99.7734693877551,0.9977443002992377,0.997749158499977
23,0.01252626207220677,99.83673469387755,0.9983819513391262,0.9983628702850493
24,0.01161035212053487,99.84897959183674,0.9985097031750627,0.9984946311439273
25,0.010641559019460472,99.8734693877551,0.9987496475754402,0.9987342895065332
26,0.00984885128733657,99.88979591836735,0.9988961576211132,0.9988959445366239
27,0.00900396525278668,99.93265306122449,0.999324800930671,0.999318142144175
28,0.008495285126423785,99.91836734693878,0.9991866141881923,0.9991975536691667
29,0.007667517413951483,99.95306122448979,0.9995354955845135,0.999539523538127
30,0.007287837410307375,99.95714285714286,0.9995761896691654,0.9995735664232971
31,0.0069060190480099695,99.95510204081633,0.9995500605875473,0.9995474207826076
32,0.00638786798820882,99.97755102040816,0.9997792553278846,0.9997743781715286

 Training with LR: 0.005, Batch Size: 64, Optimizer: SGD, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.40618501633755844,90.97755102040817,0.9099815260350278,0.9084489579130345
2,0.1257943401390361,96.73877551020408,0.9671884326936022,0.9671933248394208
3,0.09238811554849226,97.52244897959184,0.9750995200330828,0.9750783592109752
4,0.07544015135552841,97.95918367346938,0.9795339593521218,0.9794575545915898
5,0.06453371437159476,98.17346938775509,0.9816578255902039,0.9816137675759133
6,0.05602042827093803,98.45714285714286,0.9844959752236264,0.9844794590063612
7,0.050379177758484765,98.59591836734694,0.9859077838271271,0.9858647159536812
8,0.04562352823188368,98.72857142857143,0.9872495695925352,0.9872331097656526
9,0.04152878459880989,98.88163265306122,0.9887901040191529,0.9887267239241128
10,0.03839016980558449,98.96938775510205,0.9896763474180015,0.9896152699388209
11,0.03490769589902206,99.11020408163266,0.9910666856157653,0.9910543390535308
12,0.031610162442370124,99.19591836734693,0.9919480556156375,0.9919110215624393
13,0.029652332566987342,99.28367346938775,0.9928098502997382,0.9927855954042035
14,0.027181128882219425,99.35510204081632,0.993550659739683,0.9935330790291792
15,0.02510616913490732,99.41632653061224,0.9941589395805497,0.9941216696338129
16,0.023457400860658825,99.44897959183675,0.9944864473557461,0.994452964104787
17,0.02144372709765398,99.52857142857144,0.9952792977349437,0.9952657764644413
18,0.01990453923147235,99.58163265306122,0.9958049212947145,0.9957972919632387
19,0.01849384559424808,99.61836734693877,0.9961804690976491,0.9961661922321348
20,0.016989195119655222,99.70408163265306,0.997044498868336,0.9970223797474503
21,0.016084545630719708,99.68979591836735,0.9969040610479979,0.9968830626697057
22,0.014580649330752461,99.74897959183674,0.9974956586953292,0.9974859765795208
23,0.013603416417558816,99.79591836734694,0.9979583302923045,0.9979568285126156
24,0.012778481278053604,99.81020408163266,0.998117801280328,0.9980973738259042
25,0.011753368538235345,99.83673469387755,0.9983787020956256,0.9983638570004658
26,0.010943250092629139,99.84081632653061,0.9984115284487085,0.9984143338203537
27,0.009927095596629314,99.90204081632653,0.9990306245808739,0.9990128637964626
28,0.009557042523486632,99.90204081632653,0.9990320966307268,0.9990265052272799

 Training with LR: 0.005, Batch Size: 64, Optimizer: Adam, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.17558708259539177,95.57755102040815,0.9554644996617272,0.9553027263168236
2,0.056866110360867514,98.22244897959183,0.9821000355202681,0.9820790673539144
3,0.04151524981063141,98.66326530612245,0.9865581127738279,0.9865130434881737
4,0.032337515685292736,99.0,0.9899551075467379,0.9899123435138073
5,0.02488224731703373,99.22448979591837,0.9922005055953834,0.9921824984668405
6,0.02152739391105484,99.27551020408163,0.9927057274043409,0.9926823324952456
7,0.018698445688357136,99.35306122448979,0.9934982301960738,0.9934971433804117

 Training with LR: 0.005, Batch Size: 64, Optimizer: Adam, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.1671146696418835,95.67551020408163,0.9567992820105145,0.9563364351108923
2,0.05981295036976335,98.11632653061224,0.981063309100412,0.9810415885986086
3,0.04368981461733088,98.62040816326531,0.9861258438128526,0.9860922982756017
4,0.03488637779580366,98.87755102040816,0.9886961068633724,0.9886565061620137
5,0.028441518742722452,99.10612244897959,0.9910144717663714,0.9910090741463501
6,0.02546382431047555,99.15510204081632,0.9915110810824272,0.9914880706861988
7,0.02079414683178325,99.32040816326531,0.9931627785346541,0.9931369832258687
8,0.018116341800555526,99.40408163265306,0.9939898875732606,0.9939912806669937
9,0.015644523930491504,99.4857142857143,0.994825876667441,0.9947958881591136
10,0.015251795004122187,99.46734693877552,0.9946322718105473,0.9946277222277683
11,0.010697108387283308,99.6,0.995974399825428,0.9959690829709646

 Training with LR: 0.005, Batch Size: 64, Optimizer: Adam, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.16082782455350397,95.68775510204081,0.9567754884156872,0.9563864860497052
2,0.060726230486700984,98.09183673469389,0.9807848310468845,0.9807675772391592
3,0.044790029950080044,98.52857142857144,0.9851916423501705,0.9851707868826457
4,0.03704002205548108,98.7938775510204,0.9878775217494213,0.9878433852309213
5,0.029549474486298178,99.04693877551021,0.9904046480340682,0.9903952185142655
6,0.025302343770746732,99.16938775510205,0.9916586616023757,0.9916274432323131
7,0.02110500276267593,99.3061224489796,0.9930097577103358,0.9930031440081315
8,0.019228612299745308,99.35510204081632,0.9934895618403946,0.9934918841218124
9,0.01776098992317862,99.38367346938776,0.9938001285999501,0.9938095793811262
10,0.013215002653079351,99.57755102040817,0.9957548789913245,0.9957373875540141
11,0.011799599490233018,99.62448979591836,0.9962066254395594,0.9962021909604024

 Training with LR: 0.005, Batch Size: 128, Optimizer: SGD, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.7328593028276459,85.72448979591837,0.8595449392834296,0.8550957374523863
2,0.18514892655393161,95.89795918367346,0.958641258459689,0.958679229011104
3,0.12888413927379228,96.88775510204081,0.9686748870325476,0.9686800364076739
4,0.10356917786691582,97.40612244897959,0.9739245496939551,0.9738862091501174
5,0.08760868671882713,97.81632653061224,0.9780441294902102,0.9780322418054477
6,0.07764552797217593,98.04081632653062,0.9803300409947313,0.9802930523956223
7,0.07006901390753278,98.20816326530613,0.9820193007097094,0.9819636353851594
8,0.06360647603674906,98.32244897959184,0.9831571250454351,0.9831037488608516
9,0.05861928897566957,98.5734693877551,0.9856748179796447,0.9856318529767648
10,0.054782567837569796,98.57755102040817,0.9857482758832529,0.9856699938428533
11,0.05037589155273711,98.75102040816327,0.9874912876950372,0.9874240075321706
12,0.047538534062124264,98.79591836734693,0.9879242198373293,0.9878814847535737
13,0.04436696091467422,98.88571428571429,0.9888362482408437,0.9887875146487959
14,0.041509809164578394,98.98163265306123,0.9897831490101543,0.9897306151732653
15,0.03877678955479601,99.08979591836736,0.9908700821522467,0.9908477629891822
16,0.036538791108399866,99.14897959183673,0.9914724184024415,0.9914534830199047
17,0.034555153622153376,99.18163265306123,0.9918147260965746,0.9917822890670159
18,0.03253841927571723,99.24897959183674,0.9924813348732554,0.9924318422845767
19,0.030857054122745524,99.32244897959184,0.9932175888067958,0.9931819793285047
20,0.02927068622136007,99.33469387755102,0.9933512755119175,0.9933212118412127
21,0.027610535267740488,99.37959183673469,0.9937948792859628,0.9937632032420387
22,0.025618441637566523,99.48163265306123,0.9948188761686098,0.9947911615762415
23,0.024596094471152005,99.52857142857144,0.9952873196484869,0.9952761936589954
24,0.023266206060198205,99.54081632653062,0.9954170754686729,0.9953886931085748
25,0.02221595382016376,99.56530612244899,0.995651436933706,0.9956200033145468
26,0.020542712527140003,99.63265306122449,0.9963334631259521,0.9963213270959972
27,0.019610495383756397,99.68775510204082,0.9968995642255253,0.9968627952687742
28,0.018441226971688297,99.7204081632653,0.9972154223638778,0.997191921564694
29,0.017690273683260416,99.73265306122448,0.9973505568963684,0.997324321940779
30,0.0170482983776215,99.7265306122449,0.9972858715113524,0.9972556925068977
31,0.015844713541491848,99.79183673469387,0.9979264371071231,0.997929099114466
32,0.015383372374496595,99.78775510204082,0.9978826380284467,0.9978754462978575
33,0.014290964461294034,99.83265306122449,0.9983487317339084,0.9983198173734606
34,0.013670597870423223,99.84285714285714,0.9984308957535533,0.9984293757569507
35,0.013502161433754913,99.81836734693877,0.9981849057316202,0.9981745914565249
36,0.012227788340183602,99.87755102040816,0.9987857883982116,0.9987701673680386

 Training with LR: 0.005, Batch Size: 128, Optimizer: SGD, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.7048361643798668,86.13877551020408,0.8662838458676234,0.8590174378464706
2,0.18376241945333333,95.78979591836735,0.9577170294769441,0.9575027615234317
3,0.12907882798317208,96.80816326530612,0.9679559604806762,0.9678410362733585
4,0.10466359436084023,97.37959183673469,0.9737018741127914,0.9736287226143249
5,0.08907842863710991,97.76122448979592,0.9775353992777054,0.9774769847518107
6,0.07909272265846673,98.0,0.979932687579716,0.9798733180768939
7,0.07093959695637693,98.19591836734693,0.9818889796053247,0.9818705496581893
8,0.0641529215086378,98.3204081632653,0.9831739666003623,0.9831115835498527
9,0.05920876116873623,98.46326530612245,0.9845940825686588,0.9845333327813093
10,0.05555353772050796,98.57142857142858,0.9856909538642661,0.9856425784366089
11,0.05079644091923383,98.73265306122448,0.9873132838361919,0.9872737195875818
12,0.04780666764543511,98.81428571428572,0.9881315334313061,0.9880712314978661
13,0.04492496506021633,98.94081632653061,0.9893831705409932,0.989324939972434
14,0.04224653350184465,98.9469387755102,0.9894573319999573,0.989409413565282
15,0.03998180199900822,99.00408163265307,0.9900084230517523,0.9899777320872583
16,0.037355150521657485,99.14081632653061,0.9914023159555603,0.9913668624236674
17,0.03527383889526362,99.14285714285714,0.9914140060568476,0.9913934251362253
18,0.03344496178097887,99.26326530612245,0.9926180086430672,0.9925876530655575
19,0.03185925867369607,99.26530612244898,0.99265052577073,0.9926152279777136
20,0.030055372863910683,99.3265306122449,0.9932677789896852,0.9932364732718624
21,0.02842428694496189,99.37551020408164,0.9937717577228794,0.9937253810380275
22,0.027194152904708453,99.39387755102041,0.9939483889061054,0.9939038764339339
23,0.02538551450840759,99.48163265306123,0.9948292125290422,0.9948023734464357
24,0.02434496999312163,99.52448979591837,0.995254556826237,0.995236332937521
25,0.022926491078514577,99.5734693877551,0.9957471572412562,0.9957246053947575
26,0.021874706607370325,99.56530612244899,0.9956639683386722,0.9956385882733642
27,0.02071652127680303,99.63061224489795,0.9963123028367991,0.9963026861951928
28,0.019791188292380413,99.63061224489795,0.9963060579706772,0.9962880350732679
29,0.01862511346262561,99.68775510204082,0.996898034147382,0.9968810982558673
30,0.017613303532712066,99.75102040816326,0.9975094091765742,0.9975102934683839
31,0.01671071060113706,99.74285714285715,0.9974433122520099,0.9974286630975957
32,0.016129154387944166,99.76734693877552,0.9976813132292562,0.9976663786153604
33,0.015044599828643448,99.78775510204082,0.9978831317346033,0.9978789123686624
34,0.01445949614879629,99.82040816326531,0.9982125336096137,0.998202838619906
35,0.014034589142210334,99.80816326530612,0.9980832382223997,0.9980793988815083
36,0.013000449774222687,99.85510204081632,0.9985562089255847,0.9985545199965566
37,0.012279247169020555,99.85510204081632,0.9985546100730023,0.9985610450650023
38,0.011659825740469615,99.87959183673469,0.998791895615079,0.9988008844576504
39,0.011237975873792296,99.90816326530613,0.9990837470848766,0.9990809731431799

 Training with LR: 0.005, Batch Size: 128, Optimizer: SGD, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.5973712675876468,87.4938775510204,0.8780641718324279,0.8732834563793549
2,0.17520745736656237,95.84897959183674,0.9581968422082621,0.9582396034587397
3,0.12641662011025157,96.88979591836735,0.9686835304498771,0.9687198998173396
4,0.10338490653792809,97.41632653061224,0.9740137989113015,0.974035460963723
5,0.08899301425225585,97.73061224489797,0.9771456105593549,0.9771728330257886
6,0.07852354939472582,98.04081632653062,0.9803228172937223,0.9803178573331126
7,0.07097657602620809,98.15714285714286,0.9814692782829137,0.9814662229676175
8,0.06465297949065116,98.31428571428572,0.9830558622553569,0.9830597960746905
9,0.05944818029223939,98.46122448979592,0.9845467240376229,0.9845427376483382
10,0.05550805344574601,98.56326530612245,0.985570855915905,0.9855586725141702
11,0.05147032489800733,98.67551020408163,0.9866927184934546,0.9866887616018156
12,0.04799835532952304,98.77142857142857,0.987673528878784,0.9876514029149073
13,0.044798327079796606,98.85102040816327,0.9884705400896887,0.9884503805586766
14,0.04253637891350309,98.90408163265306,0.9890202719417207,0.9890204709137901
15,0.04017734091349588,98.97551020408163,0.9897124576245491,0.9897019462274729
16,0.03730980814714228,99.08367346938776,0.990823589004244,0.9908091154391065
17,0.035642479981633765,99.08979591836736,0.9908505798028024,0.990870785688686
18,0.0334737809294684,99.18367346938776,0.9918247641894954,0.9918196334295362
19,0.03222942758867074,99.23877551020408,0.9923876834592047,0.9923908954251941
20,0.03089268386422343,99.2469387755102,0.9924533209348698,0.9924481098489707
21,0.02902767284075406,99.33673469387755,0.9934006668950159,0.9933566433036379
22,0.027383809249031093,99.38979591836735,0.993897551185061,0.993887510556044
23,0.026002880339036565,99.41020408163266,0.9940888584465846,0.9940867484228756
24,0.02463974148234445,99.46938775510205,0.9947035618363149,0.9946690246751111
25,0.02370157258161988,99.48775510204082,0.9948793741855793,0.9948719202137447
26,0.022437341100300417,99.5061224489796,0.9950703948721668,0.9950661046704923
27,0.021368358613723798,99.55510204081632,0.9955399724581732,0.9955242105858048
28,0.020571911211463553,99.57755102040817,0.9957916791221137,0.9957634561802327
29,0.019422541951211097,99.66530612244898,0.996661384428698,0.9966444614791861
30,0.018529076321298552,99.7,0.9970261191947941,0.9969921778932929
31,0.017761790231307945,99.67142857142856,0.9967220729746581,0.9967145950685751
32,0.01678816441813722,99.72448979591837,0.9972512450594812,0.9972388798300006
33,0.016025045788153888,99.7795918367347,0.9977797455144708,0.9978048547637609
34,0.015622257827671716,99.76326530612245,0.9976329777862516,0.9976194234840168
35,0.01462321675093188,99.78979591836735,0.9979131460734157,0.9978984191435456
36,0.0141662880322378,99.82040816326531,0.9982254427476631,0.9982030229352368

 Training with LR: 0.005, Batch Size: 128, Optimizer: Adam, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.2238164834979698,94.8,0.9485505664752891,0.9472973021736222
2,0.060522212792800706,98.19183673469388,0.9818719137111644,0.9817986290719214
3,0.04534660199384737,98.58571428571429,0.9857606034330638,0.9857189171214629
4,0.034849786649484855,98.88367346938776,0.9887954816294664,0.988763532818
5,0.027510043400809092,99.1,0.9909701817313221,0.9909304540274381
6,0.023719005649009667,99.2204081632653,0.9921554959735885,0.9921593708560528
7,0.019580119985822035,99.34693877551021,0.9934290461330579,0.9934084743289985
8,0.014915573471785078,99.56326530612245,0.9956128928237566,0.9955885257007597
9,0.012856486697368781,99.62244897959184,0.9961902151482909,0.9961987967926833

 Training with LR: 0.005, Batch Size: 128, Optimizer: Adam, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.2249778579755178,94.63061224489796,0.9458807225463964,0.9457318893373007
2,0.06399313969824551,98.05714285714285,0.980484550075813,0.9804241178357975
3,0.04676900321603133,98.58163265306122,0.9857536904646249,0.9857368999561708
4,0.03657536357203523,98.88775510204081,0.9888128187056223,0.9887635753548455
5,0.030263071408612025,99.07959183673469,0.9907476701588518,0.9907020000432615
6,0.024100572307893215,99.26122448979592,0.9925559792641874,0.9925352345479675
7,0.021277646282772893,99.35510204081632,0.9934971504827201,0.9935013471644476
8,0.018797807748047707,99.4,0.9939636761741809,0.993943673332087
9,0.014430648027329558,99.55510204081632,0.9955240727474678,0.9955135098510836
10,0.01449095523112524,99.53061224489797,0.9952800511483411,0.9952544370552232
11,0.010932618902352403,99.64285714285714,0.996412669901426,0.9963953286036908
12,0.01081311382958483,99.64285714285714,0.9963932450083043,0.9963866001621657

 Training with LR: 0.005, Batch Size: 128, Optimizer: Adam, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.20867824397844995,94.73469387755102,0.9471729081929506,0.9468808473574564
2,0.06132560273919342,98.13469387755102,0.9812594145754601,0.9812005411387725
3,0.04608815461008107,98.58775510204082,0.9857967898902018,0.9857612783726438
4,0.03704152711151611,98.85510204081632,0.9884766618279887,0.9884465156021571
5,0.031076886081416403,98.98979591836735,0.989825337764459,0.98980840922778
6,0.025339624801329664,99.17755102040816,0.9917266681634425,0.9917000607620163
7,0.020894490921621846,99.36938775510204,0.9936795011958374,0.9936523425643303
8,0.018499786971628122,99.41836734693878,0.9941556723958597,0.994139383562047
9,0.014375254677185503,99.56938775510204,0.9956578663995599,0.9956644013785914

 Training with LR: 0.01, Batch Size: 32, Optimizer: SGD, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.2324641913852798,94.19183673469388,0.9416871140525535,0.9413867634229109
2,0.07671440472521189,97.77755102040815,0.9777006590485653,0.9776523953240732
3,0.05592675235893884,98.39591836734694,0.9839025979731749,0.983839237643353
4,0.04495596586489216,98.71836734693878,0.987183663348349,0.9870998892861828
5,0.036726630650969545,98.85918367346939,0.9885657929647808,0.9885074055852856
6,0.030548639035316832,99.12448979591836,0.9912277699333059,0.9911926259820538
7,0.025269648963257223,99.27755102040817,0.992741242403771,0.9927220416558014
8,0.021897499134557234,99.37755102040816,0.9937276901950662,0.993733246216333
9,0.01878439242790171,99.4734693877551,0.9946997540715421,0.9946949600725317
10,0.015225861331821598,99.60816326530613,0.9960469235415486,0.9960576645145943
11,0.012891793434277746,99.73469387755102,0.9973451341643808,0.9973177962253233
12,0.011517775235854165,99.7530612244898,0.9975200076561703,0.9975373165598462
13,0.008710595393514165,99.87551020408164,0.9987478980877624,0.9987458112113197

 Training with LR: 0.01, Batch Size: 32, Optimizer: SGD, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.2287920614687468,94.52857142857142,0.9451445212854976,0.9446214870332137
2,0.07549746234733465,97.90204081632653,0.9789588198427841,0.9788742006445901
3,0.05780959137129979,98.3204081632653,0.983148637516355,0.9830872048538424
4,0.0470170606058863,98.63265306122449,0.986258639174974,0.9862364580174188
5,0.03973152632161692,98.85918367346939,0.9885120122653722,0.9884853682810846
6,0.033454803469329136,99.05510204081632,0.9905096114985102,0.9904844093553073
7,0.028206817351960074,99.21224489795918,0.9920766761784627,0.9920600176524822
8,0.025365762809933134,99.29183673469387,0.992899087517284,0.992860860606412
9,0.02172648737430615,99.43673469387755,0.9943453350455448,0.9943424936331546
10,0.01881983201795505,99.49591836734693,0.9949390450167617,0.9949132999817125
11,0.01623081789092231,99.58571428571429,0.9958365151754244,0.9958041456325081
12,0.013417560748791114,99.68775510204082,0.9968689104263438,0.9968520836901078
13,0.011653383061654232,99.73673469387755,0.9973586759252377,0.9973663822560963
14,0.01016503152340603,99.80816326530612,0.9980937549030745,0.9980774347982326

 Training with LR: 0.01, Batch Size: 32, Optimizer: SGD, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.19219914262484536,95.16530612244898,0.9515614651499311,0.9511304604580333
2,0.07110396120454095,97.95714285714286,0.9795057072523645,0.9794078547385846
3,0.05368632174866923,98.41428571428571,0.9840731784846038,0.9840310153113266
4,0.04436991769203724,98.68775510204082,0.9868384462191401,0.986750622244684
5,0.036624456760034334,98.9469387755102,0.9894401004161455,0.9893895754646239
6,0.03174211557240404,99.0938775510204,0.9909137549536627,0.9908577097808333
7,0.027325012314275598,99.21632653061224,0.9921487048885428,0.9920987174075829
8,0.023714759057055182,99.29183673469387,0.9928634998955312,0.9928344384396963
9,0.02063156017419176,99.42040816326531,0.9942076096558985,0.9941836672829989
10,0.017265371168257975,99.54081632653062,0.995403053579295,0.9953752308604569
11,0.014891518011193585,99.63877551020408,0.996369671471182,0.9963830565744184
12,0.013434550641079122,99.66530612244898,0.9966376630009304,0.9966287321406474
13,0.010370229485930067,99.81632653061224,0.9981569761800803,0.9981503603679778
14,0.00947215550199717,99.8061224489796,0.9980597509688828,0.9980476422882723
15,0.008150475242528094,99.85306122448979,0.9985412887796178,0.9985295594730534

 Training with LR: 0.01, Batch Size: 32, Optimizer: Adam, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.14433935729584016,95.72857142857143,0.9570635383499141,0.9569372382995607
2,0.0670903042495596,97.90408163265306,0.9788710247254813,0.9788805426021112
3,0.05419525771233925,98.2265306122449,0.9821015201270823,0.9820716702871584
4,0.0478213455003468,98.43265306122449,0.984177876981758,0.9841908849255725
5,0.037270931178157274,98.79795918367347,0.9879016155950333,0.9878979857277186
6,0.03628124851138518,98.83469387755102,0.9882483801769665,0.9882447721990408
7,0.02811270112991701,99.04489795918367,0.9903781805461331,0.990350404565471
8,0.02656069632011685,99.09183673469387,0.9908278336584496,0.9908249547030822
9,0.026752650320113817,99.08979591836736,0.9908239599918195,0.9908207551122888
10,0.023266098562180145,99.21836734693878,0.9921046012508677,0.9921137140368144
11,0.018771063107813162,99.34897959183674,0.9934192002497249,0.993422387323528

 Training with LR: 0.01, Batch Size: 32, Optimizer: Adam, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.13501926158473088,95.99591836734695,0.9596946895704386,0.9595917641037911
2,0.06777045861566372,97.90612244897959,0.978940194733919,0.9788724304419814
3,0.053732873581824554,98.3204081632653,0.983098556507181,0.9830461746788863
4,0.045275565367574634,98.57551020408162,0.9856485358769265,0.9856261328344544
5,0.03948780772118431,98.74897959183674,0.9874385031269753,0.9873786765051257
6,0.03298843961978819,98.91224489795918,0.9890480345732545,0.9890357448521458
7,0.03081510620991709,98.96530612244898,0.9895781585341858,0.9895454226319478
8,0.027196873328027536,99.11020408163266,0.9910651791802767,0.9910611803770356
9,0.023834242591111048,99.21224489795918,0.9920726609023676,0.9920573281872033
10,0.021006347530887745,99.28367346938775,0.9927985800942485,0.9927893877584587
11,0.022112479587101146,99.26734693877552,0.992632935533735,0.9926387007389277

 Training with LR: 0.01, Batch Size: 32, Optimizer: Adam, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.1364130017815119,95.94897959183673,0.9593173853227995,0.9591622693560427
2,0.0676558017646365,97.81836734693877,0.9780382461044954,0.9779953478967294
3,0.05201951506783652,98.33061224489796,0.9831760009803909,0.983161975634674
4,0.043912173952016464,98.56122448979592,0.9855369488020355,0.9855115854693333
5,0.040581417846866606,98.6938775510204,0.9868282948878434,0.9868127003400128
6,0.03393066631684756,98.93061224489796,0.9892306936794244,0.9892240674802328
7,0.030157050648673443,99.0204081632653,0.9901388930060093,0.9901290683689332
8,0.029657298957677002,99.06734693877551,0.9905980879515912,0.9906126335459184
9,0.02316257664438111,99.21020408163265,0.9920532632904564,0.9920498531286899

 Training with LR: 0.01, Batch Size: 64, Optimizer: SGD, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.31980117729454066,92.54897959183673,0.9259235057887458,0.924659765880769
2,0.09421683953924216,97.34081632653061,0.9732676771641318,0.9732312457037985
3,0.06852952034307483,98.0469387755102,0.9803644315660346,0.9803121165315126
4,0.05432363775104051,98.46122448979592,0.9845512023720557,0.9845186332291312
5,0.045364352843454275,98.75714285714285,0.987546214430939,0.9874541103129649
6,0.038556389142540295,98.9469387755102,0.9894470509235678,0.9894040542688879
7,0.033288335773544314,99.11836734693877,0.9911564828111347,0.9911504827165132
8,0.029634028244593397,99.21632653061224,0.9921404566737146,0.9921106399999788
9,0.02574926391094996,99.3265306122449,0.9932559035624055,0.993232028225771
10,0.022638767680023156,99.45306122448979,0.994534028095765,0.9944901066175706
11,0.019800032704962812,99.55714285714285,0.9955633444500547,0.9955421143825893
12,0.017826515276352182,99.58163265306122,0.9958033831580849,0.9957921340190659
13,0.015311952162483542,99.68775510204082,0.9968846793458221,0.9968648809691082
14,0.013968043541702911,99.73265306122448,0.9973332345641033,0.997318555687503
15,0.01202073721877754,99.79183673469387,0.997922157790782,0.9979129977830379
16,0.010490227811565554,99.84081632653061,0.9984015442733559,0.9984113341857699
17,0.009032990073334723,99.90816326530613,0.9990874736170869,0.9990769094361356
18,0.007695191140159267,99.93673469387755,0.9993740364445169,0.9993706792493487
19,0.006615869728758671,99.95510204081633,0.9995556668256029,0.9995522483198922
20,0.006070383251602117,99.96122448979592,0.999616317947661,0.999616330282891
21,0.005259545622913255,99.9795918367347,0.9997935141179708,0.9997971293812574

 Training with LR: 0.01, Batch Size: 64, Optimizer: SGD, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.32206239225950783,92.85918367346939,0.928691252098756,0.9277712535714968
2,0.09231794294694502,97.55510204081632,0.9755019345498344,0.9754136752185266
3,0.06864382939014399,98.13673469387754,0.9813208378606426,0.9812195193326352
4,0.05578545682611279,98.45306122448979,0.9844600458636121,0.9844259400476499
5,0.04690361999622096,98.71632653061224,0.9871206178384977,0.9870658328949243
6,0.04120900370326506,98.81632653061224,0.9881373618344252,0.9880871679817759
7,0.03546369916944237,99.03265306122448,0.9902955420463158,0.9902417764771074
8,0.031241916576898888,99.17142857142856,0.9916955251699754,0.9916707284898283
9,0.027744249188293782,99.27142857142857,0.9926859088042767,0.9926331599890427
10,0.024076460719785798,99.4,0.9939796047278477,0.9939567213813909
11,0.021545246690900768,99.50204081632653,0.9950134085860249,0.9949714620389243
12,0.019369809328871425,99.54285714285714,0.9954275416213584,0.9954146508219581
13,0.01664334451258438,99.65102040816326,0.9965013744969016,0.9964986233012624
14,0.014988351081511342,99.67551020408163,0.9967605348114761,0.9967162309856855
15,0.013019850761471583,99.77142857142857,0.9977200218726894,0.9977157170405585
16,0.011669142276909465,99.76530612244898,0.9976607881549994,0.997634739878162
17,0.01025812155047344,99.83673469387755,0.9983685050112184,0.9983565397319708
18,0.00921579001934326,99.86938775510204,0.9986962022853948,0.9986839781850605
19,0.007945695526392732,99.91428571428571,0.9991507841749134,0.9991350850228109
20,0.007213769534310356,99.93061224489796,0.9993166221768652,0.9992990859013233
21,0.006125985481077198,99.95510204081633,0.9995514684226116,0.9995559517973287
22,0.005500046401103781,99.96938775510205,0.9996993723729467,0.9996939477716428
23,0.004808792885752789,99.98367346938775,0.9998457129611739,0.9998294015208694
24,0.004430495262515759,99.9857142857143,0.9998577518331464,0.9998691356710964
25,0.004078317558863711,99.98775510204082,0.9998754906482151,0.9998788263552278

 Training with LR: 0.01, Batch Size: 64, Optimizer: SGD, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.29137821834991556,93.19183673469388,0.9318132477647441,0.9312073828519903
2,0.09136975250467075,97.5061224489796,0.9749590450348254,0.9748803322662232
3,0.06884644367895028,98.11428571428571,0.9810395456701052,0.981040632339053
4,0.05607232326512801,98.45510204081633,0.9845223114902184,0.9844347453036674
5,0.04839045103024157,98.65102040816328,0.9864414303665845,0.9864243579598423
6,0.04240247133059072,98.79795918367347,0.987937454029981,0.9879265342866953
7,0.03772241604975218,98.97142857142858,0.9896531458380986,0.9896287624651452
8,0.033878019306317515,99.11632653061224,0.9911504137327432,0.9911085781373841
9,0.030764902285640626,99.15714285714286,0.9915478371682436,0.991524067974319
10,0.027104117607578693,99.31224489795918,0.993114120057592,0.9930732642542536
11,0.024113521941751485,99.40816326530613,0.9940847631005741,0.9940520582007164
12,0.02243385092153484,99.45918367346938,0.9945742787282927,0.9945622179369696
13,0.020136045144448986,99.48775510204082,0.9948748102162815,0.9948429597030618
14,0.018398730816987074,99.5734693877551,0.9957345847830539,0.9956999823840791
15,0.01585192419056642,99.65714285714286,0.9965725384094141,0.9965488565226727

 Training with LR: 0.01, Batch Size: 64, Optimizer: Adam, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.15110623462529313,95.66326530612244,0.9565613433275295,0.9562383646757497
2,0.06231297379588786,98.10408163265306,0.9809343690162086,0.9809366544873018
3,0.04690942189634313,98.53469387755102,0.9852486437218833,0.9852195772648763
4,0.03910444360001465,98.68571428571428,0.9867426343904053,0.9867147300798951
5,0.034239773134396696,98.87755102040816,0.9887064975599884,0.9886783550722047
6,0.029540981910264122,99.04897959183674,0.9904187307180571,0.9903924596598881
7,0.025630097865739804,99.13469387755102,0.9913251946707407,0.9913013398661752
8,0.02326148874905453,99.22244897959183,0.9921593688264935,0.992160608649255
9,0.018969848495131093,99.35102040816327,0.9934557135354037,0.9934417611534396
10,0.018979607838220506,99.36530612244898,0.9935917924891798,0.9935976505683273

 Training with LR: 0.01, Batch Size: 64, Optimizer: Adam, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.15245626808701002,95.45510204081633,0.9542694378638028,0.9540866827486421
2,0.06328793168621133,98.0061224489796,0.9799362745095538,0.9799097278163975
3,0.046449711044013804,98.4795918367347,0.9846892248010836,0.9846690096269208
4,0.04123878368120592,98.68571428571428,0.9867663449832109,0.9867584131724513
5,0.03261135460339412,98.93673469387755,0.9892959064248709,0.9892756446314628
6,0.02992151967148859,99.01224489795918,0.9900739715992163,0.9900263035728143
7,0.025638095957644838,99.14693877551021,0.9914041938666488,0.9914067181933186
8,0.022693410589124212,99.22857142857143,0.9922638866853969,0.99225036569345
9,0.02142943373492824,99.26122448979592,0.9925481131144916,0.9925432022661559
10,0.019920302419984607,99.31836734693877,0.9931570766459379,0.9931487216873984
11,0.014852443037629719,99.51224489795918,0.9950964147683703,0.9950882400386065
12,0.014995541632571994,99.47142857142856,0.9946846341828263,0.9946828349396709

 Training with LR: 0.01, Batch Size: 64, Optimizer: Adam, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.15114986825267498,95.63265306122449,0.9559965757034103,0.9559160291405325
2,0.06314150589504874,98.00408163265305,0.9799076439329155,0.9798500155805557
3,0.04971918424587775,98.42448979591836,0.9841284586887025,0.984115139774708
4,0.039872735692096956,98.69795918367346,0.9868738371544513,0.9868609542123508
5,0.033795173310336726,98.90816326530613,0.9890065791458866,0.9889999755058902
6,0.029175541964122496,99.03877551020408,0.9903308123141903,0.9903333380759278
7,0.026180059229542835,99.13673469387754,0.9913180981364468,0.9913030842601811
8,0.021834753382430003,99.27755102040817,0.9927397594100201,0.9927366557429902
9,0.022689708536771578,99.20204081632653,0.991974645638695,0.9919605716413985
10,0.01823838286865708,99.37551020408164,0.9936978793604998,0.9936808080973435

 Training with LR: 0.01, Batch Size: 128, Optimizer: SGD, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.5029035369736718,88.68367346938776,0.8886306727496383,0.8849206426341658
2,0.1258081384586759,96.82857142857144,0.9681579079430886,0.968105738389254
3,0.08992441344821422,97.65510204081632,0.9764521618663773,0.9763952624799781
4,0.07268555991974107,98.10612244897959,0.9809746240154033,0.980931742566417
5,0.0612107030755546,98.40612244897959,0.9839816084218203,0.9839664110274461
6,0.05251220427939848,98.60204081632654,0.985936039754679,0.9859241952242975
7,0.04688053191019412,98.80408163265307,0.9879713226465843,0.9879608704737952
8,0.041905083238845085,98.92244897959183,0.9891941229692923,0.9891702895331763
9,0.0377362997686933,99.03265306122448,0.9902774231374716,0.9902562440321802
10,0.03405876357750311,99.15102040816328,0.9914703618070577,0.9914382276432766
11,0.030523655015741797,99.25918367346938,0.9925682846180688,0.9925348569317217
12,0.027789005353151975,99.34693877551021,0.9934412882968514,0.9934254931699273
13,0.02576911638006957,99.40816326530613,0.9940557553112589,0.9940486590274384
14,0.023565413632160224,99.4857142857143,0.9948503695127053,0.9948256131544582
15,0.021190824529384665,99.55102040816325,0.9954964398275316,0.9954905364800366
16,0.01968943526088102,99.58367346938776,0.9958128555653637,0.9958232201129128
17,0.018439878384988784,99.60612244897959,0.9960420343287797,0.9960379440152772
18,0.01639378513270313,99.68775510204082,0.996870469860793,0.996879469867474
19,0.014787446548213925,99.75918367346938,0.9975943551845994,0.9975726568691992
20,0.013629914200001496,99.7938775510204,0.9979365222920846,0.997928761800725
21,0.012587850774801275,99.83673469387755,0.9983774669610085,0.9983579254744284
22,0.011274616099047832,99.85102040816327,0.998516073559497,0.9984940969852554
23,0.010336812755199971,99.88979591836735,0.998903764569247,0.9988980560096454

 Training with LR: 0.01, Batch Size: 128, Optimizer: SGD, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.5101224833384507,88.5734693877551,0.8866416559253686,0.8841536339145124
2,0.12827791781322764,96.86734693877551,0.9685619210220789,0.9684247218454504
3,0.09284069544730547,97.63265306122449,0.9762346670701012,0.9761674095860553
4,0.07535311175077453,98.00816326530612,0.9800107893542165,0.9799590779254508
5,0.06471607572455008,98.29795918367347,0.9829275395067463,0.9828802774824196
6,0.057283123395850705,98.46530612244898,0.9846111636708867,0.984558015328847
7,0.05081203711455002,98.62244897959184,0.986164883781567,0.9861348332794153
8,0.04589692027096493,98.76122448979592,0.987566004122485,0.9875402142018093
9,0.04193347688355816,98.90408163265306,0.9890128575313433,0.9889528994612358
10,0.03796767968655255,98.99795918367347,0.9899655690462179,0.9899056110438617
11,0.03480992440314229,99.07959183673469,0.9907642554542537,0.9907493087928081
12,0.03209888589186667,99.15918367346939,0.9915682069416791,0.9915255214171209
13,0.02912611119794433,99.26938775510204,0.9926785365630637,0.9926638866779705
14,0.027245231406816693,99.31632653061224,0.9931532889227027,0.9931115606550248
15,0.02476796348075876,99.42244897959183,0.9942089504175253,0.9941849873686956
16,0.023224546378308192,99.48367346938775,0.9948367108712549,0.9948194091864557
17,0.02092457585907286,99.56326530612245,0.9956346557445366,0.995611202714121
18,0.019504787531674065,99.58367346938776,0.9958321032224227,0.9958186313595995
19,0.018000906582571585,99.66530612244898,0.9966567125305877,0.9966405417534359
20,0.01669590129801522,99.68775510204082,0.9968707109894634,0.9968587182786924
21,0.015612513042728638,99.74897959183674,0.9974883298752693,0.9974810457577454
22,0.01479681044410885,99.75918367346938,0.9976005549945341,0.9975743883196486
23,0.013582250944098005,99.78367346938775,0.9978427598348192,0.9978322516700867
24,0.012664500620901856,99.8061224489796,0.9980651482825481,0.99806451920714
25,0.011007503436771331,99.86734693877551,0.9986714759632248,0.9986624870273962

 Training with LR: 0.01, Batch Size: 128, Optimizer: SGD, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.4377890322600581,89.93061224489796,0.8994833672886079,0.8978208580967874
2,0.12750207049183684,96.80408163265307,0.9678961744533936,0.9678484015206216
3,0.09221254767699279,97.61632653061224,0.9760678206664408,0.9760131493554205
4,0.07534933797820585,97.96326530612245,0.9795392715181805,0.9795153050008059
5,0.06538568212901176,98.26122448979592,0.9825351696007731,0.9825051019420549
6,0.05618630422828792,98.4938775510204,0.9848756833362808,0.9848508602116416
7,0.049838908325501426,98.73265306122448,0.9872751251908903,0.9872567515482785
8,0.04592517013941203,98.75510204081633,0.9875480064029732,0.9874933571251108
9,0.0421030462133472,98.88775510204081,0.9888418534998022,0.9888158937048821
10,0.038276445701737785,98.9938775510204,0.9898885770676269,0.9898765302305084
11,0.034624165417650815,99.12244897959184,0.9912010513428132,0.991169024777818
12,0.03234125943319488,99.16122448979591,0.9915911451332773,0.9915663998366577
13,0.029850648633415956,99.25510204081633,0.9925300355069313,0.992509938223787
14,0.027756535857867245,99.34489795918367,0.9934393635333029,0.9934233762235664
15,0.026296597692687503,99.37755102040816,0.9937559847322192,0.9937390821117917
16,0.024177567591992823,99.45918367346938,0.9945614780132118,0.9945717511372504
17,0.022698727100795773,99.4938775510204,0.9949182039258242,0.9949143635447069
18,0.02071715905464816,99.54285714285714,0.9954117995068247,0.9953924465849717
19,0.018825543041319122,99.64285714285714,0.9964286055881185,0.9964070826789581
20,0.017787491458932585,99.63877551020408,0.9963965176952071,0.9963711847645857
21,0.01672423010820878,99.67959183673469,0.9967917923417563,0.9967754399784091
22,0.015354511797350319,99.74285714285715,0.9974326383162065,0.9974114131897747
23,0.014604709167082067,99.73469387755102,0.9973407086484262,0.9973206860966133
24,0.013436601817603016,99.80816326530612,0.9980976959991983,0.99806880860265
25,0.012611073095293098,99.83061224489795,0.9983183720900494,0.9982896970905244
26,0.011279595503036428,99.85306122448979,0.9985440114305468,0.9985234335290233
27,0.010768810174350114,99.84693877551021,0.9984676609074488,0.9984660959548004
28,0.01022650812954372,99.86734693877551,0.9986803707133518,0.9986590964929617
29,0.009396493062863307,99.91020408163264,0.9991044714884654,0.9990897715757084
30,0.008760660769437335,99.9061224489796,0.9990762500342756,0.9990609780479989
31,0.007990416673111775,99.94489795918368,0.9994632302702563,0.9994424443776729
32,0.007406181190466854,99.95714285714286,0.9995706429994126,0.9995670761095381
33,0.0070449965461898915,99.95714285714286,0.9995769641567105,0.9995708936214456
34,0.00652942345258792,99.97755102040816,0.999779813686714,0.9997696768551055
35,0.006370604046141393,99.97142857142856,0.9997251419555635,0.9997096613022605
36,0.00586696241495343,99.9795918367347,0.9998043791609694,0.9997947433128674

 Training with LR: 0.01, Batch Size: 128, Optimizer: Adam, Activation: ReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.17512929337658475,95.18571428571428,0.951598883252837,0.9513744495538514
2,0.05972120067099834,98.0938775510204,0.9808661483293154,0.9807582814873109
3,0.04270157477892595,98.62244897959184,0.9861396854234608,0.9861008428453673
4,0.03440602296749349,98.85102040816327,0.9884180622007239,0.9884217132218127
5,0.02951046300403939,99.03673469387755,0.990298886299217,0.9902771329897518
6,0.0227486158881638,99.26530612244898,0.9925988825750212,0.9925945954951162
7,0.020061145604383834,99.39387755102041,0.9938872620237234,0.9938862500613252
8,0.017164748187487526,99.45102040816326,0.9944701535476138,0.9944615073009435
9,0.017237488333441017,99.38163265306123,0.9937761531400516,0.9937424807821454
10,0.01360117403683818,99.56326530612245,0.9956098558966231,0.9956096484097173
11,0.011920607842258166,99.6,0.9959668347398731,0.9959616493009891

 Training with LR: 0.01, Batch Size: 128, Optimizer: Adam, Activation: LeakyReLU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.17555969559123094,95.23061224489796,0.9522510931068107,0.9517613104592207
2,0.061517935156258065,98.06326530612245,0.9805244451962803,0.9804435090567598
3,0.04428370443826867,98.60612244897959,0.9859637021347867,0.9859186315455029
4,0.03572133350169028,98.8061224489796,0.9879925275134486,0.9879672293271355
5,0.029026946334068618,99.06530612244899,0.9906076937295701,0.9905814104026609
6,0.025454114840029164,99.15306122448979,0.9914804592707837,0.9914465502783341
7,0.021180557779932527,99.31428571428572,0.9931002697029628,0.9930900886509864
8,0.018297800287700384,99.39183673469387,0.9938655642047329,0.9938586696775911

 Training with LR: 0.01, Batch Size: 128, Optimizer: Adam, Activation: ELU
Epoch,Train Loss,Train Accuracy,Train Precision,Train Recall
1,0.17095199376879644,95.15510204081633,0.9513820592584175,0.9510709046856494
2,0.06380505347624421,98.04489795918367,0.9803471666011889,0.980286177798202
3,0.04636820939833945,98.5142857142857,0.9850550253696392,0.9850294189239778
4,0.039187015443079794,98.7204081632653,0.9870958534765935,0.987076922903349
5,0.031910329007278575,98.95306122448979,0.989469613704437,0.9894679067627008
6,0.027605777738285167,99.08571428571429,0.9908072020871682,0.9907761939106724
7,0.022468599591430948,99.28979591836735,0.9928521051850507,0.9928366395785929
8,0.021039340607232265,99.28979591836735,0.9928546430215288,0.9928471623271161
9,0.01874567577177683,99.34489795918367,0.9933952797498835,0.9933844251715526
